{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Image Classification\n",
    "In this project, you'll classify images from the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html).  The dataset consists of airplanes, dogs, cats, and other objects. You'll preprocess the images, then train a convolutional neural network on all the samples. The images need to be normalized and the labels need to be one-hot encoded.  You'll get to apply what you learned and build a convolutional, max pooling, dropout, and fully connected layers.  At the end, you'll get to see your neural network's predictions on the sample images.\n",
    "## Get the Data\n",
    "Run the following cell to download the [CIFAR-10 dataset for python](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "# Use Floyd's cifar-10 dataset if present\n",
    "floyd_cifar10_location = '/input/cifar-10/python.tar.gz'\n",
    "if isfile(floyd_cifar10_location):\n",
    "    tar_gz_path = floyd_cifar10_location\n",
    "else:\n",
    "    tar_gz_path = 'cifar-10-python.tar.gz'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile(tar_gz_path):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            tar_gz_path,\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open(tar_gz_path) as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Explore the Data\n",
    "The dataset is broken into batches to prevent your machine from running out of memory.  The CIFAR-10 dataset consists of 5 batches, named `data_batch_1`, `data_batch_2`, etc.. Each batch contains the labels and images that are one of the following:\n",
    "* airplane\n",
    "* automobile\n",
    "* bird\n",
    "* cat\n",
    "* deer\n",
    "* dog\n",
    "* frog\n",
    "* horse\n",
    "* ship\n",
    "* truck\n",
    "\n",
    "Understanding a dataset is part of making predictions on the data.  Play around with the code cell below by changing the `batch_id` and `sample_id`. The `batch_id` is the id for a batch (1-5). The `sample_id` is the id for a image and label pair in the batch.\n",
    "\n",
    "Ask yourself \"What are all possible labels?\", \"What is the range of values for the image data?\", \"Are the labels in order or random?\".  Answers to questions like these will help you preprocess the data and end up with better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 3:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 994, 1: 1042, 2: 965, 3: 997, 4: 990, 5: 1029, 6: 978, 7: 1015, 8: 961, 9: 1029}\n",
      "First 20 Labels: [8, 5, 0, 6, 9, 2, 8, 3, 6, 2, 7, 4, 6, 9, 0, 0, 7, 3, 7, 2]\n",
      "\n",
      "Example of Image 9999:\n",
      "Image - Min Value: 3 Max Value: 242\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 1 Name: automobile\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f69f4b040b8>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 3\n",
    "sample_id = 9999\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Implement Preprocess Functions\n",
    "### Normalize\n",
    "In the cell below, implement the `normalize` function to take in image data, `x`, and return it as a normalized Numpy array. The values should be in the range of 0 to 1, inclusive.  The return object should be the same shape as `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "from helper import load_cfar10_batch \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"    \n",
    "    return x / 255.0\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### One-hot encode\n",
    "Just like the previous code cell, you'll be implementing a function for preprocessing.  This time, you'll implement the `one_hot_encode` function. The input, `x`, are a list of labels.  Implement the function to return the list of labels as One-Hot encoded Numpy array.  The possible values for labels are 0 to 9. The one-hot encoding function should return the same encoding for each value between each call to `one_hot_encode`.  Make sure to save the map of encodings outside the function.\n",
    "\n",
    "Hint: Don't reinvent the wheel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "#     n = len(x)\n",
    "#     one_hot = np.zeros((n, 10))\n",
    "#     one_hot[range(n), x] = 1\n",
    "#     return one_hot\n",
    "\n",
    "# or\n",
    "\n",
    "    label_binarizer = LabelBinarizer()\n",
    "    label_binarizer.fit(x)\n",
    "    label_binarizer.classes_ = range(10)\n",
    "    y = label_binarizer.transform(x)\n",
    "    return y\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Randomize Data\n",
    "As you saw from exploring the data above, the order of the samples are randomized.  It doesn't hurt to randomize it again, but you don't need to for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Preprocess all the data and save it\n",
    "Running the code cell below will preprocess all the CIFAR-10 data and save it to file. The code below also uses 10% of the training data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Check Point\n",
    "This is your first checkpoint.  If you ever decide to come back to this notebook or have to restart the notebook, you can start from here.  The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Build the network\n",
    "For the neural network, you'll build each layer into a function.  Most of the code you've seen has been outside of functions. To test your code more thoroughly, we require that you put each layer in a function.  This allows us to give you better feedback and test for simple mistakes using our unittests before you submit your project.\n",
    "\n",
    "If you're finding it hard to dedicate enough time for this course a week, we've provided a small shortcut to this part of the project. In the next couple of problems, you'll have the option to use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) to build each layer, except \"Convolutional & Max Pooling\" layer.  TF Layers is similar to Keras's and TFLearn's abstraction to layers, so it's easy to pickup.\n",
    "\n",
    "If you would like to get the most of this course, try to solve all the problems without TF Layers.  Let's begin!\n",
    "### Input\n",
    "The neural network needs to read the image data, one-hot encoded labels, and dropout keep probability. Implement the following functions\n",
    "* Implement `neural_net_image_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `image_shape` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"x\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_label_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `n_classes` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"y\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_keep_prob_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) for dropout keep probability.\n",
    " * Name the TensorFlow placeholder \"keep_prob\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "\n",
    "These names will be used at the end of the project to load your saved model.\n",
    "\n",
    "Note: `None` for shapes in TensorFlow allow for a dynamic size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a bach of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    return tf.placeholder(shape=(None, 32, 32, 3), dtype=tf.float32, name='x')\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    return tf.placeholder(shape=(None, 10), dtype=tf.float32, name='y')\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    return tf.placeholder(dtype=tf.float32, name='keep_prob')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Convolution and Max Pooling Layer\n",
    "Convolution layers have a lot of success with images. For this code cell, you should implement the function `conv2d_maxpool` to apply convolution then max pooling:\n",
    "* Create the weight and bias using `conv_ksize`, `conv_num_outputs` and the shape of `x_tensor`.\n",
    "* Apply a convolution to `x_tensor` using weight and `conv_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "* Add bias\n",
    "* Add a nonlinear activation to the convolution.\n",
    "* Apply Max Pooling using `pool_ksize` and `pool_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "\n",
    "Note: You **can't** use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for this layer.  You're free to use any TensorFlow package for all the other layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    conv_shape = conv_ksize + (int(x_tensor.get_shape()[3]), conv_num_outputs)\n",
    "    weight = tf.Variable(tf.truncated_normal(shape=conv_shape, dtype=tf.float32, stddev=0.01))\n",
    "    bias = tf.Variable(tf.zeros(conv_num_outputs, dtype=tf.float32))\n",
    "    conv_out = tf.nn.conv2d(x_tensor, weight, strides=(1,)+conv_strides+(1,), padding='SAME')\n",
    "    biased = tf.add(conv_out, bias)\n",
    "    activated = tf.nn.relu(biased)\n",
    "    pooled = tf.nn.max_pool(activated, (1,)+pool_ksize+(1,), (1,)+pool_strides+(1,), padding='SAME')\n",
    "    return pooled \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Flatten Layer\n",
    "Implement the `flatten` function to change the dimension of `x_tensor` from a 4-D tensor to a 2-D tensor.  The output should be the shape (*Batch Size*, *Flattened Image Size*). You can use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for this layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "#     return tf.contrib.layers.flatten(x_tensor)\n",
    "# or\n",
    "    n = np.prod([int(d) for d in x_tensor.get_shape()[1:]])\n",
    "    return tf.reshape(x_tensor, [-1, n])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Fully-Connected Layer\n",
    "Implement the `fully_conn` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). You can use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for this layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs, use_activation=True):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    n = int(x_tensor.get_shape()[1])\n",
    "    weight = tf.Variable(tf.truncated_normal(shape=(n, num_outputs), dtype=tf.float32, stddev=0.01))\n",
    "    bias = tf.Variable(tf.zeros(num_outputs))\n",
    "    if use_activation:\n",
    "        return tf.nn.relu(tf.add(tf.matmul(x_tensor, weight), bias))\n",
    "    else:\n",
    "        return tf.add(tf.matmul(x_tensor, weight), bias)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Output Layer\n",
    "Implement the `output` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). You can use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for this layer.\n",
    "\n",
    "Note: Activation, softmax, or cross entropy shouldn't be applied to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    return fully_conn(x_tensor, num_outputs, False)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Create Convolutional Model\n",
    "Implement the function `conv_net` to create a convolutional neural network model. The function takes in a batch of images, `x`, and outputs logits.  Use the layers you created above to create this model:\n",
    "\n",
    "* Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "* Apply a Flatten Layer\n",
    "* Apply 1, 2, or 3 Fully Connected Layers\n",
    "* Apply an Output Layer\n",
    "* Return the output\n",
    "* Apply [TensorFlow's Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout) to one or more layers in the model using `keep_prob`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    \n",
    "    net = conv2d_maxpool(x, 48, (5,5), (2,2), (4,4), (2,2))\n",
    "    net = tf.nn.dropout(net, keep_prob)\n",
    "    net = conv2d_maxpool(net, 96, (3,3), (1,1), (4,4), (2,2))\n",
    "    net = tf.nn.dropout(net, keep_prob)\n",
    "    net = conv2d_maxpool(net, 256, (3,3), (1,1), (4,4), (2,2))\n",
    "    \n",
    "    net = flatten(net)\n",
    "\n",
    "    net = tf.nn.dropout(net, keep_prob)\n",
    "    net = fully_conn(net, 2048)\n",
    "    net = tf.nn.dropout(net, keep_prob)\n",
    "    net = fully_conn(net, 2048)\n",
    "    net = tf.nn.dropout(net, keep_prob)\n",
    "    net = fully_conn(net, 1000)\n",
    "    \n",
    "    net = output(net, 10)\n",
    "\n",
    "    return net\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Train the Neural Network\n",
    "### Single Optimization\n",
    "Implement the function `train_neural_network` to do a single optimization.  The optimization should use `optimizer` to optimize in `session` with a `feed_dict` of the following:\n",
    "* `x` for image input\n",
    "* `y` for labels\n",
    "* `keep_prob` for keep probability for dropout\n",
    "\n",
    "This function will be called for each batch, so `tf.global_variables_initializer()` has already been called.\n",
    "\n",
    "Note: Nothing needs to be returned. This function is only optimizing the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    session.run(optimizer, feed_dict={x: feature_batch, \n",
    "                                      y: label_batch, \n",
    "                                      keep_prob: keep_probability})\n",
    "        \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Show Stats\n",
    "Implement the function `print_stats` to print loss and validation accuracy.  Use the global variables `valid_features` and `valid_labels` to calculate validation accuracy.  Use a keep probability of `1.0` to calculate the loss and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    train_feed_dict={x: feature_batch, y: label_batch, keep_prob: 1.0}\n",
    "    valid_feed_dict={x: valid_features, y: valid_labels, keep_prob: 1.0}\n",
    "    cost_value = session.run(cost, feed_dict=train_feed_dict)\n",
    "    train_accuracy_value = session.run(accuracy, feed_dict=train_feed_dict)\n",
    "    valid_accuracy_value = session.run(accuracy, feed_dict=valid_feed_dict)\n",
    "    print('cost= {:<16.4f} train_acc= {:<16.4f} valid_acc= {:<16.4f}'.format(cost_value, train_accuracy_value, valid_accuracy_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Hyperparameters\n",
    "Tune the following parameters:\n",
    "* Set `epochs` to the number of iterations until the network stops learning or start overfitting\n",
    "* Set `batch_size` to the highest number that your machine has memory for.  Most people set them to common sizes of memory:\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* Set `keep_probability` to the probability of keeping a node using dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 250\n",
    "batch_size = 512\n",
    "keep_probability = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Train on a Single CIFAR-10 Batch\n",
    "Instead of training the neural network on all the CIFAR-10 batches of data, let's use a single batch. This should save time while you iterate on the model to get a better accuracy.  Once the final validation accuracy is 50% or greater, run the model on all the data in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  cost= 2.3035           train_acc= 0.0878           valid_acc= 0.0998          \n",
      "Epoch  2, CIFAR-10 Batch 1:  cost= 2.3045           train_acc= 0.0878           valid_acc= 0.0998          \n",
      "Epoch  3, CIFAR-10 Batch 1:  cost= 2.3036           train_acc= 0.0878           valid_acc= 0.0998          \n",
      "Epoch  4, CIFAR-10 Batch 1:  cost= 2.3032           train_acc= 0.0878           valid_acc= 0.0998          \n",
      "Epoch  5, CIFAR-10 Batch 1:  cost= 2.2989           train_acc= 0.1622           valid_acc= 0.1568          \n",
      "Epoch  6, CIFAR-10 Batch 1:  cost= 2.2330           train_acc= 0.1318           valid_acc= 0.1638          \n",
      "Epoch  7, CIFAR-10 Batch 1:  cost= 2.1705           train_acc= 0.1655           valid_acc= 0.1620          \n",
      "Epoch  8, CIFAR-10 Batch 1:  cost= 2.2731           train_acc= 0.1655           valid_acc= 0.1650          \n",
      "Epoch  9, CIFAR-10 Batch 1:  cost= 2.3460           train_acc= 0.1149           valid_acc= 0.1408          \n",
      "Epoch 10, CIFAR-10 Batch 1:  cost= 2.3347           train_acc= 0.1115           valid_acc= 0.1410          \n",
      "Epoch 11, CIFAR-10 Batch 1:  cost= 2.3351           train_acc= 0.1047           valid_acc= 0.1298          \n",
      "Epoch 12, CIFAR-10 Batch 1:  cost= 2.3935           train_acc= 0.1182           valid_acc= 0.1298          \n",
      "Epoch 13, CIFAR-10 Batch 1:  cost= 2.2627           train_acc= 0.1554           valid_acc= 0.1550          \n",
      "Epoch 14, CIFAR-10 Batch 1:  cost= 2.1555           train_acc= 0.2095           valid_acc= 0.1994          \n",
      "Epoch 15, CIFAR-10 Batch 1:  cost= 2.2838           train_acc= 0.1588           valid_acc= 0.2024          \n",
      "Epoch 16, CIFAR-10 Batch 1:  cost= 2.2011           train_acc= 0.2027           valid_acc= 0.2280          \n",
      "Epoch 17, CIFAR-10 Batch 1:  cost= 2.2612           train_acc= 0.1926           valid_acc= 0.2066          \n",
      "Epoch 18, CIFAR-10 Batch 1:  cost= 2.3670           train_acc= 0.1791           valid_acc= 0.1934          \n",
      "Epoch 19, CIFAR-10 Batch 1:  cost= 2.3744           train_acc= 0.1791           valid_acc= 0.2028          \n",
      "Epoch 20, CIFAR-10 Batch 1:  cost= 2.2129           train_acc= 0.2230           valid_acc= 0.2402          \n",
      "Epoch 21, CIFAR-10 Batch 1:  cost= 2.2018           train_acc= 0.2095           valid_acc= 0.2558          \n",
      "Epoch 22, CIFAR-10 Batch 1:  cost= 1.9686           train_acc= 0.2432           valid_acc= 0.2994          \n",
      "Epoch 23, CIFAR-10 Batch 1:  cost= 2.0573           train_acc= 0.2432           valid_acc= 0.2816          \n",
      "Epoch 24, CIFAR-10 Batch 1:  cost= 1.9332           train_acc= 0.3108           valid_acc= 0.3006          \n",
      "Epoch 25, CIFAR-10 Batch 1:  cost= 1.9725           train_acc= 0.2601           valid_acc= 0.2948          \n",
      "Epoch 26, CIFAR-10 Batch 1:  cost= 1.9134           train_acc= 0.3277           valid_acc= 0.3222          \n",
      "Epoch 27, CIFAR-10 Batch 1:  cost= 1.9528           train_acc= 0.3007           valid_acc= 0.3114          \n",
      "Epoch 28, CIFAR-10 Batch 1:  cost= 1.9538           train_acc= 0.2973           valid_acc= 0.3168          \n",
      "Epoch 29, CIFAR-10 Batch 1:  cost= 1.9111           train_acc= 0.2939           valid_acc= 0.3276          \n",
      "Epoch 30, CIFAR-10 Batch 1:  cost= 1.7664           train_acc= 0.3378           valid_acc= 0.3618          \n",
      "Epoch 31, CIFAR-10 Batch 1:  cost= 1.9677           train_acc= 0.2635           valid_acc= 0.3044          \n",
      "Epoch 32, CIFAR-10 Batch 1:  cost= 1.9876           train_acc= 0.2804           valid_acc= 0.3188          \n",
      "Epoch 33, CIFAR-10 Batch 1:  cost= 1.9718           train_acc= 0.2500           valid_acc= 0.3068          \n",
      "Epoch 34, CIFAR-10 Batch 1:  cost= 1.8970           train_acc= 0.2736           valid_acc= 0.3140          \n",
      "Epoch 35, CIFAR-10 Batch 1:  cost= 1.9008           train_acc= 0.2534           valid_acc= 0.3148          \n",
      "Epoch 36, CIFAR-10 Batch 1:  cost= 1.8378           train_acc= 0.2905           valid_acc= 0.3364          \n",
      "Epoch 37, CIFAR-10 Batch 1:  cost= 1.8885           train_acc= 0.3176           valid_acc= 0.3500          \n",
      "Epoch 38, CIFAR-10 Batch 1:  cost= 1.8545           train_acc= 0.2939           valid_acc= 0.3444          \n",
      "Epoch 39, CIFAR-10 Batch 1:  cost= 1.7568           train_acc= 0.3378           valid_acc= 0.3536          \n",
      "Epoch 40, CIFAR-10 Batch 1:  cost= 1.7149           train_acc= 0.3615           valid_acc= 0.3762          \n",
      "Epoch 41, CIFAR-10 Batch 1:  cost= 1.8381           train_acc= 0.3108           valid_acc= 0.3442          \n",
      "Epoch 42, CIFAR-10 Batch 1:  cost= 1.8078           train_acc= 0.3007           valid_acc= 0.3492          \n",
      "Epoch 43, CIFAR-10 Batch 1:  cost= 1.7350           train_acc= 0.3480           valid_acc= 0.3794          \n",
      "Epoch 44, CIFAR-10 Batch 1:  cost= 1.7151           train_acc= 0.3615           valid_acc= 0.3812          \n",
      "Epoch 45, CIFAR-10 Batch 1:  cost= 1.6707           train_acc= 0.3885           valid_acc= 0.3908          \n",
      "Epoch 46, CIFAR-10 Batch 1:  cost= 1.7813           train_acc= 0.3345           valid_acc= 0.3756          \n",
      "Epoch 47, CIFAR-10 Batch 1:  cost= 1.8082           train_acc= 0.2872           valid_acc= 0.3498          \n",
      "Epoch 48, CIFAR-10 Batch 1:  cost= 1.7145           train_acc= 0.3615           valid_acc= 0.3730          \n",
      "Epoch 49, CIFAR-10 Batch 1:  cost= 1.6608           train_acc= 0.3615           valid_acc= 0.3810          \n",
      "Epoch 50, CIFAR-10 Batch 1:  cost= 1.6852           train_acc= 0.3581           valid_acc= 0.3832          \n",
      "Epoch 51, CIFAR-10 Batch 1:  cost= 1.7107           train_acc= 0.3682           valid_acc= 0.3684          \n",
      "Epoch 52, CIFAR-10 Batch 1:  cost= 1.6790           train_acc= 0.3919           valid_acc= 0.3878          \n",
      "Epoch 53, CIFAR-10 Batch 1:  cost= 1.6291           train_acc= 0.4054           valid_acc= 0.4094          \n",
      "Epoch 54, CIFAR-10 Batch 1:  cost= 1.7271           train_acc= 0.3649           valid_acc= 0.3834          \n",
      "Epoch 55, CIFAR-10 Batch 1:  cost= 1.6700           train_acc= 0.3851           valid_acc= 0.3796          \n",
      "Epoch 56, CIFAR-10 Batch 1:  cost= 1.8384           train_acc= 0.3547           valid_acc= 0.3652          \n",
      "Epoch 57, CIFAR-10 Batch 1:  cost= 1.5890           train_acc= 0.4122           valid_acc= 0.4092          \n",
      "Epoch 58, CIFAR-10 Batch 1:  cost= 1.5711           train_acc= 0.4426           valid_acc= 0.4158          \n",
      "Epoch 59, CIFAR-10 Batch 1:  cost= 1.5807           train_acc= 0.4257           valid_acc= 0.3990          \n",
      "Epoch 60, CIFAR-10 Batch 1:  cost= 1.6376           train_acc= 0.3953           valid_acc= 0.3898          \n",
      "Epoch 61, CIFAR-10 Batch 1:  cost= 1.6775           train_acc= 0.3649           valid_acc= 0.3650          \n",
      "Epoch 62, CIFAR-10 Batch 1:  cost= 1.5650           train_acc= 0.4223           valid_acc= 0.4080          \n",
      "Epoch 63, CIFAR-10 Batch 1:  cost= 1.6860           train_acc= 0.3818           valid_acc= 0.3810          \n",
      "Epoch 64, CIFAR-10 Batch 1:  cost= 1.5770           train_acc= 0.4392           valid_acc= 0.4128          \n",
      "Epoch 65, CIFAR-10 Batch 1:  cost= 1.5588           train_acc= 0.4324           valid_acc= 0.4086          \n",
      "Epoch 66, CIFAR-10 Batch 1:  cost= 1.6160           train_acc= 0.4189           valid_acc= 0.3910          \n",
      "Epoch 67, CIFAR-10 Batch 1:  cost= 1.6070           train_acc= 0.4291           valid_acc= 0.4000          \n",
      "Epoch 68, CIFAR-10 Batch 1:  cost= 1.5431           train_acc= 0.4257           valid_acc= 0.4144          \n",
      "Epoch 69, CIFAR-10 Batch 1:  cost= 1.5225           train_acc= 0.4426           valid_acc= 0.4198          \n",
      "Epoch 70, CIFAR-10 Batch 1:  cost= 1.5900           train_acc= 0.4257           valid_acc= 0.4128          \n",
      "Epoch 71, CIFAR-10 Batch 1:  cost= 1.5630           train_acc= 0.4189           valid_acc= 0.4166          \n",
      "Epoch 72, CIFAR-10 Batch 1:  cost= 1.4927           train_acc= 0.4459           valid_acc= 0.4208          \n",
      "Epoch 73, CIFAR-10 Batch 1:  cost= 1.5407           train_acc= 0.4459           valid_acc= 0.4254          \n",
      "Epoch 74, CIFAR-10 Batch 1:  cost= 1.4154           train_acc= 0.4865           valid_acc= 0.4390          \n",
      "Epoch 75, CIFAR-10 Batch 1:  cost= 1.5576           train_acc= 0.4155           valid_acc= 0.4242          \n",
      "Epoch 76, CIFAR-10 Batch 1:  cost= 1.4807           train_acc= 0.4595           valid_acc= 0.4236          \n",
      "Epoch 77, CIFAR-10 Batch 1:  cost= 1.6147           train_acc= 0.3885           valid_acc= 0.3914          \n",
      "Epoch 78, CIFAR-10 Batch 1:  cost= 1.4447           train_acc= 0.4628           valid_acc= 0.4330          \n",
      "Epoch 79, CIFAR-10 Batch 1:  cost= 1.5328           train_acc= 0.4392           valid_acc= 0.4066          \n",
      "Epoch 80, CIFAR-10 Batch 1:  cost= 1.4534           train_acc= 0.4426           valid_acc= 0.4322          \n",
      "Epoch 81, CIFAR-10 Batch 1:  cost= 1.4397           train_acc= 0.4628           valid_acc= 0.4298          \n",
      "Epoch 82, CIFAR-10 Batch 1:  cost= 1.3590           train_acc= 0.5000           valid_acc= 0.4466          \n",
      "Epoch 83, CIFAR-10 Batch 1:  cost= 1.3760           train_acc= 0.4966           valid_acc= 0.4470          \n",
      "Epoch 84, CIFAR-10 Batch 1:  cost= 1.3437           train_acc= 0.4764           valid_acc= 0.4572          \n",
      "Epoch 85, CIFAR-10 Batch 1:  cost= 1.3395           train_acc= 0.5000           valid_acc= 0.4660          \n",
      "Epoch 86, CIFAR-10 Batch 1:  cost= 1.3151           train_acc= 0.4899           valid_acc= 0.4580          \n",
      "Epoch 87, CIFAR-10 Batch 1:  cost= 1.3153           train_acc= 0.5203           valid_acc= 0.4640          \n",
      "Epoch 88, CIFAR-10 Batch 1:  cost= 1.3782           train_acc= 0.4899           valid_acc= 0.4506          \n",
      "Epoch 89, CIFAR-10 Batch 1:  cost= 1.2872           train_acc= 0.5068           valid_acc= 0.4660          \n",
      "Epoch 90, CIFAR-10 Batch 1:  cost= 1.3119           train_acc= 0.5101           valid_acc= 0.4512          \n",
      "Epoch 91, CIFAR-10 Batch 1:  cost= 1.3623           train_acc= 0.4831           valid_acc= 0.4456          \n",
      "Epoch 92, CIFAR-10 Batch 1:  cost= 1.4253           train_acc= 0.4595           valid_acc= 0.4216          \n",
      "Epoch 93, CIFAR-10 Batch 1:  cost= 1.3164           train_acc= 0.5101           valid_acc= 0.4560          \n",
      "Epoch 94, CIFAR-10 Batch 1:  cost= 1.3319           train_acc= 0.5101           valid_acc= 0.4534          \n",
      "Epoch 95, CIFAR-10 Batch 1:  cost= 1.2404           train_acc= 0.5439           valid_acc= 0.4836          \n",
      "Epoch 96, CIFAR-10 Batch 1:  cost= 1.2341           train_acc= 0.5236           valid_acc= 0.4818          \n",
      "Epoch 97, CIFAR-10 Batch 1:  cost= 1.2940           train_acc= 0.5203           valid_acc= 0.4584          \n",
      "Epoch 98, CIFAR-10 Batch 1:  cost= 1.3366           train_acc= 0.4764           valid_acc= 0.4446          \n",
      "Epoch 99, CIFAR-10 Batch 1:  cost= 1.2962           train_acc= 0.5135           valid_acc= 0.4756          \n",
      "Epoch 100, CIFAR-10 Batch 1:  cost= 1.2306           train_acc= 0.5642           valid_acc= 0.4744          \n",
      "Epoch 101, CIFAR-10 Batch 1:  cost= 1.2354           train_acc= 0.5473           valid_acc= 0.4724          \n",
      "Epoch 102, CIFAR-10 Batch 1:  cost= 1.3109           train_acc= 0.5135           valid_acc= 0.4558          \n",
      "Epoch 103, CIFAR-10 Batch 1:  cost= 1.2793           train_acc= 0.5169           valid_acc= 0.4670          \n",
      "Epoch 104, CIFAR-10 Batch 1:  cost= 1.2781           train_acc= 0.5169           valid_acc= 0.4722          \n",
      "Epoch 105, CIFAR-10 Batch 1:  cost= 1.2191           train_acc= 0.5270           valid_acc= 0.4746          \n",
      "Epoch 106, CIFAR-10 Batch 1:  cost= 1.1933           train_acc= 0.5912           valid_acc= 0.4908          \n",
      "Epoch 107, CIFAR-10 Batch 1:  cost= 1.2101           train_acc= 0.5372           valid_acc= 0.4832          \n",
      "Epoch 108, CIFAR-10 Batch 1:  cost= 1.2010           train_acc= 0.5236           valid_acc= 0.4774          \n",
      "Epoch 109, CIFAR-10 Batch 1:  cost= 1.1945           train_acc= 0.5203           valid_acc= 0.4828          \n",
      "Epoch 110, CIFAR-10 Batch 1:  cost= 1.2262           train_acc= 0.5236           valid_acc= 0.4666          \n",
      "Epoch 111, CIFAR-10 Batch 1:  cost= 1.1890           train_acc= 0.5507           valid_acc= 0.4842          \n",
      "Epoch 112, CIFAR-10 Batch 1:  cost= 1.1829           train_acc= 0.5642           valid_acc= 0.4860          \n",
      "Epoch 113, CIFAR-10 Batch 1:  cost= 1.1453           train_acc= 0.5777           valid_acc= 0.4974          \n",
      "Epoch 114, CIFAR-10 Batch 1:  cost= 1.1133           train_acc= 0.5845           valid_acc= 0.5052          \n",
      "Epoch 115, CIFAR-10 Batch 1:  cost= 1.2005           train_acc= 0.5507           valid_acc= 0.4800          \n",
      "Epoch 116, CIFAR-10 Batch 1:  cost= 1.1953           train_acc= 0.5608           valid_acc= 0.4730          \n",
      "Epoch 117, CIFAR-10 Batch 1:  cost= 1.2490           train_acc= 0.5405           valid_acc= 0.4676          \n",
      "Epoch 118, CIFAR-10 Batch 1:  cost= 1.1547           train_acc= 0.5777           valid_acc= 0.4920          \n",
      "Epoch 119, CIFAR-10 Batch 1:  cost= 1.1923           train_acc= 0.5777           valid_acc= 0.4862          \n",
      "Epoch 120, CIFAR-10 Batch 1:  cost= 1.1777           train_acc= 0.5743           valid_acc= 0.4940          \n",
      "Epoch 121, CIFAR-10 Batch 1:  cost= 1.1015           train_acc= 0.5878           valid_acc= 0.4930          \n",
      "Epoch 122, CIFAR-10 Batch 1:  cost= 1.1613           train_acc= 0.5743           valid_acc= 0.4886          \n",
      "Epoch 123, CIFAR-10 Batch 1:  cost= 1.1503           train_acc= 0.5574           valid_acc= 0.4928          \n",
      "Epoch 124, CIFAR-10 Batch 1:  cost= 1.1710           train_acc= 0.5439           valid_acc= 0.4786          \n",
      "Epoch 125, CIFAR-10 Batch 1:  cost= 1.1590           train_acc= 0.5473           valid_acc= 0.4864          \n",
      "Epoch 126, CIFAR-10 Batch 1:  cost= 1.1622           train_acc= 0.5980           valid_acc= 0.4920          \n",
      "Epoch 127, CIFAR-10 Batch 1:  cost= 1.1622           train_acc= 0.5743           valid_acc= 0.4772          \n",
      "Epoch 128, CIFAR-10 Batch 1:  cost= 1.1819           train_acc= 0.5709           valid_acc= 0.4766          \n",
      "Epoch 129, CIFAR-10 Batch 1:  cost= 1.1717           train_acc= 0.5709           valid_acc= 0.4888          \n",
      "Epoch 130, CIFAR-10 Batch 1:  cost= 1.2019           train_acc= 0.5473           valid_acc= 0.4752          \n",
      "Epoch 131, CIFAR-10 Batch 1:  cost= 1.1840           train_acc= 0.5946           valid_acc= 0.4884          \n",
      "Epoch 132, CIFAR-10 Batch 1:  cost= 1.1165           train_acc= 0.5946           valid_acc= 0.5030          \n",
      "Epoch 133, CIFAR-10 Batch 1:  cost= 1.1542           train_acc= 0.5878           valid_acc= 0.4920          \n",
      "Epoch 134, CIFAR-10 Batch 1:  cost= 1.1587           train_acc= 0.5574           valid_acc= 0.4848          \n",
      "Epoch 135, CIFAR-10 Batch 1:  cost= 1.1490           train_acc= 0.5642           valid_acc= 0.4886          \n",
      "Epoch 136, CIFAR-10 Batch 1:  cost= 1.1347           train_acc= 0.5811           valid_acc= 0.4902          \n",
      "Epoch 137, CIFAR-10 Batch 1:  cost= 1.1532           train_acc= 0.5777           valid_acc= 0.4824          \n",
      "Epoch 138, CIFAR-10 Batch 1:  cost= 1.1169           train_acc= 0.5980           valid_acc= 0.4872          \n",
      "Epoch 139, CIFAR-10 Batch 1:  cost= 1.1903           train_acc= 0.5878           valid_acc= 0.4790          \n",
      "Epoch 140, CIFAR-10 Batch 1:  cost= 1.1521           train_acc= 0.5642           valid_acc= 0.4888          \n",
      "Epoch 141, CIFAR-10 Batch 1:  cost= 1.0986           train_acc= 0.5642           valid_acc= 0.4996          \n",
      "Epoch 142, CIFAR-10 Batch 1:  cost= 1.1099           train_acc= 0.5845           valid_acc= 0.4870          \n",
      "Epoch 143, CIFAR-10 Batch 1:  cost= 1.0894           train_acc= 0.5980           valid_acc= 0.4908          \n",
      "Epoch 144, CIFAR-10 Batch 1:  cost= 1.2169           train_acc= 0.5473           valid_acc= 0.4662          \n",
      "Epoch 145, CIFAR-10 Batch 1:  cost= 1.1737           train_acc= 0.5777           valid_acc= 0.4832          \n",
      "Epoch 146, CIFAR-10 Batch 1:  cost= 1.0851           train_acc= 0.6081           valid_acc= 0.5078          \n",
      "Epoch 147, CIFAR-10 Batch 1:  cost= 1.0550           train_acc= 0.6351           valid_acc= 0.5036          \n",
      "Epoch 148, CIFAR-10 Batch 1:  cost= 1.0752           train_acc= 0.6115           valid_acc= 0.5030          \n",
      "Epoch 149, CIFAR-10 Batch 1:  cost= 1.0466           train_acc= 0.6520           valid_acc= 0.5118          \n",
      "Epoch 150, CIFAR-10 Batch 1:  cost= 1.0984           train_acc= 0.6047           valid_acc= 0.5002          \n",
      "Epoch 151, CIFAR-10 Batch 1:  cost= 1.1034           train_acc= 0.6081           valid_acc= 0.4962          \n",
      "Epoch 152, CIFAR-10 Batch 1:  cost= 1.0545           train_acc= 0.6216           valid_acc= 0.5044          \n",
      "Epoch 153, CIFAR-10 Batch 1:  cost= 1.0252           train_acc= 0.6486           valid_acc= 0.5054          \n",
      "Epoch 154, CIFAR-10 Batch 1:  cost= 1.1317           train_acc= 0.5912           valid_acc= 0.5056          \n",
      "Epoch 155, CIFAR-10 Batch 1:  cost= 1.0990           train_acc= 0.6047           valid_acc= 0.4910          \n",
      "Epoch 156, CIFAR-10 Batch 1:  cost= 1.0888           train_acc= 0.5946           valid_acc= 0.4936          \n",
      "Epoch 157, CIFAR-10 Batch 1:  cost= 1.1672           train_acc= 0.5811           valid_acc= 0.4776          \n",
      "Epoch 158, CIFAR-10 Batch 1:  cost= 1.1739           train_acc= 0.5845           valid_acc= 0.4806          \n",
      "Epoch 159, CIFAR-10 Batch 1:  cost= 1.0778           train_acc= 0.6216           valid_acc= 0.4962          \n",
      "Epoch 160, CIFAR-10 Batch 1:  cost= 1.0286           train_acc= 0.6385           valid_acc= 0.4978          \n",
      "Epoch 161, CIFAR-10 Batch 1:  cost= 1.0251           train_acc= 0.6385           valid_acc= 0.5000          \n",
      "Epoch 162, CIFAR-10 Batch 1:  cost= 1.0406           train_acc= 0.6554           valid_acc= 0.5058          \n",
      "Epoch 163, CIFAR-10 Batch 1:  cost= 1.0216           train_acc= 0.6453           valid_acc= 0.5048          \n",
      "Epoch 164, CIFAR-10 Batch 1:  cost= 1.0371           train_acc= 0.6351           valid_acc= 0.5062          \n",
      "Epoch 165, CIFAR-10 Batch 1:  cost= 1.1182           train_acc= 0.6014           valid_acc= 0.4854          \n",
      "Epoch 166, CIFAR-10 Batch 1:  cost= 1.0187           train_acc= 0.6453           valid_acc= 0.5066          \n",
      "Epoch 167, CIFAR-10 Batch 1:  cost= 1.0917           train_acc= 0.6250           valid_acc= 0.4968          \n",
      "Epoch 168, CIFAR-10 Batch 1:  cost= 1.0076           train_acc= 0.6588           valid_acc= 0.5122          \n",
      "Epoch 169, CIFAR-10 Batch 1:  cost= 0.9780           train_acc= 0.6486           valid_acc= 0.5140          \n",
      "Epoch 170, CIFAR-10 Batch 1:  cost= 0.9648           train_acc= 0.6757           valid_acc= 0.5230          \n",
      "Epoch 171, CIFAR-10 Batch 1:  cost= 1.0173           train_acc= 0.6419           valid_acc= 0.5088          \n",
      "Epoch 172, CIFAR-10 Batch 1:  cost= 1.0719           train_acc= 0.6149           valid_acc= 0.4862          \n",
      "Epoch 173, CIFAR-10 Batch 1:  cost= 1.0122           train_acc= 0.6453           valid_acc= 0.5042          \n",
      "Epoch 174, CIFAR-10 Batch 1:  cost= 0.9735           train_acc= 0.6757           valid_acc= 0.5156          \n",
      "Epoch 175, CIFAR-10 Batch 1:  cost= 1.0162           train_acc= 0.6520           valid_acc= 0.5074          \n",
      "Epoch 176, CIFAR-10 Batch 1:  cost= 0.9819           train_acc= 0.6588           valid_acc= 0.5142          \n",
      "Epoch 177, CIFAR-10 Batch 1:  cost= 1.0399           train_acc= 0.6486           valid_acc= 0.4958          \n",
      "Epoch 178, CIFAR-10 Batch 1:  cost= 0.9422           train_acc= 0.6655           valid_acc= 0.5218          \n",
      "Epoch 179, CIFAR-10 Batch 1:  cost= 1.0341           train_acc= 0.6351           valid_acc= 0.5000          \n",
      "Epoch 180, CIFAR-10 Batch 1:  cost= 1.0263           train_acc= 0.6318           valid_acc= 0.5022          \n",
      "Epoch 181, CIFAR-10 Batch 1:  cost= 0.9797           train_acc= 0.6419           valid_acc= 0.5096          \n",
      "Epoch 182, CIFAR-10 Batch 1:  cost= 0.9456           train_acc= 0.6757           valid_acc= 0.5218          \n",
      "Epoch 183, CIFAR-10 Batch 1:  cost= 1.0251           train_acc= 0.6385           valid_acc= 0.5196          \n",
      "Epoch 184, CIFAR-10 Batch 1:  cost= 0.9691           train_acc= 0.6824           valid_acc= 0.5224          \n",
      "Epoch 185, CIFAR-10 Batch 1:  cost= 0.8989           train_acc= 0.7128           valid_acc= 0.5284          \n",
      "Epoch 186, CIFAR-10 Batch 1:  cost= 0.9547           train_acc= 0.6791           valid_acc= 0.5202          \n",
      "Epoch 187, CIFAR-10 Batch 1:  cost= 0.9478           train_acc= 0.6892           valid_acc= 0.5232          \n",
      "Epoch 188, CIFAR-10 Batch 1:  cost= 0.9124           train_acc= 0.6959           valid_acc= 0.5214          \n",
      "Epoch 189, CIFAR-10 Batch 1:  cost= 0.9961           train_acc= 0.6284           valid_acc= 0.5074          \n",
      "Epoch 190, CIFAR-10 Batch 1:  cost= 0.9830           train_acc= 0.6520           valid_acc= 0.5156          \n",
      "Epoch 191, CIFAR-10 Batch 1:  cost= 1.0337           train_acc= 0.6250           valid_acc= 0.5012          \n",
      "Epoch 192, CIFAR-10 Batch 1:  cost= 0.9132           train_acc= 0.6892           valid_acc= 0.5246          \n",
      "Epoch 193, CIFAR-10 Batch 1:  cost= 1.0288           train_acc= 0.6216           valid_acc= 0.5080          \n",
      "Epoch 194, CIFAR-10 Batch 1:  cost= 0.8985           train_acc= 0.7027           valid_acc= 0.5344          \n",
      "Epoch 195, CIFAR-10 Batch 1:  cost= 0.9671           train_acc= 0.6655           valid_acc= 0.5174          \n",
      "Epoch 196, CIFAR-10 Batch 1:  cost= 0.8677           train_acc= 0.7162           valid_acc= 0.5386          \n",
      "Epoch 197, CIFAR-10 Batch 1:  cost= 0.9442           train_acc= 0.6824           valid_acc= 0.5298          \n",
      "Epoch 198, CIFAR-10 Batch 1:  cost= 0.8705           train_acc= 0.7128           valid_acc= 0.5412          \n",
      "Epoch 199, CIFAR-10 Batch 1:  cost= 0.9979           train_acc= 0.6250           valid_acc= 0.5090          \n",
      "Epoch 200, CIFAR-10 Batch 1:  cost= 0.9199           train_acc= 0.6588           valid_acc= 0.5208          \n",
      "Epoch 201, CIFAR-10 Batch 1:  cost= 0.9801           train_acc= 0.6520           valid_acc= 0.5146          \n",
      "Epoch 202, CIFAR-10 Batch 1:  cost= 0.9490           train_acc= 0.6757           valid_acc= 0.5200          \n",
      "Epoch 203, CIFAR-10 Batch 1:  cost= 0.9061           train_acc= 0.6824           valid_acc= 0.5262          \n",
      "Epoch 204, CIFAR-10 Batch 1:  cost= 0.9563           train_acc= 0.6757           valid_acc= 0.5248          \n",
      "Epoch 205, CIFAR-10 Batch 1:  cost= 0.8994           train_acc= 0.7061           valid_acc= 0.5306          \n",
      "Epoch 206, CIFAR-10 Batch 1:  cost= 0.9484           train_acc= 0.6622           valid_acc= 0.5136          \n",
      "Epoch 207, CIFAR-10 Batch 1:  cost= 0.9364           train_acc= 0.6757           valid_acc= 0.5182          \n",
      "Epoch 208, CIFAR-10 Batch 1:  cost= 1.0385           train_acc= 0.6351           valid_acc= 0.5096          \n",
      "Epoch 209, CIFAR-10 Batch 1:  cost= 0.9176           train_acc= 0.6858           valid_acc= 0.5210          \n",
      "Epoch 210, CIFAR-10 Batch 1:  cost= 0.8746           train_acc= 0.7061           valid_acc= 0.5300          \n",
      "Epoch 211, CIFAR-10 Batch 1:  cost= 0.8225           train_acc= 0.7365           valid_acc= 0.5464          \n",
      "Epoch 212, CIFAR-10 Batch 1:  cost= 0.9171           train_acc= 0.7095           valid_acc= 0.5224          \n",
      "Epoch 213, CIFAR-10 Batch 1:  cost= 0.9471           train_acc= 0.6588           valid_acc= 0.5158          \n",
      "Epoch 214, CIFAR-10 Batch 1:  cost= 0.8674           train_acc= 0.7230           valid_acc= 0.5390          \n",
      "Epoch 215, CIFAR-10 Batch 1:  cost= 0.8626           train_acc= 0.7331           valid_acc= 0.5346          \n",
      "Epoch 216, CIFAR-10 Batch 1:  cost= 0.9706           train_acc= 0.6622           valid_acc= 0.5214          \n",
      "Epoch 217, CIFAR-10 Batch 1:  cost= 0.9003           train_acc= 0.6689           valid_acc= 0.5244          \n",
      "Epoch 218, CIFAR-10 Batch 1:  cost= 0.9572           train_acc= 0.6520           valid_acc= 0.5198          \n",
      "Epoch 219, CIFAR-10 Batch 1:  cost= 0.9290           train_acc= 0.6757           valid_acc= 0.5278          \n",
      "Epoch 220, CIFAR-10 Batch 1:  cost= 0.8316           train_acc= 0.7331           valid_acc= 0.5446          \n",
      "Epoch 221, CIFAR-10 Batch 1:  cost= 0.8214           train_acc= 0.7162           valid_acc= 0.5436          \n",
      "Epoch 222, CIFAR-10 Batch 1:  cost= 0.8222           train_acc= 0.7297           valid_acc= 0.5396          \n",
      "Epoch 223, CIFAR-10 Batch 1:  cost= 0.8635           train_acc= 0.7264           valid_acc= 0.5366          \n",
      "Epoch 224, CIFAR-10 Batch 1:  cost= 0.8243           train_acc= 0.7365           valid_acc= 0.5454          \n",
      "Epoch 225, CIFAR-10 Batch 1:  cost= 0.8387           train_acc= 0.7399           valid_acc= 0.5312          \n",
      "Epoch 226, CIFAR-10 Batch 1:  cost= 0.8402           train_acc= 0.7399           valid_acc= 0.5438          \n",
      "Epoch 227, CIFAR-10 Batch 1:  cost= 0.8906           train_acc= 0.6993           valid_acc= 0.5346          \n",
      "Epoch 228, CIFAR-10 Batch 1:  cost= 0.9022           train_acc= 0.6926           valid_acc= 0.5192          \n",
      "Epoch 229, CIFAR-10 Batch 1:  cost= 0.8695           train_acc= 0.7196           valid_acc= 0.5352          \n",
      "Epoch 230, CIFAR-10 Batch 1:  cost= 0.8215           train_acc= 0.7162           valid_acc= 0.5402          \n",
      "Epoch 231, CIFAR-10 Batch 1:  cost= 0.8574           train_acc= 0.7264           valid_acc= 0.5308          \n",
      "Epoch 232, CIFAR-10 Batch 1:  cost= 0.8513           train_acc= 0.7095           valid_acc= 0.5410          \n",
      "Epoch 233, CIFAR-10 Batch 1:  cost= 0.8184           train_acc= 0.7196           valid_acc= 0.5376          \n",
      "Epoch 234, CIFAR-10 Batch 1:  cost= 0.8561           train_acc= 0.7230           valid_acc= 0.5402          \n",
      "Epoch 235, CIFAR-10 Batch 1:  cost= 0.8573           train_acc= 0.7162           valid_acc= 0.5286          \n",
      "Epoch 236, CIFAR-10 Batch 1:  cost= 0.8087           train_acc= 0.7264           valid_acc= 0.5354          \n",
      "Epoch 237, CIFAR-10 Batch 1:  cost= 0.8695           train_acc= 0.6993           valid_acc= 0.5306          \n",
      "Epoch 238, CIFAR-10 Batch 1:  cost= 0.8538           train_acc= 0.7027           valid_acc= 0.5370          \n",
      "Epoch 239, CIFAR-10 Batch 1:  cost= 0.7879           train_acc= 0.7466           valid_acc= 0.5448          \n",
      "Epoch 240, CIFAR-10 Batch 1:  cost= 0.8373           train_acc= 0.7264           valid_acc= 0.5348          \n",
      "Epoch 241, CIFAR-10 Batch 1:  cost= 0.8501           train_acc= 0.7230           valid_acc= 0.5316          \n",
      "Epoch 242, CIFAR-10 Batch 1:  cost= 0.8096           train_acc= 0.7399           valid_acc= 0.5360          \n",
      "Epoch 243, CIFAR-10 Batch 1:  cost= 0.8042           train_acc= 0.7365           valid_acc= 0.5396          \n",
      "Epoch 244, CIFAR-10 Batch 1:  cost= 0.8078           train_acc= 0.7432           valid_acc= 0.5388          \n",
      "Epoch 245, CIFAR-10 Batch 1:  cost= 0.8531           train_acc= 0.7162           valid_acc= 0.5274          \n",
      "Epoch 246, CIFAR-10 Batch 1:  cost= 0.7955           train_acc= 0.7500           valid_acc= 0.5400          \n",
      "Epoch 247, CIFAR-10 Batch 1:  cost= 0.8225           train_acc= 0.7297           valid_acc= 0.5364          \n",
      "Epoch 248, CIFAR-10 Batch 1:  cost= 0.8240           train_acc= 0.7264           valid_acc= 0.5296          \n",
      "Epoch 249, CIFAR-10 Batch 1:  cost= 0.8461           train_acc= 0.7264           valid_acc= 0.5300          \n",
      "Epoch 250, CIFAR-10 Batch 1:  cost= 0.8356           train_acc= 0.7297           valid_acc= 0.5312          \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Fully Train the Model\n",
    "Now that you got a good accuracy with a single CIFAR-10 batch, try it with all five batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  cost= 2.3039           train_acc= 0.0878           valid_acc= 0.0998          \n",
      "Epoch  1, CIFAR-10 Batch 2:  cost= 2.3046           train_acc= 0.1047           valid_acc= 0.0998          \n",
      "Epoch  1, CIFAR-10 Batch 3:  cost= 2.3025           train_acc= 0.0743           valid_acc= 0.0998          \n",
      "Epoch  1, CIFAR-10 Batch 4:  cost= 2.3025           train_acc= 0.1047           valid_acc= 0.0942          \n",
      "Epoch  1, CIFAR-10 Batch 5:  cost= 2.2993           train_acc= 0.1182           valid_acc= 0.1104          \n",
      "Epoch  2, CIFAR-10 Batch 1:  cost= 2.3019           train_acc= 0.1047           valid_acc= 0.1062          \n",
      "Epoch  2, CIFAR-10 Batch 2:  cost= 2.2654           train_acc= 0.1588           valid_acc= 0.1440          \n",
      "Epoch  2, CIFAR-10 Batch 3:  cost= 2.1866           train_acc= 0.1520           valid_acc= 0.1580          \n",
      "Epoch  2, CIFAR-10 Batch 4:  cost= 2.1119           train_acc= 0.1689           valid_acc= 0.1678          \n",
      "Epoch  2, CIFAR-10 Batch 5:  cost= 2.1407           train_acc= 0.1520           valid_acc= 0.1548          \n",
      "Epoch  3, CIFAR-10 Batch 1:  cost= 2.2416           train_acc= 0.1486           valid_acc= 0.1782          \n",
      "Epoch  3, CIFAR-10 Batch 2:  cost= 2.0775           train_acc= 0.1689           valid_acc= 0.1880          \n",
      "Epoch  3, CIFAR-10 Batch 3:  cost= 2.0563           train_acc= 0.1655           valid_acc= 0.1874          \n",
      "Epoch  3, CIFAR-10 Batch 4:  cost= 2.1000           train_acc= 0.1520           valid_acc= 0.1828          \n",
      "Epoch  3, CIFAR-10 Batch 5:  cost= 2.0024           train_acc= 0.1993           valid_acc= 0.1824          \n",
      "Epoch  4, CIFAR-10 Batch 1:  cost= 2.0961           train_acc= 0.2264           valid_acc= 0.2184          \n",
      "Epoch  4, CIFAR-10 Batch 2:  cost= 1.9550           train_acc= 0.1791           valid_acc= 0.2308          \n",
      "Epoch  4, CIFAR-10 Batch 3:  cost= 2.0006           train_acc= 0.2736           valid_acc= 0.2296          \n",
      "Epoch  4, CIFAR-10 Batch 4:  cost= 1.8641           train_acc= 0.2669           valid_acc= 0.2830          \n",
      "Epoch  4, CIFAR-10 Batch 5:  cost= 1.9714           train_acc= 0.2365           valid_acc= 0.2288          \n",
      "Epoch  5, CIFAR-10 Batch 1:  cost= 2.0245           train_acc= 0.2264           valid_acc= 0.2710          \n",
      "Epoch  5, CIFAR-10 Batch 2:  cost= 1.9196           train_acc= 0.2264           valid_acc= 0.2670          \n",
      "Epoch  5, CIFAR-10 Batch 3:  cost= 1.8897           train_acc= 0.2905           valid_acc= 0.2906          \n",
      "Epoch  5, CIFAR-10 Batch 4:  cost= 1.8640           train_acc= 0.3108           valid_acc= 0.2962          \n",
      "Epoch  5, CIFAR-10 Batch 5:  cost= 1.8585           train_acc= 0.3209           valid_acc= 0.2854          \n",
      "Epoch  6, CIFAR-10 Batch 1:  cost= 1.8804           train_acc= 0.2669           valid_acc= 0.3160          \n",
      "Epoch  6, CIFAR-10 Batch 2:  cost= 1.8916           train_acc= 0.2838           valid_acc= 0.3108          \n",
      "Epoch  6, CIFAR-10 Batch 3:  cost= 1.7112           train_acc= 0.3682           valid_acc= 0.3164          \n",
      "Epoch  6, CIFAR-10 Batch 4:  cost= 1.7792           train_acc= 0.3176           valid_acc= 0.3136          \n",
      "Epoch  6, CIFAR-10 Batch 5:  cost= 1.7725           train_acc= 0.3615           valid_acc= 0.3286          \n",
      "Epoch  7, CIFAR-10 Batch 1:  cost= 1.9158           train_acc= 0.2365           valid_acc= 0.3062          \n",
      "Epoch  7, CIFAR-10 Batch 2:  cost= 1.8208           train_acc= 0.2804           valid_acc= 0.3238          \n",
      "Epoch  7, CIFAR-10 Batch 3:  cost= 1.7136           train_acc= 0.3649           valid_acc= 0.3186          \n",
      "Epoch  7, CIFAR-10 Batch 4:  cost= 1.7955           train_acc= 0.3007           valid_acc= 0.3020          \n",
      "Epoch  7, CIFAR-10 Batch 5:  cost= 1.7666           train_acc= 0.3446           valid_acc= 0.3350          \n",
      "Epoch  8, CIFAR-10 Batch 1:  cost= 1.9192           train_acc= 0.2635           valid_acc= 0.3060          \n",
      "Epoch  8, CIFAR-10 Batch 2:  cost= 1.8126           train_acc= 0.2703           valid_acc= 0.3254          \n",
      "Epoch  8, CIFAR-10 Batch 3:  cost= 1.6352           train_acc= 0.3953           valid_acc= 0.3466          \n",
      "Epoch  8, CIFAR-10 Batch 4:  cost= 1.7003           train_acc= 0.3412           valid_acc= 0.3334          \n",
      "Epoch  8, CIFAR-10 Batch 5:  cost= 1.7225           train_acc= 0.3311           valid_acc= 0.3414          \n",
      "Epoch  9, CIFAR-10 Batch 1:  cost= 1.7600           train_acc= 0.3311           valid_acc= 0.3538          \n",
      "Epoch  9, CIFAR-10 Batch 2:  cost= 1.9191           train_acc= 0.2399           valid_acc= 0.2942          \n",
      "Epoch  9, CIFAR-10 Batch 3:  cost= 1.7477           train_acc= 0.3378           valid_acc= 0.3210          \n",
      "Epoch  9, CIFAR-10 Batch 4:  cost= 1.6419           train_acc= 0.3682           valid_acc= 0.3524          \n",
      "Epoch  9, CIFAR-10 Batch 5:  cost= 1.7233           train_acc= 0.3581           valid_acc= 0.3438          \n",
      "Epoch 10, CIFAR-10 Batch 1:  cost= 1.8794           train_acc= 0.2635           valid_acc= 0.3168          \n",
      "Epoch 10, CIFAR-10 Batch 2:  cost= 1.7648           train_acc= 0.3108           valid_acc= 0.3542          \n",
      "Epoch 10, CIFAR-10 Batch 3:  cost= 1.6612           train_acc= 0.3851           valid_acc= 0.3546          \n",
      "Epoch 10, CIFAR-10 Batch 4:  cost= 1.6121           train_acc= 0.4054           valid_acc= 0.3818          \n",
      "Epoch 10, CIFAR-10 Batch 5:  cost= 1.6238           train_acc= 0.3649           valid_acc= 0.3736          \n",
      "Epoch 11, CIFAR-10 Batch 1:  cost= 1.7519           train_acc= 0.3041           valid_acc= 0.3606          \n",
      "Epoch 11, CIFAR-10 Batch 2:  cost= 1.7302           train_acc= 0.3041           valid_acc= 0.3694          \n",
      "Epoch 11, CIFAR-10 Batch 3:  cost= 1.5372           train_acc= 0.4054           valid_acc= 0.3884          \n",
      "Epoch 11, CIFAR-10 Batch 4:  cost= 1.6045           train_acc= 0.3649           valid_acc= 0.3640          \n",
      "Epoch 11, CIFAR-10 Batch 5:  cost= 1.6398           train_acc= 0.3851           valid_acc= 0.3784          \n",
      "Epoch 12, CIFAR-10 Batch 1:  cost= 1.6996           train_acc= 0.3311           valid_acc= 0.3794          \n",
      "Epoch 12, CIFAR-10 Batch 2:  cost= 1.7868           train_acc= 0.2939           valid_acc= 0.3518          \n",
      "Epoch 12, CIFAR-10 Batch 3:  cost= 1.5593           train_acc= 0.4189           valid_acc= 0.3798          \n",
      "Epoch 12, CIFAR-10 Batch 4:  cost= 1.5684           train_acc= 0.4122           valid_acc= 0.3812          \n",
      "Epoch 12, CIFAR-10 Batch 5:  cost= 1.5681           train_acc= 0.3986           valid_acc= 0.3946          \n",
      "Epoch 13, CIFAR-10 Batch 1:  cost= 1.6770           train_acc= 0.3480           valid_acc= 0.3876          \n",
      "Epoch 13, CIFAR-10 Batch 2:  cost= 1.7006           train_acc= 0.3108           valid_acc= 0.3876          \n",
      "Epoch 13, CIFAR-10 Batch 3:  cost= 1.5430           train_acc= 0.4257           valid_acc= 0.3872          \n",
      "Epoch 13, CIFAR-10 Batch 4:  cost= 1.5424           train_acc= 0.4189           valid_acc= 0.3860          \n",
      "Epoch 13, CIFAR-10 Batch 5:  cost= 1.5917           train_acc= 0.3953           valid_acc= 0.4022          \n",
      "Epoch 14, CIFAR-10 Batch 1:  cost= 1.7244           train_acc= 0.3345           valid_acc= 0.3730          \n",
      "Epoch 14, CIFAR-10 Batch 2:  cost= 1.7474           train_acc= 0.3277           valid_acc= 0.3672          \n",
      "Epoch 14, CIFAR-10 Batch 3:  cost= 1.5136           train_acc= 0.4291           valid_acc= 0.3940          \n",
      "Epoch 14, CIFAR-10 Batch 4:  cost= 1.5153           train_acc= 0.4358           valid_acc= 0.4148          \n",
      "Epoch 14, CIFAR-10 Batch 5:  cost= 1.4371           train_acc= 0.4696           valid_acc= 0.4470          \n",
      "Epoch 15, CIFAR-10 Batch 1:  cost= 1.5789           train_acc= 0.3750           valid_acc= 0.4280          \n",
      "Epoch 15, CIFAR-10 Batch 2:  cost= 1.5911           train_acc= 0.3851           valid_acc= 0.4180          \n",
      "Epoch 15, CIFAR-10 Batch 3:  cost= 1.5576           train_acc= 0.4595           valid_acc= 0.3948          \n",
      "Epoch 15, CIFAR-10 Batch 4:  cost= 1.5513           train_acc= 0.4257           valid_acc= 0.3922          \n",
      "Epoch 15, CIFAR-10 Batch 5:  cost= 1.5088           train_acc= 0.4122           valid_acc= 0.4292          \n",
      "Epoch 16, CIFAR-10 Batch 1:  cost= 1.6499           train_acc= 0.3378           valid_acc= 0.3990          \n",
      "Epoch 16, CIFAR-10 Batch 2:  cost= 1.6321           train_acc= 0.3615           valid_acc= 0.4116          \n",
      "Epoch 16, CIFAR-10 Batch 3:  cost= 1.4544           train_acc= 0.4730           valid_acc= 0.4272          \n",
      "Epoch 16, CIFAR-10 Batch 4:  cost= 1.4137           train_acc= 0.4595           valid_acc= 0.4356          \n",
      "Epoch 16, CIFAR-10 Batch 5:  cost= 1.5018           train_acc= 0.4392           valid_acc= 0.4338          \n",
      "Epoch 17, CIFAR-10 Batch 1:  cost= 1.5780           train_acc= 0.3919           valid_acc= 0.4334          \n",
      "Epoch 17, CIFAR-10 Batch 2:  cost= 1.5597           train_acc= 0.3986           valid_acc= 0.4442          \n",
      "Epoch 17, CIFAR-10 Batch 3:  cost= 1.4215           train_acc= 0.4459           valid_acc= 0.4236          \n",
      "Epoch 17, CIFAR-10 Batch 4:  cost= 1.4427           train_acc= 0.4561           valid_acc= 0.4390          \n",
      "Epoch 17, CIFAR-10 Batch 5:  cost= 1.4307           train_acc= 0.4662           valid_acc= 0.4632          \n",
      "Epoch 18, CIFAR-10 Batch 1:  cost= 1.5393           train_acc= 0.4155           valid_acc= 0.4570          \n",
      "Epoch 18, CIFAR-10 Batch 2:  cost= 1.4779           train_acc= 0.4088           valid_acc= 0.4568          \n",
      "Epoch 18, CIFAR-10 Batch 3:  cost= 1.4551           train_acc= 0.4696           valid_acc= 0.4328          \n",
      "Epoch 18, CIFAR-10 Batch 4:  cost= 1.3873           train_acc= 0.4865           valid_acc= 0.4460          \n",
      "Epoch 18, CIFAR-10 Batch 5:  cost= 1.4036           train_acc= 0.4966           valid_acc= 0.4644          \n",
      "Epoch 19, CIFAR-10 Batch 1:  cost= 1.5468           train_acc= 0.4020           valid_acc= 0.4472          \n",
      "Epoch 19, CIFAR-10 Batch 2:  cost= 1.5538           train_acc= 0.3885           valid_acc= 0.4350          \n",
      "Epoch 19, CIFAR-10 Batch 3:  cost= 1.3471           train_acc= 0.5068           valid_acc= 0.4656          \n",
      "Epoch 19, CIFAR-10 Batch 4:  cost= 1.3993           train_acc= 0.5068           valid_acc= 0.4488          \n",
      "Epoch 19, CIFAR-10 Batch 5:  cost= 1.4060           train_acc= 0.4831           valid_acc= 0.4670          \n",
      "Epoch 20, CIFAR-10 Batch 1:  cost= 1.5213           train_acc= 0.4257           valid_acc= 0.4660          \n",
      "Epoch 20, CIFAR-10 Batch 2:  cost= 1.5529           train_acc= 0.3851           valid_acc= 0.4430          \n",
      "Epoch 20, CIFAR-10 Batch 3:  cost= 1.3864           train_acc= 0.4899           valid_acc= 0.4502          \n",
      "Epoch 20, CIFAR-10 Batch 4:  cost= 1.3393           train_acc= 0.4865           valid_acc= 0.4704          \n",
      "Epoch 20, CIFAR-10 Batch 5:  cost= 1.3671           train_acc= 0.5101           valid_acc= 0.4804          \n",
      "Epoch 21, CIFAR-10 Batch 1:  cost= 1.5184           train_acc= 0.4155           valid_acc= 0.4756          \n",
      "Epoch 21, CIFAR-10 Batch 2:  cost= 1.5813           train_acc= 0.3818           valid_acc= 0.4398          \n",
      "Epoch 21, CIFAR-10 Batch 3:  cost= 1.3532           train_acc= 0.4865           valid_acc= 0.4624          \n",
      "Epoch 21, CIFAR-10 Batch 4:  cost= 1.3535           train_acc= 0.4831           valid_acc= 0.4566          \n",
      "Epoch 21, CIFAR-10 Batch 5:  cost= 1.3646           train_acc= 0.5203           valid_acc= 0.4834          \n",
      "Epoch 22, CIFAR-10 Batch 1:  cost= 1.4693           train_acc= 0.4392           valid_acc= 0.4738          \n",
      "Epoch 22, CIFAR-10 Batch 2:  cost= 1.5935           train_acc= 0.3851           valid_acc= 0.4300          \n",
      "Epoch 22, CIFAR-10 Batch 3:  cost= 1.3520           train_acc= 0.5034           valid_acc= 0.4570          \n",
      "Epoch 22, CIFAR-10 Batch 4:  cost= 1.3488           train_acc= 0.5236           valid_acc= 0.4652          \n",
      "Epoch 22, CIFAR-10 Batch 5:  cost= 1.3747           train_acc= 0.5068           valid_acc= 0.4894          \n",
      "Epoch 23, CIFAR-10 Batch 1:  cost= 1.4940           train_acc= 0.3986           valid_acc= 0.4680          \n",
      "Epoch 23, CIFAR-10 Batch 2:  cost= 1.5321           train_acc= 0.4291           valid_acc= 0.4576          \n",
      "Epoch 23, CIFAR-10 Batch 3:  cost= 1.3236           train_acc= 0.5068           valid_acc= 0.4660          \n",
      "Epoch 23, CIFAR-10 Batch 4:  cost= 1.3259           train_acc= 0.5236           valid_acc= 0.4814          \n",
      "Epoch 23, CIFAR-10 Batch 5:  cost= 1.3732           train_acc= 0.4764           valid_acc= 0.4766          \n",
      "Epoch 24, CIFAR-10 Batch 1:  cost= 1.4487           train_acc= 0.4426           valid_acc= 0.5050          \n",
      "Epoch 24, CIFAR-10 Batch 2:  cost= 1.5104           train_acc= 0.4392           valid_acc= 0.4638          \n",
      "Epoch 24, CIFAR-10 Batch 3:  cost= 1.3206           train_acc= 0.5034           valid_acc= 0.4742          \n",
      "Epoch 24, CIFAR-10 Batch 4:  cost= 1.3512           train_acc= 0.4966           valid_acc= 0.4788          \n",
      "Epoch 24, CIFAR-10 Batch 5:  cost= 1.3516           train_acc= 0.5203           valid_acc= 0.4840          \n",
      "Epoch 25, CIFAR-10 Batch 1:  cost= 1.4568           train_acc= 0.4527           valid_acc= 0.4878          \n",
      "Epoch 25, CIFAR-10 Batch 2:  cost= 1.4864           train_acc= 0.4392           valid_acc= 0.4638          \n",
      "Epoch 25, CIFAR-10 Batch 3:  cost= 1.3363           train_acc= 0.4831           valid_acc= 0.4628          \n",
      "Epoch 25, CIFAR-10 Batch 4:  cost= 1.3392           train_acc= 0.5068           valid_acc= 0.4814          \n",
      "Epoch 25, CIFAR-10 Batch 5:  cost= 1.3836           train_acc= 0.5000           valid_acc= 0.4728          \n",
      "Epoch 26, CIFAR-10 Batch 1:  cost= 1.4330           train_acc= 0.4797           valid_acc= 0.5016          \n",
      "Epoch 26, CIFAR-10 Batch 2:  cost= 1.5191           train_acc= 0.4358           valid_acc= 0.4558          \n",
      "Epoch 26, CIFAR-10 Batch 3:  cost= 1.2775           train_acc= 0.5372           valid_acc= 0.4868          \n",
      "Epoch 26, CIFAR-10 Batch 4:  cost= 1.2745           train_acc= 0.5338           valid_acc= 0.5072          \n",
      "Epoch 26, CIFAR-10 Batch 5:  cost= 1.3483           train_acc= 0.5000           valid_acc= 0.4846          \n",
      "Epoch 27, CIFAR-10 Batch 1:  cost= 1.4485           train_acc= 0.4595           valid_acc= 0.4990          \n",
      "Epoch 27, CIFAR-10 Batch 2:  cost= 1.4197           train_acc= 0.4595           valid_acc= 0.4870          \n",
      "Epoch 27, CIFAR-10 Batch 3:  cost= 1.3752           train_acc= 0.4730           valid_acc= 0.4524          \n",
      "Epoch 27, CIFAR-10 Batch 4:  cost= 1.2393           train_acc= 0.5642           valid_acc= 0.5132          \n",
      "Epoch 27, CIFAR-10 Batch 5:  cost= 1.3264           train_acc= 0.5236           valid_acc= 0.4886          \n",
      "Epoch 28, CIFAR-10 Batch 1:  cost= 1.4003           train_acc= 0.4932           valid_acc= 0.5104          \n",
      "Epoch 28, CIFAR-10 Batch 2:  cost= 1.5517           train_acc= 0.4493           valid_acc= 0.4574          \n",
      "Epoch 28, CIFAR-10 Batch 3:  cost= 1.3069           train_acc= 0.5236           valid_acc= 0.4742          \n",
      "Epoch 28, CIFAR-10 Batch 4:  cost= 1.2252           train_acc= 0.5608           valid_acc= 0.5128          \n",
      "Epoch 28, CIFAR-10 Batch 5:  cost= 1.2958           train_acc= 0.5304           valid_acc= 0.4924          \n",
      "Epoch 29, CIFAR-10 Batch 1:  cost= 1.4067           train_acc= 0.4764           valid_acc= 0.5018          \n",
      "Epoch 29, CIFAR-10 Batch 2:  cost= 1.4335           train_acc= 0.4595           valid_acc= 0.4874          \n",
      "Epoch 29, CIFAR-10 Batch 3:  cost= 1.3059           train_acc= 0.5304           valid_acc= 0.4794          \n",
      "Epoch 29, CIFAR-10 Batch 4:  cost= 1.2475           train_acc= 0.5541           valid_acc= 0.5092          \n",
      "Epoch 29, CIFAR-10 Batch 5:  cost= 1.2890           train_acc= 0.5203           valid_acc= 0.5012          \n",
      "Epoch 30, CIFAR-10 Batch 1:  cost= 1.3897           train_acc= 0.4899           valid_acc= 0.5216          \n",
      "Epoch 30, CIFAR-10 Batch 2:  cost= 1.4473           train_acc= 0.4392           valid_acc= 0.4896          \n",
      "Epoch 30, CIFAR-10 Batch 3:  cost= 1.3174           train_acc= 0.5169           valid_acc= 0.4616          \n",
      "Epoch 30, CIFAR-10 Batch 4:  cost= 1.2319           train_acc= 0.5507           valid_acc= 0.5168          \n",
      "Epoch 30, CIFAR-10 Batch 5:  cost= 1.3015           train_acc= 0.5236           valid_acc= 0.5062          \n",
      "Epoch 31, CIFAR-10 Batch 1:  cost= 1.3844           train_acc= 0.4932           valid_acc= 0.5134          \n",
      "Epoch 31, CIFAR-10 Batch 2:  cost= 1.4460           train_acc= 0.4493           valid_acc= 0.4764          \n",
      "Epoch 31, CIFAR-10 Batch 3:  cost= 1.2708           train_acc= 0.5338           valid_acc= 0.4936          \n",
      "Epoch 31, CIFAR-10 Batch 4:  cost= 1.2636           train_acc= 0.5372           valid_acc= 0.5010          \n",
      "Epoch 31, CIFAR-10 Batch 5:  cost= 1.3054           train_acc= 0.5270           valid_acc= 0.4944          \n",
      "Epoch 32, CIFAR-10 Batch 1:  cost= 1.4107           train_acc= 0.5000           valid_acc= 0.5238          \n",
      "Epoch 32, CIFAR-10 Batch 2:  cost= 1.4002           train_acc= 0.4797           valid_acc= 0.4962          \n",
      "Epoch 32, CIFAR-10 Batch 3:  cost= 1.2528           train_acc= 0.5473           valid_acc= 0.4976          \n",
      "Epoch 32, CIFAR-10 Batch 4:  cost= 1.2447           train_acc= 0.5338           valid_acc= 0.5212          \n",
      "Epoch 32, CIFAR-10 Batch 5:  cost= 1.3048           train_acc= 0.5507           valid_acc= 0.4874          \n",
      "Epoch 33, CIFAR-10 Batch 1:  cost= 1.3990           train_acc= 0.4831           valid_acc= 0.5112          \n",
      "Epoch 33, CIFAR-10 Batch 2:  cost= 1.3576           train_acc= 0.5034           valid_acc= 0.5150          \n",
      "Epoch 33, CIFAR-10 Batch 3:  cost= 1.2389           train_acc= 0.5338           valid_acc= 0.4996          \n",
      "Epoch 33, CIFAR-10 Batch 4:  cost= 1.2259           train_acc= 0.5608           valid_acc= 0.5148          \n",
      "Epoch 33, CIFAR-10 Batch 5:  cost= 1.2502           train_acc= 0.5541           valid_acc= 0.5012          \n",
      "Epoch 34, CIFAR-10 Batch 1:  cost= 1.3443           train_acc= 0.5000           valid_acc= 0.5254          \n",
      "Epoch 34, CIFAR-10 Batch 2:  cost= 1.3646           train_acc= 0.4662           valid_acc= 0.5118          \n",
      "Epoch 34, CIFAR-10 Batch 3:  cost= 1.2489           train_acc= 0.5507           valid_acc= 0.4904          \n",
      "Epoch 34, CIFAR-10 Batch 4:  cost= 1.2511           train_acc= 0.5507           valid_acc= 0.5062          \n",
      "Epoch 34, CIFAR-10 Batch 5:  cost= 1.2520           train_acc= 0.5743           valid_acc= 0.5124          \n",
      "Epoch 35, CIFAR-10 Batch 1:  cost= 1.3554           train_acc= 0.5270           valid_acc= 0.5318          \n",
      "Epoch 35, CIFAR-10 Batch 2:  cost= 1.4683           train_acc= 0.4561           valid_acc= 0.4744          \n",
      "Epoch 35, CIFAR-10 Batch 3:  cost= 1.2385           train_acc= 0.5169           valid_acc= 0.4926          \n",
      "Epoch 35, CIFAR-10 Batch 4:  cost= 1.2085           train_acc= 0.5439           valid_acc= 0.5162          \n",
      "Epoch 35, CIFAR-10 Batch 5:  cost= 1.2419           train_acc= 0.5608           valid_acc= 0.5000          \n",
      "Epoch 36, CIFAR-10 Batch 1:  cost= 1.3516           train_acc= 0.5135           valid_acc= 0.5370          \n",
      "Epoch 36, CIFAR-10 Batch 2:  cost= 1.4270           train_acc= 0.4628           valid_acc= 0.4898          \n",
      "Epoch 36, CIFAR-10 Batch 3:  cost= 1.2107           train_acc= 0.5743           valid_acc= 0.5032          \n",
      "Epoch 36, CIFAR-10 Batch 4:  cost= 1.2052           train_acc= 0.5473           valid_acc= 0.5216          \n",
      "Epoch 36, CIFAR-10 Batch 5:  cost= 1.2330           train_acc= 0.5642           valid_acc= 0.5120          \n",
      "Epoch 37, CIFAR-10 Batch 1:  cost= 1.3076           train_acc= 0.5439           valid_acc= 0.5432          \n",
      "Epoch 37, CIFAR-10 Batch 2:  cost= 1.3860           train_acc= 0.4899           valid_acc= 0.4982          \n",
      "Epoch 37, CIFAR-10 Batch 3:  cost= 1.2226           train_acc= 0.5676           valid_acc= 0.4978          \n",
      "Epoch 37, CIFAR-10 Batch 4:  cost= 1.2025           train_acc= 0.5338           valid_acc= 0.5244          \n",
      "Epoch 37, CIFAR-10 Batch 5:  cost= 1.2865           train_acc= 0.5439           valid_acc= 0.5094          \n",
      "Epoch 38, CIFAR-10 Batch 1:  cost= 1.3529           train_acc= 0.5000           valid_acc= 0.5232          \n",
      "Epoch 38, CIFAR-10 Batch 2:  cost= 1.3504           train_acc= 0.5034           valid_acc= 0.5124          \n",
      "Epoch 38, CIFAR-10 Batch 3:  cost= 1.2764           train_acc= 0.5068           valid_acc= 0.4790          \n",
      "Epoch 38, CIFAR-10 Batch 4:  cost= 1.1758           train_acc= 0.5743           valid_acc= 0.5364          \n",
      "Epoch 38, CIFAR-10 Batch 5:  cost= 1.2650           train_acc= 0.5439           valid_acc= 0.5014          \n",
      "Epoch 39, CIFAR-10 Batch 1:  cost= 1.3672           train_acc= 0.5101           valid_acc= 0.5404          \n",
      "Epoch 39, CIFAR-10 Batch 2:  cost= 1.3573           train_acc= 0.5034           valid_acc= 0.5052          \n",
      "Epoch 39, CIFAR-10 Batch 3:  cost= 1.2093           train_acc= 0.5676           valid_acc= 0.5096          \n",
      "Epoch 39, CIFAR-10 Batch 4:  cost= 1.2110           train_acc= 0.5439           valid_acc= 0.5112          \n",
      "Epoch 39, CIFAR-10 Batch 5:  cost= 1.2208           train_acc= 0.5574           valid_acc= 0.5088          \n",
      "Epoch 40, CIFAR-10 Batch 1:  cost= 1.3603           train_acc= 0.5507           valid_acc= 0.5424          \n",
      "Epoch 40, CIFAR-10 Batch 2:  cost= 1.3782           train_acc= 0.4797           valid_acc= 0.5034          \n",
      "Epoch 40, CIFAR-10 Batch 3:  cost= 1.2452           train_acc= 0.5270           valid_acc= 0.4934          \n",
      "Epoch 40, CIFAR-10 Batch 4:  cost= 1.1832           train_acc= 0.5709           valid_acc= 0.5276          \n",
      "Epoch 40, CIFAR-10 Batch 5:  cost= 1.2618           train_acc= 0.5676           valid_acc= 0.5080          \n",
      "Epoch 41, CIFAR-10 Batch 1:  cost= 1.3446           train_acc= 0.5405           valid_acc= 0.5456          \n",
      "Epoch 41, CIFAR-10 Batch 2:  cost= 1.3678           train_acc= 0.4932           valid_acc= 0.5062          \n",
      "Epoch 41, CIFAR-10 Batch 3:  cost= 1.2465           train_acc= 0.5473           valid_acc= 0.4990          \n",
      "Epoch 41, CIFAR-10 Batch 4:  cost= 1.1643           train_acc= 0.5541           valid_acc= 0.5306          \n",
      "Epoch 41, CIFAR-10 Batch 5:  cost= 1.2855           train_acc= 0.5169           valid_acc= 0.4998          \n",
      "Epoch 42, CIFAR-10 Batch 1:  cost= 1.2653           train_acc= 0.5574           valid_acc= 0.5478          \n",
      "Epoch 42, CIFAR-10 Batch 2:  cost= 1.3192           train_acc= 0.4932           valid_acc= 0.5166          \n",
      "Epoch 42, CIFAR-10 Batch 3:  cost= 1.1875           train_acc= 0.5473           valid_acc= 0.5190          \n",
      "Epoch 42, CIFAR-10 Batch 4:  cost= 1.1565           train_acc= 0.5777           valid_acc= 0.5380          \n",
      "Epoch 42, CIFAR-10 Batch 5:  cost= 1.1780           train_acc= 0.5878           valid_acc= 0.5408          \n",
      "Epoch 43, CIFAR-10 Batch 1:  cost= 1.2958           train_acc= 0.5541           valid_acc= 0.5480          \n",
      "Epoch 43, CIFAR-10 Batch 2:  cost= 1.3754           train_acc= 0.5034           valid_acc= 0.4918          \n",
      "Epoch 43, CIFAR-10 Batch 3:  cost= 1.2421           train_acc= 0.5338           valid_acc= 0.4894          \n",
      "Epoch 43, CIFAR-10 Batch 4:  cost= 1.1374           train_acc= 0.5878           valid_acc= 0.5418          \n",
      "Epoch 43, CIFAR-10 Batch 5:  cost= 1.2358           train_acc= 0.5676           valid_acc= 0.5108          \n",
      "Epoch 44, CIFAR-10 Batch 1:  cost= 1.2829           train_acc= 0.5473           valid_acc= 0.5536          \n",
      "Epoch 44, CIFAR-10 Batch 2:  cost= 1.3462           train_acc= 0.5236           valid_acc= 0.5146          \n",
      "Epoch 44, CIFAR-10 Batch 3:  cost= 1.2328           train_acc= 0.5405           valid_acc= 0.5024          \n",
      "Epoch 44, CIFAR-10 Batch 4:  cost= 1.1731           train_acc= 0.5642           valid_acc= 0.5460          \n",
      "Epoch 44, CIFAR-10 Batch 5:  cost= 1.1815           train_acc= 0.5676           valid_acc= 0.5272          \n",
      "Epoch 45, CIFAR-10 Batch 1:  cost= 1.3088           train_acc= 0.5338           valid_acc= 0.5430          \n",
      "Epoch 45, CIFAR-10 Batch 2:  cost= 1.3389           train_acc= 0.5068           valid_acc= 0.5202          \n",
      "Epoch 45, CIFAR-10 Batch 3:  cost= 1.1900           train_acc= 0.5541           valid_acc= 0.5228          \n",
      "Epoch 45, CIFAR-10 Batch 4:  cost= 1.1502           train_acc= 0.5845           valid_acc= 0.5364          \n",
      "Epoch 45, CIFAR-10 Batch 5:  cost= 1.2439           train_acc= 0.5608           valid_acc= 0.5132          \n",
      "Epoch 46, CIFAR-10 Batch 1:  cost= 1.3039           train_acc= 0.5236           valid_acc= 0.5454          \n",
      "Epoch 46, CIFAR-10 Batch 2:  cost= 1.2916           train_acc= 0.5608           valid_acc= 0.5368          \n",
      "Epoch 46, CIFAR-10 Batch 3:  cost= 1.1989           train_acc= 0.5912           valid_acc= 0.5084          \n",
      "Epoch 46, CIFAR-10 Batch 4:  cost= 1.1956           train_acc= 0.5777           valid_acc= 0.5276          \n",
      "Epoch 46, CIFAR-10 Batch 5:  cost= 1.2219           train_acc= 0.5304           valid_acc= 0.5108          \n",
      "Epoch 47, CIFAR-10 Batch 1:  cost= 1.2925           train_acc= 0.5405           valid_acc= 0.5432          \n",
      "Epoch 47, CIFAR-10 Batch 2:  cost= 1.2758           train_acc= 0.5236           valid_acc= 0.5424          \n",
      "Epoch 47, CIFAR-10 Batch 3:  cost= 1.1612           train_acc= 0.5878           valid_acc= 0.5258          \n",
      "Epoch 47, CIFAR-10 Batch 4:  cost= 1.1556           train_acc= 0.5676           valid_acc= 0.5276          \n",
      "Epoch 47, CIFAR-10 Batch 5:  cost= 1.2051           train_acc= 0.5676           valid_acc= 0.5272          \n",
      "Epoch 48, CIFAR-10 Batch 1:  cost= 1.2605           train_acc= 0.5507           valid_acc= 0.5516          \n",
      "Epoch 48, CIFAR-10 Batch 2:  cost= 1.3436           train_acc= 0.4966           valid_acc= 0.5032          \n",
      "Epoch 48, CIFAR-10 Batch 3:  cost= 1.1535           train_acc= 0.5676           valid_acc= 0.5240          \n",
      "Epoch 48, CIFAR-10 Batch 4:  cost= 1.1741           train_acc= 0.6014           valid_acc= 0.5216          \n",
      "Epoch 48, CIFAR-10 Batch 5:  cost= 1.1967           train_acc= 0.5507           valid_acc= 0.5294          \n",
      "Epoch 49, CIFAR-10 Batch 1:  cost= 1.2590           train_acc= 0.5777           valid_acc= 0.5640          \n",
      "Epoch 49, CIFAR-10 Batch 2:  cost= 1.2517           train_acc= 0.5507           valid_acc= 0.5350          \n",
      "Epoch 49, CIFAR-10 Batch 3:  cost= 1.2451           train_acc= 0.5372           valid_acc= 0.4924          \n",
      "Epoch 49, CIFAR-10 Batch 4:  cost= 1.1727           train_acc= 0.5676           valid_acc= 0.5324          \n",
      "Epoch 49, CIFAR-10 Batch 5:  cost= 1.2486           train_acc= 0.5338           valid_acc= 0.5036          \n",
      "Epoch 50, CIFAR-10 Batch 1:  cost= 1.3111           train_acc= 0.5541           valid_acc= 0.5356          \n",
      "Epoch 50, CIFAR-10 Batch 2:  cost= 1.2633           train_acc= 0.5439           valid_acc= 0.5362          \n",
      "Epoch 50, CIFAR-10 Batch 3:  cost= 1.2066           train_acc= 0.5743           valid_acc= 0.5110          \n",
      "Epoch 50, CIFAR-10 Batch 4:  cost= 1.1300           train_acc= 0.5912           valid_acc= 0.5382          \n",
      "Epoch 50, CIFAR-10 Batch 5:  cost= 1.1392           train_acc= 0.5811           valid_acc= 0.5396          \n",
      "Epoch 51, CIFAR-10 Batch 1:  cost= 1.3075           train_acc= 0.5439           valid_acc= 0.5458          \n",
      "Epoch 51, CIFAR-10 Batch 2:  cost= 1.3880           train_acc= 0.4696           valid_acc= 0.4814          \n",
      "Epoch 51, CIFAR-10 Batch 3:  cost= 1.1953           train_acc= 0.5507           valid_acc= 0.5144          \n",
      "Epoch 51, CIFAR-10 Batch 4:  cost= 1.1112           train_acc= 0.6115           valid_acc= 0.5482          \n",
      "Epoch 51, CIFAR-10 Batch 5:  cost= 1.2002           train_acc= 0.5743           valid_acc= 0.5318          \n",
      "Epoch 52, CIFAR-10 Batch 1:  cost= 1.3554           train_acc= 0.5203           valid_acc= 0.5456          \n",
      "Epoch 52, CIFAR-10 Batch 2:  cost= 1.3088           train_acc= 0.5135           valid_acc= 0.5242          \n",
      "Epoch 52, CIFAR-10 Batch 3:  cost= 1.1695           train_acc= 0.5743           valid_acc= 0.5212          \n",
      "Epoch 52, CIFAR-10 Batch 4:  cost= 1.1414           train_acc= 0.6216           valid_acc= 0.5404          \n",
      "Epoch 52, CIFAR-10 Batch 5:  cost= 1.1880           train_acc= 0.5777           valid_acc= 0.5372          \n",
      "Epoch 53, CIFAR-10 Batch 1:  cost= 1.2904           train_acc= 0.5541           valid_acc= 0.5618          \n",
      "Epoch 53, CIFAR-10 Batch 2:  cost= 1.2951           train_acc= 0.5203           valid_acc= 0.5346          \n",
      "Epoch 53, CIFAR-10 Batch 3:  cost= 1.2176           train_acc= 0.5574           valid_acc= 0.5062          \n",
      "Epoch 53, CIFAR-10 Batch 4:  cost= 1.1420           train_acc= 0.6115           valid_acc= 0.5364          \n",
      "Epoch 53, CIFAR-10 Batch 5:  cost= 1.2002           train_acc= 0.5608           valid_acc= 0.5230          \n",
      "Epoch 54, CIFAR-10 Batch 1:  cost= 1.2963           train_acc= 0.5574           valid_acc= 0.5498          \n",
      "Epoch 54, CIFAR-10 Batch 2:  cost= 1.2891           train_acc= 0.5135           valid_acc= 0.5302          \n",
      "Epoch 54, CIFAR-10 Batch 3:  cost= 1.2117           train_acc= 0.5473           valid_acc= 0.4890          \n",
      "Epoch 54, CIFAR-10 Batch 4:  cost= 1.1082           train_acc= 0.5777           valid_acc= 0.5392          \n",
      "Epoch 54, CIFAR-10 Batch 5:  cost= 1.1743           train_acc= 0.5811           valid_acc= 0.5326          \n",
      "Epoch 55, CIFAR-10 Batch 1:  cost= 1.2875           train_acc= 0.5507           valid_acc= 0.5524          \n",
      "Epoch 55, CIFAR-10 Batch 2:  cost= 1.2398           train_acc= 0.5405           valid_acc= 0.5470          \n",
      "Epoch 55, CIFAR-10 Batch 3:  cost= 1.2181           train_acc= 0.5608           valid_acc= 0.5042          \n",
      "Epoch 55, CIFAR-10 Batch 4:  cost= 1.1579           train_acc= 0.5709           valid_acc= 0.5376          \n",
      "Epoch 55, CIFAR-10 Batch 5:  cost= 1.1420           train_acc= 0.5980           valid_acc= 0.5416          \n",
      "Epoch 56, CIFAR-10 Batch 1:  cost= 1.3267           train_acc= 0.5203           valid_acc= 0.5438          \n",
      "Epoch 56, CIFAR-10 Batch 2:  cost= 1.2888           train_acc= 0.5236           valid_acc= 0.5374          \n",
      "Epoch 56, CIFAR-10 Batch 3:  cost= 1.1449           train_acc= 0.5574           valid_acc= 0.5292          \n",
      "Epoch 56, CIFAR-10 Batch 4:  cost= 1.1320           train_acc= 0.6081           valid_acc= 0.5356          \n",
      "Epoch 56, CIFAR-10 Batch 5:  cost= 1.1626           train_acc= 0.5845           valid_acc= 0.5334          \n",
      "Epoch 57, CIFAR-10 Batch 1:  cost= 1.2368           train_acc= 0.5777           valid_acc= 0.5774          \n",
      "Epoch 57, CIFAR-10 Batch 2:  cost= 1.2413           train_acc= 0.5439           valid_acc= 0.5530          \n",
      "Epoch 57, CIFAR-10 Batch 3:  cost= 1.1958           train_acc= 0.5574           valid_acc= 0.5182          \n",
      "Epoch 57, CIFAR-10 Batch 4:  cost= 1.1392           train_acc= 0.6047           valid_acc= 0.5466          \n",
      "Epoch 57, CIFAR-10 Batch 5:  cost= 1.1940           train_acc= 0.5676           valid_acc= 0.5222          \n",
      "Epoch 58, CIFAR-10 Batch 1:  cost= 1.2845           train_acc= 0.5338           valid_acc= 0.5438          \n",
      "Epoch 58, CIFAR-10 Batch 2:  cost= 1.2693           train_acc= 0.5405           valid_acc= 0.5422          \n",
      "Epoch 58, CIFAR-10 Batch 3:  cost= 1.2056           train_acc= 0.5439           valid_acc= 0.5000          \n",
      "Epoch 58, CIFAR-10 Batch 4:  cost= 1.1301           train_acc= 0.5946           valid_acc= 0.5424          \n",
      "Epoch 58, CIFAR-10 Batch 5:  cost= 1.1015           train_acc= 0.5946           valid_acc= 0.5516          \n",
      "Epoch 59, CIFAR-10 Batch 1:  cost= 1.2980           train_acc= 0.5473           valid_acc= 0.5392          \n",
      "Epoch 59, CIFAR-10 Batch 2:  cost= 1.2538           train_acc= 0.5405           valid_acc= 0.5384          \n",
      "Epoch 59, CIFAR-10 Batch 3:  cost= 1.1747           train_acc= 0.5743           valid_acc= 0.5210          \n",
      "Epoch 59, CIFAR-10 Batch 4:  cost= 1.1437           train_acc= 0.6115           valid_acc= 0.5372          \n",
      "Epoch 59, CIFAR-10 Batch 5:  cost= 1.1629           train_acc= 0.5709           valid_acc= 0.5338          \n",
      "Epoch 60, CIFAR-10 Batch 1:  cost= 1.2940           train_acc= 0.5507           valid_acc= 0.5506          \n",
      "Epoch 60, CIFAR-10 Batch 2:  cost= 1.2856           train_acc= 0.5304           valid_acc= 0.5286          \n",
      "Epoch 60, CIFAR-10 Batch 3:  cost= 1.1786           train_acc= 0.5405           valid_acc= 0.5102          \n",
      "Epoch 60, CIFAR-10 Batch 4:  cost= 1.0829           train_acc= 0.6250           valid_acc= 0.5546          \n",
      "Epoch 60, CIFAR-10 Batch 5:  cost= 1.1789           train_acc= 0.5709           valid_acc= 0.5252          \n",
      "Epoch 61, CIFAR-10 Batch 1:  cost= 1.2457           train_acc= 0.5676           valid_acc= 0.5688          \n",
      "Epoch 61, CIFAR-10 Batch 2:  cost= 1.2831           train_acc= 0.5338           valid_acc= 0.5234          \n",
      "Epoch 61, CIFAR-10 Batch 3:  cost= 1.2181           train_acc= 0.5372           valid_acc= 0.5060          \n",
      "Epoch 61, CIFAR-10 Batch 4:  cost= 1.1164           train_acc= 0.6385           valid_acc= 0.5442          \n",
      "Epoch 61, CIFAR-10 Batch 5:  cost= 1.1370           train_acc= 0.6014           valid_acc= 0.5474          \n",
      "Epoch 62, CIFAR-10 Batch 1:  cost= 1.2958           train_acc= 0.5372           valid_acc= 0.5538          \n",
      "Epoch 62, CIFAR-10 Batch 2:  cost= 1.2499           train_acc= 0.5203           valid_acc= 0.5366          \n",
      "Epoch 62, CIFAR-10 Batch 3:  cost= 1.1724           train_acc= 0.5541           valid_acc= 0.5310          \n",
      "Epoch 62, CIFAR-10 Batch 4:  cost= 1.0963           train_acc= 0.6216           valid_acc= 0.5456          \n",
      "Epoch 62, CIFAR-10 Batch 5:  cost= 1.1494           train_acc= 0.6047           valid_acc= 0.5366          \n",
      "Epoch 63, CIFAR-10 Batch 1:  cost= 1.2953           train_acc= 0.5236           valid_acc= 0.5592          \n",
      "Epoch 63, CIFAR-10 Batch 2:  cost= 1.2066           train_acc= 0.5709           valid_acc= 0.5566          \n",
      "Epoch 63, CIFAR-10 Batch 3:  cost= 1.1605           train_acc= 0.5439           valid_acc= 0.5246          \n",
      "Epoch 63, CIFAR-10 Batch 4:  cost= 1.1065           train_acc= 0.6115           valid_acc= 0.5492          \n",
      "Epoch 63, CIFAR-10 Batch 5:  cost= 1.1425           train_acc= 0.5878           valid_acc= 0.5354          \n",
      "Epoch 64, CIFAR-10 Batch 1:  cost= 1.2622           train_acc= 0.5439           valid_acc= 0.5660          \n",
      "Epoch 64, CIFAR-10 Batch 2:  cost= 1.3085           train_acc= 0.5203           valid_acc= 0.5256          \n",
      "Epoch 64, CIFAR-10 Batch 3:  cost= 1.2026           train_acc= 0.5541           valid_acc= 0.5066          \n",
      "Epoch 64, CIFAR-10 Batch 4:  cost= 1.0644           train_acc= 0.6115           valid_acc= 0.5554          \n",
      "Epoch 64, CIFAR-10 Batch 5:  cost= 1.1261           train_acc= 0.6081           valid_acc= 0.5460          \n",
      "Epoch 65, CIFAR-10 Batch 1:  cost= 1.2620           train_acc= 0.5676           valid_acc= 0.5646          \n",
      "Epoch 65, CIFAR-10 Batch 2:  cost= 1.2641           train_acc= 0.5608           valid_acc= 0.5334          \n",
      "Epoch 65, CIFAR-10 Batch 3:  cost= 1.1813           train_acc= 0.5439           valid_acc= 0.5118          \n",
      "Epoch 65, CIFAR-10 Batch 4:  cost= 1.1384           train_acc= 0.6081           valid_acc= 0.5388          \n",
      "Epoch 65, CIFAR-10 Batch 5:  cost= 1.1700           train_acc= 0.5743           valid_acc= 0.5196          \n",
      "Epoch 66, CIFAR-10 Batch 1:  cost= 1.2436           train_acc= 0.5642           valid_acc= 0.5610          \n",
      "Epoch 66, CIFAR-10 Batch 2:  cost= 1.2499           train_acc= 0.5608           valid_acc= 0.5400          \n",
      "Epoch 66, CIFAR-10 Batch 3:  cost= 1.1283           train_acc= 0.5608           valid_acc= 0.5292          \n",
      "Epoch 66, CIFAR-10 Batch 4:  cost= 1.1109           train_acc= 0.6216           valid_acc= 0.5456          \n",
      "Epoch 66, CIFAR-10 Batch 5:  cost= 1.1230           train_acc= 0.5946           valid_acc= 0.5484          \n",
      "Epoch 67, CIFAR-10 Batch 1:  cost= 1.2508           train_acc= 0.5507           valid_acc= 0.5648          \n",
      "Epoch 67, CIFAR-10 Batch 2:  cost= 1.2344           train_acc= 0.5507           valid_acc= 0.5416          \n",
      "Epoch 67, CIFAR-10 Batch 3:  cost= 1.1075           train_acc= 0.5980           valid_acc= 0.5432          \n",
      "Epoch 67, CIFAR-10 Batch 4:  cost= 1.1134           train_acc= 0.6149           valid_acc= 0.5486          \n",
      "Epoch 67, CIFAR-10 Batch 5:  cost= 1.1475           train_acc= 0.6014           valid_acc= 0.5376          \n",
      "Epoch 68, CIFAR-10 Batch 1:  cost= 1.2986           train_acc= 0.5338           valid_acc= 0.5608          \n",
      "Epoch 68, CIFAR-10 Batch 2:  cost= 1.2624           train_acc= 0.5507           valid_acc= 0.5288          \n",
      "Epoch 68, CIFAR-10 Batch 3:  cost= 1.1397           train_acc= 0.5574           valid_acc= 0.5254          \n",
      "Epoch 68, CIFAR-10 Batch 4:  cost= 1.1082           train_acc= 0.6453           valid_acc= 0.5406          \n",
      "Epoch 68, CIFAR-10 Batch 5:  cost= 1.1737           train_acc= 0.5541           valid_acc= 0.5268          \n",
      "Epoch 69, CIFAR-10 Batch 1:  cost= 1.2292           train_acc= 0.5743           valid_acc= 0.5778          \n",
      "Epoch 69, CIFAR-10 Batch 2:  cost= 1.2209           train_acc= 0.5405           valid_acc= 0.5464          \n",
      "Epoch 69, CIFAR-10 Batch 3:  cost= 1.1775           train_acc= 0.5574           valid_acc= 0.5218          \n",
      "Epoch 69, CIFAR-10 Batch 4:  cost= 1.0808           train_acc= 0.6351           valid_acc= 0.5596          \n",
      "Epoch 69, CIFAR-10 Batch 5:  cost= 1.1549           train_acc= 0.5912           valid_acc= 0.5474          \n",
      "Epoch 70, CIFAR-10 Batch 1:  cost= 1.2621           train_acc= 0.5811           valid_acc= 0.5720          \n",
      "Epoch 70, CIFAR-10 Batch 2:  cost= 1.2139           train_acc= 0.5101           valid_acc= 0.5512          \n",
      "Epoch 70, CIFAR-10 Batch 3:  cost= 1.1560           train_acc= 0.5676           valid_acc= 0.5278          \n",
      "Epoch 70, CIFAR-10 Batch 4:  cost= 1.0892           train_acc= 0.6149           valid_acc= 0.5512          \n",
      "Epoch 70, CIFAR-10 Batch 5:  cost= 1.1439           train_acc= 0.5811           valid_acc= 0.5412          \n",
      "Epoch 71, CIFAR-10 Batch 1:  cost= 1.2471           train_acc= 0.5473           valid_acc= 0.5690          \n",
      "Epoch 71, CIFAR-10 Batch 2:  cost= 1.2350           train_acc= 0.5304           valid_acc= 0.5410          \n",
      "Epoch 71, CIFAR-10 Batch 3:  cost= 1.1970           train_acc= 0.5405           valid_acc= 0.5164          \n",
      "Epoch 71, CIFAR-10 Batch 4:  cost= 1.1160           train_acc= 0.6081           valid_acc= 0.5396          \n",
      "Epoch 71, CIFAR-10 Batch 5:  cost= 1.1787           train_acc= 0.5878           valid_acc= 0.5406          \n",
      "Epoch 72, CIFAR-10 Batch 1:  cost= 1.2648           train_acc= 0.5203           valid_acc= 0.5588          \n",
      "Epoch 72, CIFAR-10 Batch 2:  cost= 1.2543           train_acc= 0.5338           valid_acc= 0.5436          \n",
      "Epoch 72, CIFAR-10 Batch 3:  cost= 1.1408           train_acc= 0.5473           valid_acc= 0.5326          \n",
      "Epoch 72, CIFAR-10 Batch 4:  cost= 1.0448           train_acc= 0.6554           valid_acc= 0.5642          \n",
      "Epoch 72, CIFAR-10 Batch 5:  cost= 1.1450           train_acc= 0.5912           valid_acc= 0.5452          \n",
      "Epoch 73, CIFAR-10 Batch 1:  cost= 1.2255           train_acc= 0.5507           valid_acc= 0.5698          \n",
      "Epoch 73, CIFAR-10 Batch 2:  cost= 1.2590           train_acc= 0.5304           valid_acc= 0.5436          \n",
      "Epoch 73, CIFAR-10 Batch 3:  cost= 1.1743           train_acc= 0.5473           valid_acc= 0.5162          \n",
      "Epoch 73, CIFAR-10 Batch 4:  cost= 1.0853           train_acc= 0.6216           valid_acc= 0.5516          \n",
      "Epoch 73, CIFAR-10 Batch 5:  cost= 1.1308           train_acc= 0.6014           valid_acc= 0.5450          \n",
      "Epoch 74, CIFAR-10 Batch 1:  cost= 1.2610           train_acc= 0.5405           valid_acc= 0.5648          \n",
      "Epoch 74, CIFAR-10 Batch 2:  cost= 1.2472           train_acc= 0.5473           valid_acc= 0.5448          \n",
      "Epoch 74, CIFAR-10 Batch 3:  cost= 1.1487           train_acc= 0.5676           valid_acc= 0.5308          \n",
      "Epoch 74, CIFAR-10 Batch 4:  cost= 1.0300           train_acc= 0.6284           valid_acc= 0.5734          \n",
      "Epoch 74, CIFAR-10 Batch 5:  cost= 1.1785           train_acc= 0.5642           valid_acc= 0.5328          \n",
      "Epoch 75, CIFAR-10 Batch 1:  cost= 1.2310           train_acc= 0.5743           valid_acc= 0.5692          \n",
      "Epoch 75, CIFAR-10 Batch 2:  cost= 1.2871           train_acc= 0.5236           valid_acc= 0.5142          \n",
      "Epoch 75, CIFAR-10 Batch 3:  cost= 1.1401           train_acc= 0.5574           valid_acc= 0.5196          \n",
      "Epoch 75, CIFAR-10 Batch 4:  cost= 1.1337           train_acc= 0.5878           valid_acc= 0.5244          \n",
      "Epoch 75, CIFAR-10 Batch 5:  cost= 1.1817           train_acc= 0.5777           valid_acc= 0.5276          \n",
      "Epoch 76, CIFAR-10 Batch 1:  cost= 1.2742           train_acc= 0.5507           valid_acc= 0.5630          \n",
      "Epoch 76, CIFAR-10 Batch 2:  cost= 1.2089           train_acc= 0.5574           valid_acc= 0.5484          \n",
      "Epoch 76, CIFAR-10 Batch 3:  cost= 1.1698           train_acc= 0.5541           valid_acc= 0.5220          \n",
      "Epoch 76, CIFAR-10 Batch 4:  cost= 1.0380           train_acc= 0.6318           valid_acc= 0.5596          \n",
      "Epoch 76, CIFAR-10 Batch 5:  cost= 1.1424           train_acc= 0.5709           valid_acc= 0.5474          \n",
      "Epoch 77, CIFAR-10 Batch 1:  cost= 1.2609           train_acc= 0.5338           valid_acc= 0.5622          \n",
      "Epoch 77, CIFAR-10 Batch 2:  cost= 1.2060           train_acc= 0.5743           valid_acc= 0.5434          \n",
      "Epoch 77, CIFAR-10 Batch 3:  cost= 1.1537           train_acc= 0.5473           valid_acc= 0.5222          \n",
      "Epoch 77, CIFAR-10 Batch 4:  cost= 1.0751           train_acc= 0.6385           valid_acc= 0.5506          \n",
      "Epoch 77, CIFAR-10 Batch 5:  cost= 1.1486           train_acc= 0.5946           valid_acc= 0.5454          \n",
      "Epoch 78, CIFAR-10 Batch 1:  cost= 1.2366           train_acc= 0.5608           valid_acc= 0.5700          \n",
      "Epoch 78, CIFAR-10 Batch 2:  cost= 1.1775           train_acc= 0.5845           valid_acc= 0.5648          \n",
      "Epoch 78, CIFAR-10 Batch 3:  cost= 1.1504           train_acc= 0.5676           valid_acc= 0.5262          \n",
      "Epoch 78, CIFAR-10 Batch 4:  cost= 1.0596           train_acc= 0.6318           valid_acc= 0.5466          \n",
      "Epoch 78, CIFAR-10 Batch 5:  cost= 1.1151           train_acc= 0.6149           valid_acc= 0.5434          \n",
      "Epoch 79, CIFAR-10 Batch 1:  cost= 1.2716           train_acc= 0.5372           valid_acc= 0.5660          \n",
      "Epoch 79, CIFAR-10 Batch 2:  cost= 1.2172           train_acc= 0.5507           valid_acc= 0.5278          \n",
      "Epoch 79, CIFAR-10 Batch 3:  cost= 1.2161           train_acc= 0.5169           valid_acc= 0.5032          \n",
      "Epoch 79, CIFAR-10 Batch 4:  cost= 1.0600           train_acc= 0.6520           valid_acc= 0.5586          \n",
      "Epoch 79, CIFAR-10 Batch 5:  cost= 1.1215           train_acc= 0.6014           valid_acc= 0.5466          \n",
      "Epoch 80, CIFAR-10 Batch 1:  cost= 1.2266           train_acc= 0.5743           valid_acc= 0.5752          \n",
      "Epoch 80, CIFAR-10 Batch 2:  cost= 1.2048           train_acc= 0.5709           valid_acc= 0.5502          \n",
      "Epoch 80, CIFAR-10 Batch 3:  cost= 1.1151           train_acc= 0.5946           valid_acc= 0.5460          \n",
      "Epoch 80, CIFAR-10 Batch 4:  cost= 1.0954           train_acc= 0.6115           valid_acc= 0.5446          \n",
      "Epoch 80, CIFAR-10 Batch 5:  cost= 1.1303           train_acc= 0.6047           valid_acc= 0.5422          \n",
      "Epoch 81, CIFAR-10 Batch 1:  cost= 1.1993           train_acc= 0.5574           valid_acc= 0.5708          \n",
      "Epoch 81, CIFAR-10 Batch 2:  cost= 1.2105           train_acc= 0.5743           valid_acc= 0.5526          \n",
      "Epoch 81, CIFAR-10 Batch 3:  cost= 1.1595           train_acc= 0.5405           valid_acc= 0.5246          \n",
      "Epoch 81, CIFAR-10 Batch 4:  cost= 1.0575           train_acc= 0.6689           valid_acc= 0.5602          \n",
      "Epoch 81, CIFAR-10 Batch 5:  cost= 1.1117           train_acc= 0.6014           valid_acc= 0.5622          \n",
      "Epoch 82, CIFAR-10 Batch 1:  cost= 1.2424           train_acc= 0.5642           valid_acc= 0.5804          \n",
      "Epoch 82, CIFAR-10 Batch 2:  cost= 1.2877           train_acc= 0.5372           valid_acc= 0.5266          \n",
      "Epoch 82, CIFAR-10 Batch 3:  cost= 1.1049           train_acc= 0.5642           valid_acc= 0.5382          \n",
      "Epoch 82, CIFAR-10 Batch 4:  cost= 1.0515           train_acc= 0.6351           valid_acc= 0.5598          \n",
      "Epoch 82, CIFAR-10 Batch 5:  cost= 1.1525           train_acc= 0.5743           valid_acc= 0.5342          \n",
      "Epoch 83, CIFAR-10 Batch 1:  cost= 1.1861           train_acc= 0.5811           valid_acc= 0.5844          \n",
      "Epoch 83, CIFAR-10 Batch 2:  cost= 1.1639           train_acc= 0.5845           valid_acc= 0.5700          \n",
      "Epoch 83, CIFAR-10 Batch 3:  cost= 1.1087           train_acc= 0.5743           valid_acc= 0.5436          \n",
      "Epoch 83, CIFAR-10 Batch 4:  cost= 1.0190           train_acc= 0.6757           valid_acc= 0.5696          \n",
      "Epoch 83, CIFAR-10 Batch 5:  cost= 1.1257           train_acc= 0.6047           valid_acc= 0.5416          \n",
      "Epoch 84, CIFAR-10 Batch 1:  cost= 1.2110           train_acc= 0.5676           valid_acc= 0.5740          \n",
      "Epoch 84, CIFAR-10 Batch 2:  cost= 1.1966           train_acc= 0.5743           valid_acc= 0.5652          \n",
      "Epoch 84, CIFAR-10 Batch 3:  cost= 1.1115           train_acc= 0.5878           valid_acc= 0.5430          \n",
      "Epoch 84, CIFAR-10 Batch 4:  cost= 1.0684           train_acc= 0.6419           valid_acc= 0.5500          \n",
      "Epoch 84, CIFAR-10 Batch 5:  cost= 1.0510           train_acc= 0.6284           valid_acc= 0.5688          \n",
      "Epoch 85, CIFAR-10 Batch 1:  cost= 1.2517           train_acc= 0.5541           valid_acc= 0.5804          \n",
      "Epoch 85, CIFAR-10 Batch 2:  cost= 1.2583           train_acc= 0.5541           valid_acc= 0.5342          \n",
      "Epoch 85, CIFAR-10 Batch 3:  cost= 1.1029           train_acc= 0.5709           valid_acc= 0.5462          \n",
      "Epoch 85, CIFAR-10 Batch 4:  cost= 1.0723           train_acc= 0.6318           valid_acc= 0.5622          \n",
      "Epoch 85, CIFAR-10 Batch 5:  cost= 1.1247           train_acc= 0.5946           valid_acc= 0.5414          \n",
      "Epoch 86, CIFAR-10 Batch 1:  cost= 1.2349           train_acc= 0.5473           valid_acc= 0.5728          \n",
      "Epoch 86, CIFAR-10 Batch 2:  cost= 1.2134           train_acc= 0.5743           valid_acc= 0.5504          \n",
      "Epoch 86, CIFAR-10 Batch 3:  cost= 1.1560           train_acc= 0.5473           valid_acc= 0.5306          \n",
      "Epoch 86, CIFAR-10 Batch 4:  cost= 1.0793           train_acc= 0.6419           valid_acc= 0.5382          \n",
      "Epoch 86, CIFAR-10 Batch 5:  cost= 1.1984           train_acc= 0.5439           valid_acc= 0.5252          \n",
      "Epoch 87, CIFAR-10 Batch 1:  cost= 1.2414           train_acc= 0.5541           valid_acc= 0.5672          \n",
      "Epoch 87, CIFAR-10 Batch 2:  cost= 1.1998           train_acc= 0.5608           valid_acc= 0.5478          \n",
      "Epoch 87, CIFAR-10 Batch 3:  cost= 1.1261           train_acc= 0.5608           valid_acc= 0.5450          \n",
      "Epoch 87, CIFAR-10 Batch 4:  cost= 1.0731           train_acc= 0.6622           valid_acc= 0.5520          \n",
      "Epoch 87, CIFAR-10 Batch 5:  cost= 1.1087           train_acc= 0.6014           valid_acc= 0.5508          \n",
      "Epoch 88, CIFAR-10 Batch 1:  cost= 1.2193           train_acc= 0.5709           valid_acc= 0.5788          \n",
      "Epoch 88, CIFAR-10 Batch 2:  cost= 1.2102           train_acc= 0.5608           valid_acc= 0.5642          \n",
      "Epoch 88, CIFAR-10 Batch 3:  cost= 1.1215           train_acc= 0.5743           valid_acc= 0.5374          \n",
      "Epoch 88, CIFAR-10 Batch 4:  cost= 1.0618           train_acc= 0.6318           valid_acc= 0.5536          \n",
      "Epoch 88, CIFAR-10 Batch 5:  cost= 1.1318           train_acc= 0.5912           valid_acc= 0.5436          \n",
      "Epoch 89, CIFAR-10 Batch 1:  cost= 1.2314           train_acc= 0.5574           valid_acc= 0.5726          \n",
      "Epoch 89, CIFAR-10 Batch 2:  cost= 1.2124           train_acc= 0.5574           valid_acc= 0.5590          \n",
      "Epoch 89, CIFAR-10 Batch 3:  cost= 1.1389           train_acc= 0.5946           valid_acc= 0.5262          \n",
      "Epoch 89, CIFAR-10 Batch 4:  cost= 1.0640           train_acc= 0.6318           valid_acc= 0.5636          \n",
      "Epoch 89, CIFAR-10 Batch 5:  cost= 1.1263           train_acc= 0.5946           valid_acc= 0.5470          \n",
      "Epoch 90, CIFAR-10 Batch 1:  cost= 1.2145           train_acc= 0.5676           valid_acc= 0.5808          \n",
      "Epoch 90, CIFAR-10 Batch 2:  cost= 1.2277           train_acc= 0.5507           valid_acc= 0.5552          \n",
      "Epoch 90, CIFAR-10 Batch 3:  cost= 1.0651           train_acc= 0.6047           valid_acc= 0.5556          \n",
      "Epoch 90, CIFAR-10 Batch 4:  cost= 1.0085           train_acc= 0.6554           valid_acc= 0.5760          \n",
      "Epoch 90, CIFAR-10 Batch 5:  cost= 1.1463           train_acc= 0.5507           valid_acc= 0.5432          \n",
      "Epoch 91, CIFAR-10 Batch 1:  cost= 1.2664           train_acc= 0.5338           valid_acc= 0.5670          \n",
      "Epoch 91, CIFAR-10 Batch 2:  cost= 1.1927           train_acc= 0.5574           valid_acc= 0.5586          \n",
      "Epoch 91, CIFAR-10 Batch 3:  cost= 1.1171           train_acc= 0.5777           valid_acc= 0.5436          \n",
      "Epoch 91, CIFAR-10 Batch 4:  cost= 1.0844           train_acc= 0.6318           valid_acc= 0.5554          \n",
      "Epoch 91, CIFAR-10 Batch 5:  cost= 1.0973           train_acc= 0.5845           valid_acc= 0.5592          \n",
      "Epoch 92, CIFAR-10 Batch 1:  cost= 1.2270           train_acc= 0.5338           valid_acc= 0.5736          \n",
      "Epoch 92, CIFAR-10 Batch 2:  cost= 1.2418           train_acc= 0.5372           valid_acc= 0.5468          \n",
      "Epoch 92, CIFAR-10 Batch 3:  cost= 1.0896           train_acc= 0.5845           valid_acc= 0.5394          \n",
      "Epoch 92, CIFAR-10 Batch 4:  cost= 1.0715           train_acc= 0.6182           valid_acc= 0.5554          \n",
      "Epoch 92, CIFAR-10 Batch 5:  cost= 1.0948           train_acc= 0.6014           valid_acc= 0.5570          \n",
      "Epoch 93, CIFAR-10 Batch 1:  cost= 1.2114           train_acc= 0.5676           valid_acc= 0.5792          \n",
      "Epoch 93, CIFAR-10 Batch 2:  cost= 1.1784           train_acc= 0.5608           valid_acc= 0.5530          \n",
      "Epoch 93, CIFAR-10 Batch 3:  cost= 1.1272           train_acc= 0.5507           valid_acc= 0.5350          \n",
      "Epoch 93, CIFAR-10 Batch 4:  cost= 1.0807           train_acc= 0.6284           valid_acc= 0.5562          \n",
      "Epoch 93, CIFAR-10 Batch 5:  cost= 1.0925           train_acc= 0.6081           valid_acc= 0.5618          \n",
      "Epoch 94, CIFAR-10 Batch 1:  cost= 1.2061           train_acc= 0.5743           valid_acc= 0.5826          \n",
      "Epoch 94, CIFAR-10 Batch 2:  cost= 1.1947           train_acc= 0.5676           valid_acc= 0.5582          \n",
      "Epoch 94, CIFAR-10 Batch 3:  cost= 1.0735           train_acc= 0.6081           valid_acc= 0.5438          \n",
      "Epoch 94, CIFAR-10 Batch 4:  cost= 1.0099           train_acc= 0.6757           valid_acc= 0.5758          \n",
      "Epoch 94, CIFAR-10 Batch 5:  cost= 1.1309           train_acc= 0.5912           valid_acc= 0.5542          \n",
      "Epoch 95, CIFAR-10 Batch 1:  cost= 1.1879           train_acc= 0.5709           valid_acc= 0.5840          \n",
      "Epoch 95, CIFAR-10 Batch 2:  cost= 1.2548           train_acc= 0.5642           valid_acc= 0.5428          \n",
      "Epoch 95, CIFAR-10 Batch 3:  cost= 1.0749           train_acc= 0.5845           valid_acc= 0.5516          \n",
      "Epoch 95, CIFAR-10 Batch 4:  cost= 1.0023           train_acc= 0.6689           valid_acc= 0.5794          \n",
      "Epoch 95, CIFAR-10 Batch 5:  cost= 1.0583           train_acc= 0.6182           valid_acc= 0.5774          \n",
      "Epoch 96, CIFAR-10 Batch 1:  cost= 1.2094           train_acc= 0.5608           valid_acc= 0.5774          \n",
      "Epoch 96, CIFAR-10 Batch 2:  cost= 1.2063           train_acc= 0.5541           valid_acc= 0.5520          \n",
      "Epoch 96, CIFAR-10 Batch 3:  cost= 1.0781           train_acc= 0.5912           valid_acc= 0.5522          \n",
      "Epoch 96, CIFAR-10 Batch 4:  cost= 1.0588           train_acc= 0.6385           valid_acc= 0.5614          \n",
      "Epoch 96, CIFAR-10 Batch 5:  cost= 1.0824           train_acc= 0.6149           valid_acc= 0.5592          \n",
      "Epoch 97, CIFAR-10 Batch 1:  cost= 1.2051           train_acc= 0.5439           valid_acc= 0.5806          \n",
      "Epoch 97, CIFAR-10 Batch 2:  cost= 1.1800           train_acc= 0.5608           valid_acc= 0.5678          \n",
      "Epoch 97, CIFAR-10 Batch 3:  cost= 1.1100           train_acc= 0.5676           valid_acc= 0.5400          \n",
      "Epoch 97, CIFAR-10 Batch 4:  cost= 1.0376           train_acc= 0.6655           valid_acc= 0.5756          \n",
      "Epoch 97, CIFAR-10 Batch 5:  cost= 1.0936           train_acc= 0.5743           valid_acc= 0.5574          \n",
      "Epoch 98, CIFAR-10 Batch 1:  cost= 1.1983           train_acc= 0.5372           valid_acc= 0.5766          \n",
      "Epoch 98, CIFAR-10 Batch 2:  cost= 1.2204           train_acc= 0.5507           valid_acc= 0.5388          \n",
      "Epoch 98, CIFAR-10 Batch 3:  cost= 1.1043           train_acc= 0.5541           valid_acc= 0.5430          \n",
      "Epoch 98, CIFAR-10 Batch 4:  cost= 1.0359           train_acc= 0.6520           valid_acc= 0.5624          \n",
      "Epoch 98, CIFAR-10 Batch 5:  cost= 1.0743           train_acc= 0.6081           valid_acc= 0.5662          \n",
      "Epoch 99, CIFAR-10 Batch 1:  cost= 1.2695           train_acc= 0.5405           valid_acc= 0.5658          \n",
      "Epoch 99, CIFAR-10 Batch 2:  cost= 1.2110           train_acc= 0.5642           valid_acc= 0.5490          \n",
      "Epoch 99, CIFAR-10 Batch 3:  cost= 1.0638           train_acc= 0.5946           valid_acc= 0.5588          \n",
      "Epoch 99, CIFAR-10 Batch 4:  cost= 1.0052           train_acc= 0.6622           valid_acc= 0.5826          \n",
      "Epoch 99, CIFAR-10 Batch 5:  cost= 1.0578           train_acc= 0.6115           valid_acc= 0.5600          \n",
      "Epoch 100, CIFAR-10 Batch 1:  cost= 1.1838           train_acc= 0.5709           valid_acc= 0.5778          \n",
      "Epoch 100, CIFAR-10 Batch 2:  cost= 1.1714           train_acc= 0.5709           valid_acc= 0.5572          \n",
      "Epoch 100, CIFAR-10 Batch 3:  cost= 1.0730           train_acc= 0.5912           valid_acc= 0.5516          \n",
      "Epoch 100, CIFAR-10 Batch 4:  cost= 1.0434           train_acc= 0.6351           valid_acc= 0.5612          \n",
      "Epoch 100, CIFAR-10 Batch 5:  cost= 1.1190           train_acc= 0.5980           valid_acc= 0.5394          \n",
      "Epoch 101, CIFAR-10 Batch 1:  cost= 1.1648           train_acc= 0.5743           valid_acc= 0.5916          \n",
      "Epoch 101, CIFAR-10 Batch 2:  cost= 1.1993           train_acc= 0.5541           valid_acc= 0.5502          \n",
      "Epoch 101, CIFAR-10 Batch 3:  cost= 1.0998           train_acc= 0.5845           valid_acc= 0.5460          \n",
      "Epoch 101, CIFAR-10 Batch 4:  cost= 1.0605           train_acc= 0.6284           valid_acc= 0.5538          \n",
      "Epoch 101, CIFAR-10 Batch 5:  cost= 1.0742           train_acc= 0.6115           valid_acc= 0.5612          \n",
      "Epoch 102, CIFAR-10 Batch 1:  cost= 1.1883           train_acc= 0.5946           valid_acc= 0.5876          \n",
      "Epoch 102, CIFAR-10 Batch 2:  cost= 1.2090           train_acc= 0.5541           valid_acc= 0.5406          \n",
      "Epoch 102, CIFAR-10 Batch 3:  cost= 1.1508           train_acc= 0.5709           valid_acc= 0.5354          \n",
      "Epoch 102, CIFAR-10 Batch 4:  cost= 1.0034           train_acc= 0.6520           valid_acc= 0.5832          \n",
      "Epoch 102, CIFAR-10 Batch 5:  cost= 1.1080           train_acc= 0.5676           valid_acc= 0.5370          \n",
      "Epoch 103, CIFAR-10 Batch 1:  cost= 1.2131           train_acc= 0.5642           valid_acc= 0.5690          \n",
      "Epoch 103, CIFAR-10 Batch 2:  cost= 1.0961           train_acc= 0.6081           valid_acc= 0.5882          \n",
      "Epoch 103, CIFAR-10 Batch 3:  cost= 1.1256           train_acc= 0.5507           valid_acc= 0.5322          \n",
      "Epoch 103, CIFAR-10 Batch 4:  cost= 1.0266           train_acc= 0.6554           valid_acc= 0.5770          \n",
      "Epoch 103, CIFAR-10 Batch 5:  cost= 1.1001           train_acc= 0.5946           valid_acc= 0.5532          \n",
      "Epoch 104, CIFAR-10 Batch 1:  cost= 1.1858           train_acc= 0.5676           valid_acc= 0.5772          \n",
      "Epoch 104, CIFAR-10 Batch 2:  cost= 1.1701           train_acc= 0.5743           valid_acc= 0.5548          \n",
      "Epoch 104, CIFAR-10 Batch 3:  cost= 1.0680           train_acc= 0.6047           valid_acc= 0.5566          \n",
      "Epoch 104, CIFAR-10 Batch 4:  cost= 1.0840           train_acc= 0.6385           valid_acc= 0.5524          \n",
      "Epoch 104, CIFAR-10 Batch 5:  cost= 1.0398           train_acc= 0.6318           valid_acc= 0.5736          \n",
      "Epoch 105, CIFAR-10 Batch 1:  cost= 1.2012           train_acc= 0.5642           valid_acc= 0.5802          \n",
      "Epoch 105, CIFAR-10 Batch 2:  cost= 1.1419           train_acc= 0.5709           valid_acc= 0.5720          \n",
      "Epoch 105, CIFAR-10 Batch 3:  cost= 1.0670           train_acc= 0.5980           valid_acc= 0.5498          \n",
      "Epoch 105, CIFAR-10 Batch 4:  cost= 1.0832           train_acc= 0.6385           valid_acc= 0.5446          \n",
      "Epoch 105, CIFAR-10 Batch 5:  cost= 1.0831           train_acc= 0.6149           valid_acc= 0.5596          \n",
      "Epoch 106, CIFAR-10 Batch 1:  cost= 1.1580           train_acc= 0.5980           valid_acc= 0.5906          \n",
      "Epoch 106, CIFAR-10 Batch 2:  cost= 1.1933           train_acc= 0.5743           valid_acc= 0.5518          \n",
      "Epoch 106, CIFAR-10 Batch 3:  cost= 1.0524           train_acc= 0.5845           valid_acc= 0.5610          \n",
      "Epoch 106, CIFAR-10 Batch 4:  cost= 1.0534           train_acc= 0.6318           valid_acc= 0.5654          \n",
      "Epoch 106, CIFAR-10 Batch 5:  cost= 1.0824           train_acc= 0.5946           valid_acc= 0.5610          \n",
      "Epoch 107, CIFAR-10 Batch 1:  cost= 1.2337           train_acc= 0.5676           valid_acc= 0.5710          \n",
      "Epoch 107, CIFAR-10 Batch 2:  cost= 1.1478           train_acc= 0.5946           valid_acc= 0.5690          \n",
      "Epoch 107, CIFAR-10 Batch 3:  cost= 1.1245           train_acc= 0.5946           valid_acc= 0.5414          \n",
      "Epoch 107, CIFAR-10 Batch 4:  cost= 1.0226           train_acc= 0.6520           valid_acc= 0.5662          \n",
      "Epoch 107, CIFAR-10 Batch 5:  cost= 1.0101           train_acc= 0.6419           valid_acc= 0.5826          \n",
      "Epoch 108, CIFAR-10 Batch 1:  cost= 1.1696           train_acc= 0.5811           valid_acc= 0.5860          \n",
      "Epoch 108, CIFAR-10 Batch 2:  cost= 1.1115           train_acc= 0.6014           valid_acc= 0.5762          \n",
      "Epoch 108, CIFAR-10 Batch 3:  cost= 1.0803           train_acc= 0.6081           valid_acc= 0.5594          \n",
      "Epoch 108, CIFAR-10 Batch 4:  cost= 1.0112           train_acc= 0.6588           valid_acc= 0.5770          \n",
      "Epoch 108, CIFAR-10 Batch 5:  cost= 1.0820           train_acc= 0.5912           valid_acc= 0.5490          \n",
      "Epoch 109, CIFAR-10 Batch 1:  cost= 1.1500           train_acc= 0.5912           valid_acc= 0.5868          \n",
      "Epoch 109, CIFAR-10 Batch 2:  cost= 1.1147           train_acc= 0.6047           valid_acc= 0.5816          \n",
      "Epoch 109, CIFAR-10 Batch 3:  cost= 1.1157           train_acc= 0.5743           valid_acc= 0.5428          \n",
      "Epoch 109, CIFAR-10 Batch 4:  cost= 1.0057           train_acc= 0.6689           valid_acc= 0.5780          \n",
      "Epoch 109, CIFAR-10 Batch 5:  cost= 1.0146           train_acc= 0.6318           valid_acc= 0.5678          \n",
      "Epoch 110, CIFAR-10 Batch 1:  cost= 1.1508           train_acc= 0.5878           valid_acc= 0.5938          \n",
      "Epoch 110, CIFAR-10 Batch 2:  cost= 1.1434           train_acc= 0.5912           valid_acc= 0.5660          \n",
      "Epoch 110, CIFAR-10 Batch 3:  cost= 1.0768           train_acc= 0.5845           valid_acc= 0.5588          \n",
      "Epoch 110, CIFAR-10 Batch 4:  cost= 0.9901           train_acc= 0.6757           valid_acc= 0.5962          \n",
      "Epoch 110, CIFAR-10 Batch 5:  cost= 1.0578           train_acc= 0.6318           valid_acc= 0.5684          \n",
      "Epoch 111, CIFAR-10 Batch 1:  cost= 1.1680           train_acc= 0.6014           valid_acc= 0.5954          \n",
      "Epoch 111, CIFAR-10 Batch 2:  cost= 1.1360           train_acc= 0.5777           valid_acc= 0.5706          \n",
      "Epoch 111, CIFAR-10 Batch 3:  cost= 1.0539           train_acc= 0.6284           valid_acc= 0.5600          \n",
      "Epoch 111, CIFAR-10 Batch 4:  cost= 1.0308           train_acc= 0.6622           valid_acc= 0.5636          \n",
      "Epoch 111, CIFAR-10 Batch 5:  cost= 1.0900           train_acc= 0.5845           valid_acc= 0.5570          \n",
      "Epoch 112, CIFAR-10 Batch 1:  cost= 1.1753           train_acc= 0.5912           valid_acc= 0.5898          \n",
      "Epoch 112, CIFAR-10 Batch 2:  cost= 1.1523           train_acc= 0.5878           valid_acc= 0.5668          \n",
      "Epoch 112, CIFAR-10 Batch 3:  cost= 1.1035           train_acc= 0.5676           valid_acc= 0.5456          \n",
      "Epoch 112, CIFAR-10 Batch 4:  cost= 1.0134           train_acc= 0.6689           valid_acc= 0.5780          \n",
      "Epoch 112, CIFAR-10 Batch 5:  cost= 1.0447           train_acc= 0.6149           valid_acc= 0.5724          \n",
      "Epoch 113, CIFAR-10 Batch 1:  cost= 1.1730           train_acc= 0.5743           valid_acc= 0.5804          \n",
      "Epoch 113, CIFAR-10 Batch 2:  cost= 1.1401           train_acc= 0.5845           valid_acc= 0.5734          \n",
      "Epoch 113, CIFAR-10 Batch 3:  cost= 1.1577           train_acc= 0.5608           valid_acc= 0.5266          \n",
      "Epoch 113, CIFAR-10 Batch 4:  cost= 0.9949           train_acc= 0.6588           valid_acc= 0.5766          \n",
      "Epoch 113, CIFAR-10 Batch 5:  cost= 1.0898           train_acc= 0.6081           valid_acc= 0.5578          \n",
      "Epoch 114, CIFAR-10 Batch 1:  cost= 1.1406           train_acc= 0.5980           valid_acc= 0.5934          \n",
      "Epoch 114, CIFAR-10 Batch 2:  cost= 1.0981           train_acc= 0.6047           valid_acc= 0.5748          \n",
      "Epoch 114, CIFAR-10 Batch 3:  cost= 1.0940           train_acc= 0.5980           valid_acc= 0.5470          \n",
      "Epoch 114, CIFAR-10 Batch 4:  cost= 1.0158           train_acc= 0.6419           valid_acc= 0.5838          \n",
      "Epoch 114, CIFAR-10 Batch 5:  cost= 1.0721           train_acc= 0.6149           valid_acc= 0.5566          \n",
      "Epoch 115, CIFAR-10 Batch 1:  cost= 1.1150           train_acc= 0.5878           valid_acc= 0.6042          \n",
      "Epoch 115, CIFAR-10 Batch 2:  cost= 1.1259           train_acc= 0.6014           valid_acc= 0.5684          \n",
      "Epoch 115, CIFAR-10 Batch 3:  cost= 1.0758           train_acc= 0.5845           valid_acc= 0.5508          \n",
      "Epoch 115, CIFAR-10 Batch 4:  cost= 0.9825           train_acc= 0.6791           valid_acc= 0.5886          \n",
      "Epoch 115, CIFAR-10 Batch 5:  cost= 1.0978           train_acc= 0.5743           valid_acc= 0.5516          \n",
      "Epoch 116, CIFAR-10 Batch 1:  cost= 1.1178           train_acc= 0.5777           valid_acc= 0.6044          \n",
      "Epoch 116, CIFAR-10 Batch 2:  cost= 1.1145           train_acc= 0.6182           valid_acc= 0.5708          \n",
      "Epoch 116, CIFAR-10 Batch 3:  cost= 1.0447           train_acc= 0.6081           valid_acc= 0.5678          \n",
      "Epoch 116, CIFAR-10 Batch 4:  cost= 1.0173           train_acc= 0.6554           valid_acc= 0.5696          \n",
      "Epoch 116, CIFAR-10 Batch 5:  cost= 1.0337           train_acc= 0.6081           valid_acc= 0.5754          \n",
      "Epoch 117, CIFAR-10 Batch 1:  cost= 1.0895           train_acc= 0.6250           valid_acc= 0.5978          \n",
      "Epoch 117, CIFAR-10 Batch 2:  cost= 1.1289           train_acc= 0.5946           valid_acc= 0.5664          \n",
      "Epoch 117, CIFAR-10 Batch 3:  cost= 1.0907           train_acc= 0.5912           valid_acc= 0.5438          \n",
      "Epoch 117, CIFAR-10 Batch 4:  cost= 1.0392           train_acc= 0.6351           valid_acc= 0.5744          \n",
      "Epoch 117, CIFAR-10 Batch 5:  cost= 1.0347           train_acc= 0.6149           valid_acc= 0.5718          \n",
      "Epoch 118, CIFAR-10 Batch 1:  cost= 1.1473           train_acc= 0.5709           valid_acc= 0.6012          \n",
      "Epoch 118, CIFAR-10 Batch 2:  cost= 1.1098           train_acc= 0.5912           valid_acc= 0.5718          \n",
      "Epoch 118, CIFAR-10 Batch 3:  cost= 1.0489           train_acc= 0.6250           valid_acc= 0.5620          \n",
      "Epoch 118, CIFAR-10 Batch 4:  cost= 0.9654           train_acc= 0.6689           valid_acc= 0.5902          \n",
      "Epoch 118, CIFAR-10 Batch 5:  cost= 1.0015           train_acc= 0.6486           valid_acc= 0.5898          \n",
      "Epoch 119, CIFAR-10 Batch 1:  cost= 1.1530           train_acc= 0.5845           valid_acc= 0.5920          \n",
      "Epoch 119, CIFAR-10 Batch 2:  cost= 1.0738           train_acc= 0.6047           valid_acc= 0.5936          \n",
      "Epoch 119, CIFAR-10 Batch 3:  cost= 1.0326           train_acc= 0.6182           valid_acc= 0.5690          \n",
      "Epoch 119, CIFAR-10 Batch 4:  cost= 0.9772           train_acc= 0.6926           valid_acc= 0.5910          \n",
      "Epoch 119, CIFAR-10 Batch 5:  cost= 1.0447           train_acc= 0.6318           valid_acc= 0.5796          \n",
      "Epoch 120, CIFAR-10 Batch 1:  cost= 1.1452           train_acc= 0.5878           valid_acc= 0.5912          \n",
      "Epoch 120, CIFAR-10 Batch 2:  cost= 1.0912           train_acc= 0.5878           valid_acc= 0.5930          \n",
      "Epoch 120, CIFAR-10 Batch 3:  cost= 1.0916           train_acc= 0.5811           valid_acc= 0.5498          \n",
      "Epoch 120, CIFAR-10 Batch 4:  cost= 0.9959           train_acc= 0.6791           valid_acc= 0.5750          \n",
      "Epoch 120, CIFAR-10 Batch 5:  cost= 1.0691           train_acc= 0.6182           valid_acc= 0.5590          \n",
      "Epoch 121, CIFAR-10 Batch 1:  cost= 1.1382           train_acc= 0.6047           valid_acc= 0.5928          \n",
      "Epoch 121, CIFAR-10 Batch 2:  cost= 1.0865           train_acc= 0.6115           valid_acc= 0.5786          \n",
      "Epoch 121, CIFAR-10 Batch 3:  cost= 1.0267           train_acc= 0.6318           valid_acc= 0.5748          \n",
      "Epoch 121, CIFAR-10 Batch 4:  cost= 1.0123           train_acc= 0.6486           valid_acc= 0.5770          \n",
      "Epoch 121, CIFAR-10 Batch 5:  cost= 1.0030           train_acc= 0.6216           valid_acc= 0.5836          \n",
      "Epoch 122, CIFAR-10 Batch 1:  cost= 1.1146           train_acc= 0.5980           valid_acc= 0.6020          \n",
      "Epoch 122, CIFAR-10 Batch 2:  cost= 1.1508           train_acc= 0.5878           valid_acc= 0.5664          \n",
      "Epoch 122, CIFAR-10 Batch 3:  cost= 1.0397           train_acc= 0.6014           valid_acc= 0.5722          \n",
      "Epoch 122, CIFAR-10 Batch 4:  cost= 1.0296           train_acc= 0.6486           valid_acc= 0.5608          \n",
      "Epoch 122, CIFAR-10 Batch 5:  cost= 1.0138           train_acc= 0.6216           valid_acc= 0.5788          \n",
      "Epoch 123, CIFAR-10 Batch 1:  cost= 1.1487           train_acc= 0.5642           valid_acc= 0.5868          \n",
      "Epoch 123, CIFAR-10 Batch 2:  cost= 1.1216           train_acc= 0.5811           valid_acc= 0.5688          \n",
      "Epoch 123, CIFAR-10 Batch 3:  cost= 1.0127           train_acc= 0.6182           valid_acc= 0.5780          \n",
      "Epoch 123, CIFAR-10 Batch 4:  cost= 1.0702           train_acc= 0.6182           valid_acc= 0.5534          \n",
      "Epoch 123, CIFAR-10 Batch 5:  cost= 1.0146           train_acc= 0.6351           valid_acc= 0.5824          \n",
      "Epoch 124, CIFAR-10 Batch 1:  cost= 1.1675           train_acc= 0.5642           valid_acc= 0.5758          \n",
      "Epoch 124, CIFAR-10 Batch 2:  cost= 1.1131           train_acc= 0.5777           valid_acc= 0.5650          \n",
      "Epoch 124, CIFAR-10 Batch 3:  cost= 1.0436           train_acc= 0.5980           valid_acc= 0.5618          \n",
      "Epoch 124, CIFAR-10 Batch 4:  cost= 0.9488           train_acc= 0.6926           valid_acc= 0.6028          \n",
      "Epoch 124, CIFAR-10 Batch 5:  cost= 1.0111           train_acc= 0.6419           valid_acc= 0.5918          \n",
      "Epoch 125, CIFAR-10 Batch 1:  cost= 1.1026           train_acc= 0.5912           valid_acc= 0.5972          \n",
      "Epoch 125, CIFAR-10 Batch 2:  cost= 1.1097           train_acc= 0.6182           valid_acc= 0.5928          \n",
      "Epoch 125, CIFAR-10 Batch 3:  cost= 0.9892           train_acc= 0.6081           valid_acc= 0.5850          \n",
      "Epoch 125, CIFAR-10 Batch 4:  cost= 0.9782           train_acc= 0.6757           valid_acc= 0.5904          \n",
      "Epoch 125, CIFAR-10 Batch 5:  cost= 0.9870           train_acc= 0.6351           valid_acc= 0.5956          \n",
      "Epoch 126, CIFAR-10 Batch 1:  cost= 1.1535           train_acc= 0.5743           valid_acc= 0.5908          \n",
      "Epoch 126, CIFAR-10 Batch 2:  cost= 1.1726           train_acc= 0.5878           valid_acc= 0.5678          \n",
      "Epoch 126, CIFAR-10 Batch 3:  cost= 1.0668           train_acc= 0.6014           valid_acc= 0.5616          \n",
      "Epoch 126, CIFAR-10 Batch 4:  cost= 0.9977           train_acc= 0.6554           valid_acc= 0.5768          \n",
      "Epoch 126, CIFAR-10 Batch 5:  cost= 1.0056           train_acc= 0.6453           valid_acc= 0.5672          \n",
      "Epoch 127, CIFAR-10 Batch 1:  cost= 1.1138           train_acc= 0.6047           valid_acc= 0.5964          \n",
      "Epoch 127, CIFAR-10 Batch 2:  cost= 1.0539           train_acc= 0.6419           valid_acc= 0.5884          \n",
      "Epoch 127, CIFAR-10 Batch 3:  cost= 1.0360           train_acc= 0.6284           valid_acc= 0.5726          \n",
      "Epoch 127, CIFAR-10 Batch 4:  cost= 1.0043           train_acc= 0.6588           valid_acc= 0.5854          \n",
      "Epoch 127, CIFAR-10 Batch 5:  cost= 0.9699           train_acc= 0.6554           valid_acc= 0.5978          \n",
      "Epoch 128, CIFAR-10 Batch 1:  cost= 1.0989           train_acc= 0.6216           valid_acc= 0.6026          \n",
      "Epoch 128, CIFAR-10 Batch 2:  cost= 1.1037           train_acc= 0.6115           valid_acc= 0.5796          \n",
      "Epoch 128, CIFAR-10 Batch 3:  cost= 1.0916           train_acc= 0.5709           valid_acc= 0.5526          \n",
      "Epoch 128, CIFAR-10 Batch 4:  cost= 0.9800           train_acc= 0.6858           valid_acc= 0.5866          \n",
      "Epoch 128, CIFAR-10 Batch 5:  cost= 1.0095           train_acc= 0.6351           valid_acc= 0.5818          \n",
      "Epoch 129, CIFAR-10 Batch 1:  cost= 1.1689           train_acc= 0.5574           valid_acc= 0.5824          \n",
      "Epoch 129, CIFAR-10 Batch 2:  cost= 1.0586           train_acc= 0.6385           valid_acc= 0.5944          \n",
      "Epoch 129, CIFAR-10 Batch 3:  cost= 0.9881           train_acc= 0.6284           valid_acc= 0.5792          \n",
      "Epoch 129, CIFAR-10 Batch 4:  cost= 1.0039           train_acc= 0.6588           valid_acc= 0.5724          \n",
      "Epoch 129, CIFAR-10 Batch 5:  cost= 0.9722           train_acc= 0.6622           valid_acc= 0.5838          \n",
      "Epoch 130, CIFAR-10 Batch 1:  cost= 1.1471           train_acc= 0.5878           valid_acc= 0.5890          \n",
      "Epoch 130, CIFAR-10 Batch 2:  cost= 1.1085           train_acc= 0.5946           valid_acc= 0.5784          \n",
      "Epoch 130, CIFAR-10 Batch 3:  cost= 1.0306           train_acc= 0.6284           valid_acc= 0.5690          \n",
      "Epoch 130, CIFAR-10 Batch 4:  cost= 0.9990           train_acc= 0.6622           valid_acc= 0.5824          \n",
      "Epoch 130, CIFAR-10 Batch 5:  cost= 1.0257           train_acc= 0.6081           valid_acc= 0.5800          \n",
      "Epoch 131, CIFAR-10 Batch 1:  cost= 1.1143           train_acc= 0.6115           valid_acc= 0.6082          \n",
      "Epoch 131, CIFAR-10 Batch 2:  cost= 1.1109           train_acc= 0.6081           valid_acc= 0.5904          \n",
      "Epoch 131, CIFAR-10 Batch 3:  cost= 1.0778           train_acc= 0.5777           valid_acc= 0.5608          \n",
      "Epoch 131, CIFAR-10 Batch 4:  cost= 0.9602           train_acc= 0.6858           valid_acc= 0.5864          \n",
      "Epoch 131, CIFAR-10 Batch 5:  cost= 1.0233           train_acc= 0.6149           valid_acc= 0.5810          \n",
      "Epoch 132, CIFAR-10 Batch 1:  cost= 1.1620           train_acc= 0.5845           valid_acc= 0.5788          \n",
      "Epoch 132, CIFAR-10 Batch 2:  cost= 1.0564           train_acc= 0.6216           valid_acc= 0.6060          \n",
      "Epoch 132, CIFAR-10 Batch 3:  cost= 1.0590           train_acc= 0.5912           valid_acc= 0.5604          \n",
      "Epoch 132, CIFAR-10 Batch 4:  cost= 0.9851           train_acc= 0.6791           valid_acc= 0.5864          \n",
      "Epoch 132, CIFAR-10 Batch 5:  cost= 0.9995           train_acc= 0.6115           valid_acc= 0.5860          \n",
      "Epoch 133, CIFAR-10 Batch 1:  cost= 1.0962           train_acc= 0.6081           valid_acc= 0.5984          \n",
      "Epoch 133, CIFAR-10 Batch 2:  cost= 1.0660           train_acc= 0.6149           valid_acc= 0.5914          \n",
      "Epoch 133, CIFAR-10 Batch 3:  cost= 1.0178           train_acc= 0.6318           valid_acc= 0.5712          \n",
      "Epoch 133, CIFAR-10 Batch 4:  cost= 0.9562           train_acc= 0.6926           valid_acc= 0.6022          \n",
      "Epoch 133, CIFAR-10 Batch 5:  cost= 0.9981           train_acc= 0.6182           valid_acc= 0.5838          \n",
      "Epoch 134, CIFAR-10 Batch 1:  cost= 1.1207           train_acc= 0.5743           valid_acc= 0.5972          \n",
      "Epoch 134, CIFAR-10 Batch 2:  cost= 1.0594           train_acc= 0.6216           valid_acc= 0.5958          \n",
      "Epoch 134, CIFAR-10 Batch 3:  cost= 1.0083           train_acc= 0.6588           valid_acc= 0.5828          \n",
      "Epoch 134, CIFAR-10 Batch 4:  cost= 1.0310           train_acc= 0.6419           valid_acc= 0.5670          \n",
      "Epoch 134, CIFAR-10 Batch 5:  cost= 1.0105           train_acc= 0.6318           valid_acc= 0.5864          \n",
      "Epoch 135, CIFAR-10 Batch 1:  cost= 1.0761           train_acc= 0.6284           valid_acc= 0.6072          \n",
      "Epoch 135, CIFAR-10 Batch 2:  cost= 1.1414           train_acc= 0.5777           valid_acc= 0.5646          \n",
      "Epoch 135, CIFAR-10 Batch 3:  cost= 1.0931           train_acc= 0.5811           valid_acc= 0.5606          \n",
      "Epoch 135, CIFAR-10 Batch 4:  cost= 1.0246           train_acc= 0.6554           valid_acc= 0.5636          \n",
      "Epoch 135, CIFAR-10 Batch 5:  cost= 1.0566           train_acc= 0.5845           valid_acc= 0.5572          \n",
      "Epoch 136, CIFAR-10 Batch 1:  cost= 1.1074           train_acc= 0.6149           valid_acc= 0.5900          \n",
      "Epoch 136, CIFAR-10 Batch 2:  cost= 1.0896           train_acc= 0.6047           valid_acc= 0.5944          \n",
      "Epoch 136, CIFAR-10 Batch 3:  cost= 1.1084           train_acc= 0.5676           valid_acc= 0.5450          \n",
      "Epoch 136, CIFAR-10 Batch 4:  cost= 0.9509           train_acc= 0.6824           valid_acc= 0.5896          \n",
      "Epoch 136, CIFAR-10 Batch 5:  cost= 1.0172           train_acc= 0.6385           valid_acc= 0.5828          \n",
      "Epoch 137, CIFAR-10 Batch 1:  cost= 1.1062           train_acc= 0.6149           valid_acc= 0.5994          \n",
      "Epoch 137, CIFAR-10 Batch 2:  cost= 1.1642           train_acc= 0.5709           valid_acc= 0.5654          \n",
      "Epoch 137, CIFAR-10 Batch 3:  cost= 1.0632           train_acc= 0.6351           valid_acc= 0.5652          \n",
      "Epoch 137, CIFAR-10 Batch 4:  cost= 1.0072           train_acc= 0.6655           valid_acc= 0.5760          \n",
      "Epoch 137, CIFAR-10 Batch 5:  cost= 0.9800           train_acc= 0.6520           valid_acc= 0.5912          \n",
      "Epoch 138, CIFAR-10 Batch 1:  cost= 1.1314           train_acc= 0.5980           valid_acc= 0.6004          \n",
      "Epoch 138, CIFAR-10 Batch 2:  cost= 1.1005           train_acc= 0.6216           valid_acc= 0.5792          \n",
      "Epoch 138, CIFAR-10 Batch 3:  cost= 1.0802           train_acc= 0.6047           valid_acc= 0.5660          \n",
      "Epoch 138, CIFAR-10 Batch 4:  cost= 0.9416           train_acc= 0.6824           valid_acc= 0.5984          \n",
      "Epoch 138, CIFAR-10 Batch 5:  cost= 0.9856           train_acc= 0.6419           valid_acc= 0.5840          \n",
      "Epoch 139, CIFAR-10 Batch 1:  cost= 1.0939           train_acc= 0.6284           valid_acc= 0.6036          \n",
      "Epoch 139, CIFAR-10 Batch 2:  cost= 1.0837           train_acc= 0.6149           valid_acc= 0.5850          \n",
      "Epoch 139, CIFAR-10 Batch 3:  cost= 1.0255           train_acc= 0.6284           valid_acc= 0.5768          \n",
      "Epoch 139, CIFAR-10 Batch 4:  cost= 1.0380           train_acc= 0.6520           valid_acc= 0.5706          \n",
      "Epoch 139, CIFAR-10 Batch 5:  cost= 0.9862           train_acc= 0.6351           valid_acc= 0.5892          \n",
      "Epoch 140, CIFAR-10 Batch 1:  cost= 1.1000           train_acc= 0.6149           valid_acc= 0.5984          \n",
      "Epoch 140, CIFAR-10 Batch 2:  cost= 1.1110           train_acc= 0.6182           valid_acc= 0.5642          \n",
      "Epoch 140, CIFAR-10 Batch 3:  cost= 1.0601           train_acc= 0.6047           valid_acc= 0.5650          \n",
      "Epoch 140, CIFAR-10 Batch 4:  cost= 0.9794           train_acc= 0.6926           valid_acc= 0.5804          \n",
      "Epoch 140, CIFAR-10 Batch 5:  cost= 1.0245           train_acc= 0.6014           valid_acc= 0.5782          \n",
      "Epoch 141, CIFAR-10 Batch 1:  cost= 1.0745           train_acc= 0.6115           valid_acc= 0.6062          \n",
      "Epoch 141, CIFAR-10 Batch 2:  cost= 1.0475           train_acc= 0.6081           valid_acc= 0.5896          \n",
      "Epoch 141, CIFAR-10 Batch 3:  cost= 1.0515           train_acc= 0.6047           valid_acc= 0.5662          \n",
      "Epoch 141, CIFAR-10 Batch 4:  cost= 0.9581           train_acc= 0.6959           valid_acc= 0.5920          \n",
      "Epoch 141, CIFAR-10 Batch 5:  cost= 0.9783           train_acc= 0.6182           valid_acc= 0.5996          \n",
      "Epoch 142, CIFAR-10 Batch 1:  cost= 1.0664           train_acc= 0.6284           valid_acc= 0.6116          \n",
      "Epoch 142, CIFAR-10 Batch 2:  cost= 1.0820           train_acc= 0.6115           valid_acc= 0.5848          \n",
      "Epoch 142, CIFAR-10 Batch 3:  cost= 1.0099           train_acc= 0.6453           valid_acc= 0.5782          \n",
      "Epoch 142, CIFAR-10 Batch 4:  cost= 1.0462           train_acc= 0.6216           valid_acc= 0.5630          \n",
      "Epoch 142, CIFAR-10 Batch 5:  cost= 0.9891           train_acc= 0.6351           valid_acc= 0.5902          \n",
      "Epoch 143, CIFAR-10 Batch 1:  cost= 1.1015           train_acc= 0.6081           valid_acc= 0.6090          \n",
      "Epoch 143, CIFAR-10 Batch 2:  cost= 1.1037           train_acc= 0.6182           valid_acc= 0.5736          \n",
      "Epoch 143, CIFAR-10 Batch 3:  cost= 1.0348           train_acc= 0.6014           valid_acc= 0.5670          \n",
      "Epoch 143, CIFAR-10 Batch 4:  cost= 0.9568           train_acc= 0.7027           valid_acc= 0.5856          \n",
      "Epoch 143, CIFAR-10 Batch 5:  cost= 1.0070           train_acc= 0.6149           valid_acc= 0.5910          \n",
      "Epoch 144, CIFAR-10 Batch 1:  cost= 1.0577           train_acc= 0.6149           valid_acc= 0.6136          \n",
      "Epoch 144, CIFAR-10 Batch 2:  cost= 1.0773           train_acc= 0.6149           valid_acc= 0.5824          \n",
      "Epoch 144, CIFAR-10 Batch 3:  cost= 1.0243           train_acc= 0.6385           valid_acc= 0.5800          \n",
      "Epoch 144, CIFAR-10 Batch 4:  cost= 0.9680           train_acc= 0.6622           valid_acc= 0.5888          \n",
      "Epoch 144, CIFAR-10 Batch 5:  cost= 0.9704           train_acc= 0.6318           valid_acc= 0.5984          \n",
      "Epoch 145, CIFAR-10 Batch 1:  cost= 1.0633           train_acc= 0.6149           valid_acc= 0.6038          \n",
      "Epoch 145, CIFAR-10 Batch 2:  cost= 1.0827           train_acc= 0.6250           valid_acc= 0.5846          \n",
      "Epoch 145, CIFAR-10 Batch 3:  cost= 1.0377           train_acc= 0.6115           valid_acc= 0.5710          \n",
      "Epoch 145, CIFAR-10 Batch 4:  cost= 0.9260           train_acc= 0.7027           valid_acc= 0.6034          \n",
      "Epoch 145, CIFAR-10 Batch 5:  cost= 0.9878           train_acc= 0.6149           valid_acc= 0.5858          \n",
      "Epoch 146, CIFAR-10 Batch 1:  cost= 1.1110           train_acc= 0.6115           valid_acc= 0.5924          \n",
      "Epoch 146, CIFAR-10 Batch 2:  cost= 1.0808           train_acc= 0.6182           valid_acc= 0.5772          \n",
      "Epoch 146, CIFAR-10 Batch 3:  cost= 1.0516           train_acc= 0.6250           valid_acc= 0.5748          \n",
      "Epoch 146, CIFAR-10 Batch 4:  cost= 0.9261           train_acc= 0.6926           valid_acc= 0.6062          \n",
      "Epoch 146, CIFAR-10 Batch 5:  cost= 0.9579           train_acc= 0.6351           valid_acc= 0.5952          \n",
      "Epoch 147, CIFAR-10 Batch 1:  cost= 1.1124           train_acc= 0.5709           valid_acc= 0.5960          \n",
      "Epoch 147, CIFAR-10 Batch 2:  cost= 1.0445           train_acc= 0.6318           valid_acc= 0.5942          \n",
      "Epoch 147, CIFAR-10 Batch 3:  cost= 1.0555           train_acc= 0.6081           valid_acc= 0.5632          \n",
      "Epoch 147, CIFAR-10 Batch 4:  cost= 0.9495           train_acc= 0.6824           valid_acc= 0.5912          \n",
      "Epoch 147, CIFAR-10 Batch 5:  cost= 1.0141           train_acc= 0.6149           valid_acc= 0.5790          \n",
      "Epoch 148, CIFAR-10 Batch 1:  cost= 1.1035           train_acc= 0.5777           valid_acc= 0.6014          \n",
      "Epoch 148, CIFAR-10 Batch 2:  cost= 1.0139           train_acc= 0.6486           valid_acc= 0.6018          \n",
      "Epoch 148, CIFAR-10 Batch 3:  cost= 1.0464           train_acc= 0.6081           valid_acc= 0.5672          \n",
      "Epoch 148, CIFAR-10 Batch 4:  cost= 0.9871           train_acc= 0.6689           valid_acc= 0.5868          \n",
      "Epoch 148, CIFAR-10 Batch 5:  cost= 1.0305           train_acc= 0.6182           valid_acc= 0.5766          \n",
      "Epoch 149, CIFAR-10 Batch 1:  cost= 1.0617           train_acc= 0.6284           valid_acc= 0.6182          \n",
      "Epoch 149, CIFAR-10 Batch 2:  cost= 1.0818           train_acc= 0.6216           valid_acc= 0.5776          \n",
      "Epoch 149, CIFAR-10 Batch 3:  cost= 1.0270           train_acc= 0.6047           valid_acc= 0.5714          \n",
      "Epoch 149, CIFAR-10 Batch 4:  cost= 0.9972           train_acc= 0.6554           valid_acc= 0.5750          \n",
      "Epoch 149, CIFAR-10 Batch 5:  cost= 0.9627           train_acc= 0.6520           valid_acc= 0.5998          \n",
      "Epoch 150, CIFAR-10 Batch 1:  cost= 1.0700           train_acc= 0.6250           valid_acc= 0.6164          \n",
      "Epoch 150, CIFAR-10 Batch 2:  cost= 1.0757           train_acc= 0.6284           valid_acc= 0.5820          \n",
      "Epoch 150, CIFAR-10 Batch 3:  cost= 1.0338           train_acc= 0.6250           valid_acc= 0.5774          \n",
      "Epoch 150, CIFAR-10 Batch 4:  cost= 0.9920           train_acc= 0.6554           valid_acc= 0.5860          \n",
      "Epoch 150, CIFAR-10 Batch 5:  cost= 0.9681           train_acc= 0.6520           valid_acc= 0.6044          \n",
      "Epoch 151, CIFAR-10 Batch 1:  cost= 1.1168           train_acc= 0.6081           valid_acc= 0.5988          \n",
      "Epoch 151, CIFAR-10 Batch 2:  cost= 1.0593           train_acc= 0.6182           valid_acc= 0.5894          \n",
      "Epoch 151, CIFAR-10 Batch 3:  cost= 0.9487           train_acc= 0.6791           valid_acc= 0.6044          \n",
      "Epoch 151, CIFAR-10 Batch 4:  cost= 0.9972           train_acc= 0.6655           valid_acc= 0.5776          \n",
      "Epoch 151, CIFAR-10 Batch 5:  cost= 0.9666           train_acc= 0.6250           valid_acc= 0.5934          \n",
      "Epoch 152, CIFAR-10 Batch 1:  cost= 1.0245           train_acc= 0.6453           valid_acc= 0.6206          \n",
      "Epoch 152, CIFAR-10 Batch 2:  cost= 1.0747           train_acc= 0.6081           valid_acc= 0.5828          \n",
      "Epoch 152, CIFAR-10 Batch 3:  cost= 1.0163           train_acc= 0.6081           valid_acc= 0.5740          \n",
      "Epoch 152, CIFAR-10 Batch 4:  cost= 0.9462           train_acc= 0.6858           valid_acc= 0.5836          \n",
      "Epoch 152, CIFAR-10 Batch 5:  cost= 1.0288           train_acc= 0.6047           valid_acc= 0.5764          \n",
      "Epoch 153, CIFAR-10 Batch 1:  cost= 1.0131           train_acc= 0.6486           valid_acc= 0.6262          \n",
      "Epoch 153, CIFAR-10 Batch 2:  cost= 1.1004           train_acc= 0.6216           valid_acc= 0.5768          \n",
      "Epoch 153, CIFAR-10 Batch 3:  cost= 1.0327           train_acc= 0.6115           valid_acc= 0.5710          \n",
      "Epoch 153, CIFAR-10 Batch 4:  cost= 0.9443           train_acc= 0.6926           valid_acc= 0.5920          \n",
      "Epoch 153, CIFAR-10 Batch 5:  cost= 0.9556           train_acc= 0.6453           valid_acc= 0.6060          \n",
      "Epoch 154, CIFAR-10 Batch 1:  cost= 1.1254           train_acc= 0.5912           valid_acc= 0.5986          \n",
      "Epoch 154, CIFAR-10 Batch 2:  cost= 1.0459           train_acc= 0.6318           valid_acc= 0.5924          \n",
      "Epoch 154, CIFAR-10 Batch 3:  cost= 1.0176           train_acc= 0.6216           valid_acc= 0.5716          \n",
      "Epoch 154, CIFAR-10 Batch 4:  cost= 0.9295           train_acc= 0.6858           valid_acc= 0.5954          \n",
      "Epoch 154, CIFAR-10 Batch 5:  cost= 0.9257           train_acc= 0.6757           valid_acc= 0.6046          \n",
      "Epoch 155, CIFAR-10 Batch 1:  cost= 1.0816           train_acc= 0.6284           valid_acc= 0.6074          \n",
      "Epoch 155, CIFAR-10 Batch 2:  cost= 1.0674           train_acc= 0.6284           valid_acc= 0.5944          \n",
      "Epoch 155, CIFAR-10 Batch 3:  cost= 0.9817           train_acc= 0.6216           valid_acc= 0.5812          \n",
      "Epoch 155, CIFAR-10 Batch 4:  cost= 0.9818           train_acc= 0.6791           valid_acc= 0.5904          \n",
      "Epoch 155, CIFAR-10 Batch 5:  cost= 1.0216           train_acc= 0.6149           valid_acc= 0.5648          \n",
      "Epoch 156, CIFAR-10 Batch 1:  cost= 1.1033           train_acc= 0.5912           valid_acc= 0.5958          \n",
      "Epoch 156, CIFAR-10 Batch 2:  cost= 1.0351           train_acc= 0.6351           valid_acc= 0.6040          \n",
      "Epoch 156, CIFAR-10 Batch 3:  cost= 1.0169           train_acc= 0.6149           valid_acc= 0.5814          \n",
      "Epoch 156, CIFAR-10 Batch 4:  cost= 0.9968           train_acc= 0.6689           valid_acc= 0.5692          \n",
      "Epoch 156, CIFAR-10 Batch 5:  cost= 0.9391           train_acc= 0.6622           valid_acc= 0.5990          \n",
      "Epoch 157, CIFAR-10 Batch 1:  cost= 1.0698           train_acc= 0.5878           valid_acc= 0.6126          \n",
      "Epoch 157, CIFAR-10 Batch 2:  cost= 1.1086           train_acc= 0.6047           valid_acc= 0.5714          \n",
      "Epoch 157, CIFAR-10 Batch 3:  cost= 1.0519           train_acc= 0.5946           valid_acc= 0.5624          \n",
      "Epoch 157, CIFAR-10 Batch 4:  cost= 0.9527           train_acc= 0.6824           valid_acc= 0.5980          \n",
      "Epoch 157, CIFAR-10 Batch 5:  cost= 0.9887           train_acc= 0.6419           valid_acc= 0.5812          \n",
      "Epoch 158, CIFAR-10 Batch 1:  cost= 1.1230           train_acc= 0.5709           valid_acc= 0.5938          \n",
      "Epoch 158, CIFAR-10 Batch 2:  cost= 1.0695           train_acc= 0.6182           valid_acc= 0.5862          \n",
      "Epoch 158, CIFAR-10 Batch 3:  cost= 1.0857           train_acc= 0.5743           valid_acc= 0.5458          \n",
      "Epoch 158, CIFAR-10 Batch 4:  cost= 0.9505           train_acc= 0.7061           valid_acc= 0.5894          \n",
      "Epoch 158, CIFAR-10 Batch 5:  cost= 1.0297           train_acc= 0.6014           valid_acc= 0.5712          \n",
      "Epoch 159, CIFAR-10 Batch 1:  cost= 1.0326           train_acc= 0.6250           valid_acc= 0.6176          \n",
      "Epoch 159, CIFAR-10 Batch 2:  cost= 1.0421           train_acc= 0.6486           valid_acc= 0.6062          \n",
      "Epoch 159, CIFAR-10 Batch 3:  cost= 1.0701           train_acc= 0.6047           valid_acc= 0.5662          \n",
      "Epoch 159, CIFAR-10 Batch 4:  cost= 0.9794           train_acc= 0.6858           valid_acc= 0.5884          \n",
      "Epoch 159, CIFAR-10 Batch 5:  cost= 0.9963           train_acc= 0.6385           valid_acc= 0.5852          \n",
      "Epoch 160, CIFAR-10 Batch 1:  cost= 1.1154           train_acc= 0.5980           valid_acc= 0.6014          \n",
      "Epoch 160, CIFAR-10 Batch 2:  cost= 1.0355           train_acc= 0.6486           valid_acc= 0.5948          \n",
      "Epoch 160, CIFAR-10 Batch 3:  cost= 0.9521           train_acc= 0.6351           valid_acc= 0.6110          \n",
      "Epoch 160, CIFAR-10 Batch 4:  cost= 0.9824           train_acc= 0.6757           valid_acc= 0.5730          \n",
      "Epoch 160, CIFAR-10 Batch 5:  cost= 0.9891           train_acc= 0.6182           valid_acc= 0.5828          \n",
      "Epoch 161, CIFAR-10 Batch 1:  cost= 1.1151           train_acc= 0.6081           valid_acc= 0.5950          \n",
      "Epoch 161, CIFAR-10 Batch 2:  cost= 1.1486           train_acc= 0.5676           valid_acc= 0.5564          \n",
      "Epoch 161, CIFAR-10 Batch 3:  cost= 0.9442           train_acc= 0.6622           valid_acc= 0.5994          \n",
      "Epoch 161, CIFAR-10 Batch 4:  cost= 0.9472           train_acc= 0.6791           valid_acc= 0.5974          \n",
      "Epoch 161, CIFAR-10 Batch 5:  cost= 0.9707           train_acc= 0.6318           valid_acc= 0.5998          \n",
      "Epoch 162, CIFAR-10 Batch 1:  cost= 1.0808           train_acc= 0.6149           valid_acc= 0.5964          \n",
      "Epoch 162, CIFAR-10 Batch 2:  cost= 1.0744           train_acc= 0.6081           valid_acc= 0.5736          \n",
      "Epoch 162, CIFAR-10 Batch 3:  cost= 0.9402           train_acc= 0.6520           valid_acc= 0.5960          \n",
      "Epoch 162, CIFAR-10 Batch 4:  cost= 0.9602           train_acc= 0.6723           valid_acc= 0.5894          \n",
      "Epoch 162, CIFAR-10 Batch 5:  cost= 0.9991           train_acc= 0.6250           valid_acc= 0.5738          \n",
      "Epoch 163, CIFAR-10 Batch 1:  cost= 1.0325           train_acc= 0.6047           valid_acc= 0.6220          \n",
      "Epoch 163, CIFAR-10 Batch 2:  cost= 1.0404           train_acc= 0.6385           valid_acc= 0.5914          \n",
      "Epoch 163, CIFAR-10 Batch 3:  cost= 1.0160           train_acc= 0.6318           valid_acc= 0.5824          \n",
      "Epoch 163, CIFAR-10 Batch 4:  cost= 0.9882           train_acc= 0.6385           valid_acc= 0.5882          \n",
      "Epoch 163, CIFAR-10 Batch 5:  cost= 1.0269           train_acc= 0.6149           valid_acc= 0.5648          \n",
      "Epoch 164, CIFAR-10 Batch 1:  cost= 1.0448           train_acc= 0.6149           valid_acc= 0.6166          \n",
      "Epoch 164, CIFAR-10 Batch 2:  cost= 1.0718           train_acc= 0.6351           valid_acc= 0.5710          \n",
      "Epoch 164, CIFAR-10 Batch 3:  cost= 1.0959           train_acc= 0.5811           valid_acc= 0.5576          \n",
      "Epoch 164, CIFAR-10 Batch 4:  cost= 0.9024           train_acc= 0.7095           valid_acc= 0.6128          \n",
      "Epoch 164, CIFAR-10 Batch 5:  cost= 1.0070           train_acc= 0.6250           valid_acc= 0.5770          \n",
      "Epoch 165, CIFAR-10 Batch 1:  cost= 1.0450           train_acc= 0.6250           valid_acc= 0.6186          \n",
      "Epoch 165, CIFAR-10 Batch 2:  cost= 1.0705           train_acc= 0.6318           valid_acc= 0.5832          \n",
      "Epoch 165, CIFAR-10 Batch 3:  cost= 1.0065           train_acc= 0.6622           valid_acc= 0.5800          \n",
      "Epoch 165, CIFAR-10 Batch 4:  cost= 1.0052           train_acc= 0.6588           valid_acc= 0.5656          \n",
      "Epoch 165, CIFAR-10 Batch 5:  cost= 0.9915           train_acc= 0.6149           valid_acc= 0.5798          \n",
      "Epoch 166, CIFAR-10 Batch 1:  cost= 1.1025           train_acc= 0.5980           valid_acc= 0.6054          \n",
      "Epoch 166, CIFAR-10 Batch 2:  cost= 1.0421           train_acc= 0.6486           valid_acc= 0.5904          \n",
      "Epoch 166, CIFAR-10 Batch 3:  cost= 1.0303           train_acc= 0.6216           valid_acc= 0.5710          \n",
      "Epoch 166, CIFAR-10 Batch 4:  cost= 0.9686           train_acc= 0.6689           valid_acc= 0.5792          \n",
      "Epoch 166, CIFAR-10 Batch 5:  cost= 0.9559           train_acc= 0.6791           valid_acc= 0.6034          \n",
      "Epoch 167, CIFAR-10 Batch 1:  cost= 1.0578           train_acc= 0.5878           valid_acc= 0.6150          \n",
      "Epoch 167, CIFAR-10 Batch 2:  cost= 1.0482           train_acc= 0.6149           valid_acc= 0.5854          \n",
      "Epoch 167, CIFAR-10 Batch 3:  cost= 1.0229           train_acc= 0.6419           valid_acc= 0.5678          \n",
      "Epoch 167, CIFAR-10 Batch 4:  cost= 0.9534           train_acc= 0.6824           valid_acc= 0.5886          \n",
      "Epoch 167, CIFAR-10 Batch 5:  cost= 0.9808           train_acc= 0.6284           valid_acc= 0.5776          \n",
      "Epoch 168, CIFAR-10 Batch 1:  cost= 1.1210           train_acc= 0.6014           valid_acc= 0.5994          \n",
      "Epoch 168, CIFAR-10 Batch 2:  cost= 1.0542           train_acc= 0.6385           valid_acc= 0.5916          \n",
      "Epoch 168, CIFAR-10 Batch 3:  cost= 1.0058           train_acc= 0.6486           valid_acc= 0.5762          \n",
      "Epoch 168, CIFAR-10 Batch 4:  cost= 0.9374           train_acc= 0.6959           valid_acc= 0.5996          \n",
      "Epoch 168, CIFAR-10 Batch 5:  cost= 0.9613           train_acc= 0.6453           valid_acc= 0.5860          \n",
      "Epoch 169, CIFAR-10 Batch 1:  cost= 1.0469           train_acc= 0.6047           valid_acc= 0.5982          \n",
      "Epoch 169, CIFAR-10 Batch 2:  cost= 1.0518           train_acc= 0.6588           valid_acc= 0.6022          \n",
      "Epoch 169, CIFAR-10 Batch 3:  cost= 0.9368           train_acc= 0.6554           valid_acc= 0.6110          \n",
      "Epoch 169, CIFAR-10 Batch 4:  cost= 0.9711           train_acc= 0.6588           valid_acc= 0.5878          \n",
      "Epoch 169, CIFAR-10 Batch 5:  cost= 1.0022           train_acc= 0.6216           valid_acc= 0.5828          \n",
      "Epoch 170, CIFAR-10 Batch 1:  cost= 1.0454           train_acc= 0.6284           valid_acc= 0.6108          \n",
      "Epoch 170, CIFAR-10 Batch 2:  cost= 1.0062           train_acc= 0.6419           valid_acc= 0.6010          \n",
      "Epoch 170, CIFAR-10 Batch 3:  cost= 1.0483           train_acc= 0.6115           valid_acc= 0.5662          \n",
      "Epoch 170, CIFAR-10 Batch 4:  cost= 0.9144           train_acc= 0.6993           valid_acc= 0.6168          \n",
      "Epoch 170, CIFAR-10 Batch 5:  cost= 0.9302           train_acc= 0.6723           valid_acc= 0.5952          \n",
      "Epoch 171, CIFAR-10 Batch 1:  cost= 1.1235           train_acc= 0.5811           valid_acc= 0.5874          \n",
      "Epoch 171, CIFAR-10 Batch 2:  cost= 1.0530           train_acc= 0.6318           valid_acc= 0.5728          \n",
      "Epoch 171, CIFAR-10 Batch 3:  cost= 1.0094           train_acc= 0.6182           valid_acc= 0.5820          \n",
      "Epoch 171, CIFAR-10 Batch 4:  cost= 0.9778           train_acc= 0.6858           valid_acc= 0.5834          \n",
      "Epoch 171, CIFAR-10 Batch 5:  cost= 0.9621           train_acc= 0.6655           valid_acc= 0.5916          \n",
      "Epoch 172, CIFAR-10 Batch 1:  cost= 1.0299           train_acc= 0.6216           valid_acc= 0.6190          \n",
      "Epoch 172, CIFAR-10 Batch 2:  cost= 1.0898           train_acc= 0.6385           valid_acc= 0.5804          \n",
      "Epoch 172, CIFAR-10 Batch 3:  cost= 1.0041           train_acc= 0.6385           valid_acc= 0.5790          \n",
      "Epoch 172, CIFAR-10 Batch 4:  cost= 0.9897           train_acc= 0.6486           valid_acc= 0.5820          \n",
      "Epoch 172, CIFAR-10 Batch 5:  cost= 0.9433           train_acc= 0.6655           valid_acc= 0.5940          \n",
      "Epoch 173, CIFAR-10 Batch 1:  cost= 1.1518           train_acc= 0.5642           valid_acc= 0.5828          \n",
      "Epoch 173, CIFAR-10 Batch 2:  cost= 1.0384           train_acc= 0.6385           valid_acc= 0.5872          \n",
      "Epoch 173, CIFAR-10 Batch 3:  cost= 1.0500           train_acc= 0.6115           valid_acc= 0.5644          \n",
      "Epoch 173, CIFAR-10 Batch 4:  cost= 0.9280           train_acc= 0.6858           valid_acc= 0.5974          \n",
      "Epoch 173, CIFAR-10 Batch 5:  cost= 0.9628           train_acc= 0.6723           valid_acc= 0.5826          \n",
      "Epoch 174, CIFAR-10 Batch 1:  cost= 1.0312           train_acc= 0.6014           valid_acc= 0.6172          \n",
      "Epoch 174, CIFAR-10 Batch 2:  cost= 1.0280           train_acc= 0.6486           valid_acc= 0.5872          \n",
      "Epoch 174, CIFAR-10 Batch 3:  cost= 0.9730           train_acc= 0.6419           valid_acc= 0.5814          \n",
      "Epoch 174, CIFAR-10 Batch 4:  cost= 0.9517           train_acc= 0.6723           valid_acc= 0.5876          \n",
      "Epoch 174, CIFAR-10 Batch 5:  cost= 0.9911           train_acc= 0.6351           valid_acc= 0.5774          \n",
      "Epoch 175, CIFAR-10 Batch 1:  cost= 1.0815           train_acc= 0.6419           valid_acc= 0.5960          \n",
      "Epoch 175, CIFAR-10 Batch 2:  cost= 1.0273           train_acc= 0.6453           valid_acc= 0.5950          \n",
      "Epoch 175, CIFAR-10 Batch 3:  cost= 1.0312           train_acc= 0.6014           valid_acc= 0.5570          \n",
      "Epoch 175, CIFAR-10 Batch 4:  cost= 0.9005           train_acc= 0.6959           valid_acc= 0.6166          \n",
      "Epoch 175, CIFAR-10 Batch 5:  cost= 0.9999           train_acc= 0.6385           valid_acc= 0.5742          \n",
      "Epoch 176, CIFAR-10 Batch 1:  cost= 1.0915           train_acc= 0.6047           valid_acc= 0.6012          \n",
      "Epoch 176, CIFAR-10 Batch 2:  cost= 1.0318           train_acc= 0.6520           valid_acc= 0.5978          \n",
      "Epoch 176, CIFAR-10 Batch 3:  cost= 0.9508           train_acc= 0.6486           valid_acc= 0.5852          \n",
      "Epoch 176, CIFAR-10 Batch 4:  cost= 0.9396           train_acc= 0.6723           valid_acc= 0.5912          \n",
      "Epoch 176, CIFAR-10 Batch 5:  cost= 0.9783           train_acc= 0.6453           valid_acc= 0.5816          \n",
      "Epoch 177, CIFAR-10 Batch 1:  cost= 0.9961           train_acc= 0.6385           valid_acc= 0.6218          \n",
      "Epoch 177, CIFAR-10 Batch 2:  cost= 1.0167           train_acc= 0.6588           valid_acc= 0.5998          \n",
      "Epoch 177, CIFAR-10 Batch 3:  cost= 0.9748           train_acc= 0.6284           valid_acc= 0.5758          \n",
      "Epoch 177, CIFAR-10 Batch 4:  cost= 0.9998           train_acc= 0.6689           valid_acc= 0.5798          \n",
      "Epoch 177, CIFAR-10 Batch 5:  cost= 0.9451           train_acc= 0.6723           valid_acc= 0.6022          \n",
      "Epoch 178, CIFAR-10 Batch 1:  cost= 0.9996           train_acc= 0.6351           valid_acc= 0.6254          \n",
      "Epoch 178, CIFAR-10 Batch 2:  cost= 1.0339           train_acc= 0.6554           valid_acc= 0.5872          \n",
      "Epoch 178, CIFAR-10 Batch 3:  cost= 0.9527           train_acc= 0.6622           valid_acc= 0.5882          \n",
      "Epoch 178, CIFAR-10 Batch 4:  cost= 0.9355           train_acc= 0.6723           valid_acc= 0.5920          \n",
      "Epoch 178, CIFAR-10 Batch 5:  cost= 0.9804           train_acc= 0.6351           valid_acc= 0.5722          \n",
      "Epoch 179, CIFAR-10 Batch 1:  cost= 1.1075           train_acc= 0.6047           valid_acc= 0.5988          \n",
      "Epoch 179, CIFAR-10 Batch 2:  cost= 1.0254           train_acc= 0.6588           valid_acc= 0.5864          \n",
      "Epoch 179, CIFAR-10 Batch 3:  cost= 1.0135           train_acc= 0.6250           valid_acc= 0.5730          \n",
      "Epoch 179, CIFAR-10 Batch 4:  cost= 0.9669           train_acc= 0.6723           valid_acc= 0.5852          \n",
      "Epoch 179, CIFAR-10 Batch 5:  cost= 0.9701           train_acc= 0.6554           valid_acc= 0.5746          \n",
      "Epoch 180, CIFAR-10 Batch 1:  cost= 1.1013           train_acc= 0.5980           valid_acc= 0.5988          \n",
      "Epoch 180, CIFAR-10 Batch 2:  cost= 1.0532           train_acc= 0.6250           valid_acc= 0.5834          \n",
      "Epoch 180, CIFAR-10 Batch 3:  cost= 0.9630           train_acc= 0.6486           valid_acc= 0.5854          \n",
      "Epoch 180, CIFAR-10 Batch 4:  cost= 0.9577           train_acc= 0.6622           valid_acc= 0.5836          \n",
      "Epoch 180, CIFAR-10 Batch 5:  cost= 0.9686           train_acc= 0.6284           valid_acc= 0.5850          \n",
      "Epoch 181, CIFAR-10 Batch 1:  cost= 1.0533           train_acc= 0.6385           valid_acc= 0.6050          \n",
      "Epoch 181, CIFAR-10 Batch 2:  cost= 1.0421           train_acc= 0.6486           valid_acc= 0.5860          \n",
      "Epoch 181, CIFAR-10 Batch 3:  cost= 0.9759           train_acc= 0.6554           valid_acc= 0.5780          \n",
      "Epoch 181, CIFAR-10 Batch 4:  cost= 1.0047           train_acc= 0.6622           valid_acc= 0.5610          \n",
      "Epoch 181, CIFAR-10 Batch 5:  cost= 0.9483           train_acc= 0.6419           valid_acc= 0.5996          \n",
      "Epoch 182, CIFAR-10 Batch 1:  cost= 1.0901           train_acc= 0.6149           valid_acc= 0.5944          \n",
      "Epoch 182, CIFAR-10 Batch 2:  cost= 1.0062           train_acc= 0.6453           valid_acc= 0.5980          \n",
      "Epoch 182, CIFAR-10 Batch 3:  cost= 0.9395           train_acc= 0.6520           valid_acc= 0.5974          \n",
      "Epoch 182, CIFAR-10 Batch 4:  cost= 0.9600           train_acc= 0.6622           valid_acc= 0.5922          \n",
      "Epoch 182, CIFAR-10 Batch 5:  cost= 0.9586           train_acc= 0.6554           valid_acc= 0.5946          \n",
      "Epoch 183, CIFAR-10 Batch 1:  cost= 1.0455           train_acc= 0.6351           valid_acc= 0.6104          \n",
      "Epoch 183, CIFAR-10 Batch 2:  cost= 1.1013           train_acc= 0.6149           valid_acc= 0.5608          \n",
      "Epoch 183, CIFAR-10 Batch 3:  cost= 1.0111           train_acc= 0.6453           valid_acc= 0.5776          \n",
      "Epoch 183, CIFAR-10 Batch 4:  cost= 0.9220           train_acc= 0.6858           valid_acc= 0.5924          \n",
      "Epoch 183, CIFAR-10 Batch 5:  cost= 0.9425           train_acc= 0.6588           valid_acc= 0.6006          \n",
      "Epoch 184, CIFAR-10 Batch 1:  cost= 1.1177           train_acc= 0.5811           valid_acc= 0.5928          \n",
      "Epoch 184, CIFAR-10 Batch 2:  cost= 1.0779           train_acc= 0.6182           valid_acc= 0.5762          \n",
      "Epoch 184, CIFAR-10 Batch 3:  cost= 0.9578           train_acc= 0.6318           valid_acc= 0.5848          \n",
      "Epoch 184, CIFAR-10 Batch 4:  cost= 0.9668           train_acc= 0.6723           valid_acc= 0.5918          \n",
      "Epoch 184, CIFAR-10 Batch 5:  cost= 0.9327           train_acc= 0.6453           valid_acc= 0.6052          \n",
      "Epoch 185, CIFAR-10 Batch 1:  cost= 1.0526           train_acc= 0.6216           valid_acc= 0.6130          \n",
      "Epoch 185, CIFAR-10 Batch 2:  cost= 1.0811           train_acc= 0.6115           valid_acc= 0.5720          \n",
      "Epoch 185, CIFAR-10 Batch 3:  cost= 1.0113           train_acc= 0.6047           valid_acc= 0.5746          \n",
      "Epoch 185, CIFAR-10 Batch 4:  cost= 0.9404           train_acc= 0.6689           valid_acc= 0.5920          \n",
      "Epoch 185, CIFAR-10 Batch 5:  cost= 0.9487           train_acc= 0.6588           valid_acc= 0.5882          \n",
      "Epoch 186, CIFAR-10 Batch 1:  cost= 1.0545           train_acc= 0.6486           valid_acc= 0.6108          \n",
      "Epoch 186, CIFAR-10 Batch 2:  cost= 0.9741           train_acc= 0.6824           valid_acc= 0.6026          \n",
      "Epoch 186, CIFAR-10 Batch 3:  cost= 0.9771           train_acc= 0.6284           valid_acc= 0.5814          \n",
      "Epoch 186, CIFAR-10 Batch 4:  cost= 0.9398           train_acc= 0.6892           valid_acc= 0.6008          \n",
      "Epoch 186, CIFAR-10 Batch 5:  cost= 0.9437           train_acc= 0.6453           valid_acc= 0.5986          \n",
      "Epoch 187, CIFAR-10 Batch 1:  cost= 1.1131           train_acc= 0.5980           valid_acc= 0.5864          \n",
      "Epoch 187, CIFAR-10 Batch 2:  cost= 1.0143           train_acc= 0.6622           valid_acc= 0.5870          \n",
      "Epoch 187, CIFAR-10 Batch 3:  cost= 0.9579           train_acc= 0.6622           valid_acc= 0.5848          \n",
      "Epoch 187, CIFAR-10 Batch 4:  cost= 0.9855           train_acc= 0.6520           valid_acc= 0.5764          \n",
      "Epoch 187, CIFAR-10 Batch 5:  cost= 1.0064           train_acc= 0.6385           valid_acc= 0.5788          \n",
      "Epoch 188, CIFAR-10 Batch 1:  cost= 1.0913           train_acc= 0.6014           valid_acc= 0.6074          \n",
      "Epoch 188, CIFAR-10 Batch 2:  cost= 0.9909           train_acc= 0.6588           valid_acc= 0.6068          \n",
      "Epoch 188, CIFAR-10 Batch 3:  cost= 0.9941           train_acc= 0.6318           valid_acc= 0.5812          \n",
      "Epoch 188, CIFAR-10 Batch 4:  cost= 0.9610           train_acc= 0.6655           valid_acc= 0.5924          \n",
      "Epoch 188, CIFAR-10 Batch 5:  cost= 0.9623           train_acc= 0.6318           valid_acc= 0.5866          \n",
      "Epoch 189, CIFAR-10 Batch 1:  cost= 1.0819           train_acc= 0.6385           valid_acc= 0.6012          \n",
      "Epoch 189, CIFAR-10 Batch 2:  cost= 0.9869           train_acc= 0.6689           valid_acc= 0.6060          \n",
      "Epoch 189, CIFAR-10 Batch 3:  cost= 0.9893           train_acc= 0.6520           valid_acc= 0.5802          \n",
      "Epoch 189, CIFAR-10 Batch 4:  cost= 0.9852           train_acc= 0.6622           valid_acc= 0.5860          \n",
      "Epoch 189, CIFAR-10 Batch 5:  cost= 0.9873           train_acc= 0.6351           valid_acc= 0.5830          \n",
      "Epoch 190, CIFAR-10 Batch 1:  cost= 1.0883           train_acc= 0.6115           valid_acc= 0.6028          \n",
      "Epoch 190, CIFAR-10 Batch 2:  cost= 1.0281           train_acc= 0.6284           valid_acc= 0.5962          \n",
      "Epoch 190, CIFAR-10 Batch 3:  cost= 0.9520           train_acc= 0.6486           valid_acc= 0.5954          \n",
      "Epoch 190, CIFAR-10 Batch 4:  cost= 1.0455           train_acc= 0.6318           valid_acc= 0.5568          \n",
      "Epoch 190, CIFAR-10 Batch 5:  cost= 0.9136           train_acc= 0.6655           valid_acc= 0.6068          \n",
      "Epoch 191, CIFAR-10 Batch 1:  cost= 1.0706           train_acc= 0.6182           valid_acc= 0.6002          \n",
      "Epoch 191, CIFAR-10 Batch 2:  cost= 1.0454           train_acc= 0.6419           valid_acc= 0.5860          \n",
      "Epoch 191, CIFAR-10 Batch 3:  cost= 1.0726           train_acc= 0.6081           valid_acc= 0.5566          \n",
      "Epoch 191, CIFAR-10 Batch 4:  cost= 0.9376           train_acc= 0.6926           valid_acc= 0.6020          \n",
      "Epoch 191, CIFAR-10 Batch 5:  cost= 0.8969           train_acc= 0.6588           valid_acc= 0.6100          \n",
      "Epoch 192, CIFAR-10 Batch 1:  cost= 1.1216           train_acc= 0.6182           valid_acc= 0.5864          \n",
      "Epoch 192, CIFAR-10 Batch 2:  cost= 0.9911           train_acc= 0.6655           valid_acc= 0.5984          \n",
      "Epoch 192, CIFAR-10 Batch 3:  cost= 0.9578           train_acc= 0.6689           valid_acc= 0.5936          \n",
      "Epoch 192, CIFAR-10 Batch 4:  cost= 0.9980           train_acc= 0.6453           valid_acc= 0.5786          \n",
      "Epoch 192, CIFAR-10 Batch 5:  cost= 0.9415           train_acc= 0.6351           valid_acc= 0.6008          \n",
      "Epoch 193, CIFAR-10 Batch 1:  cost= 1.0457           train_acc= 0.6419           valid_acc= 0.6042          \n",
      "Epoch 193, CIFAR-10 Batch 2:  cost= 0.9846           train_acc= 0.6622           valid_acc= 0.5988          \n",
      "Epoch 193, CIFAR-10 Batch 3:  cost= 1.0081           train_acc= 0.6149           valid_acc= 0.5712          \n",
      "Epoch 193, CIFAR-10 Batch 4:  cost= 0.9044           train_acc= 0.6993           valid_acc= 0.6144          \n",
      "Epoch 193, CIFAR-10 Batch 5:  cost= 0.9269           train_acc= 0.6486           valid_acc= 0.5970          \n",
      "Epoch 194, CIFAR-10 Batch 1:  cost= 1.0055           train_acc= 0.6588           valid_acc= 0.6258          \n",
      "Epoch 194, CIFAR-10 Batch 2:  cost= 1.0087           train_acc= 0.6453           valid_acc= 0.5940          \n",
      "Epoch 194, CIFAR-10 Batch 3:  cost= 0.9902           train_acc= 0.6588           valid_acc= 0.5890          \n",
      "Epoch 194, CIFAR-10 Batch 4:  cost= 0.9533           train_acc= 0.6588           valid_acc= 0.5916          \n",
      "Epoch 194, CIFAR-10 Batch 5:  cost= 1.0394           train_acc= 0.6216           valid_acc= 0.5602          \n",
      "Epoch 195, CIFAR-10 Batch 1:  cost= 1.0656           train_acc= 0.6486           valid_acc= 0.6012          \n",
      "Epoch 195, CIFAR-10 Batch 2:  cost= 1.1274           train_acc= 0.5878           valid_acc= 0.5572          \n",
      "Epoch 195, CIFAR-10 Batch 3:  cost= 0.9366           train_acc= 0.6723           valid_acc= 0.6038          \n",
      "Epoch 195, CIFAR-10 Batch 4:  cost= 1.0018           train_acc= 0.6588           valid_acc= 0.5774          \n",
      "Epoch 195, CIFAR-10 Batch 5:  cost= 0.9552           train_acc= 0.6318           valid_acc= 0.5878          \n",
      "Epoch 196, CIFAR-10 Batch 1:  cost= 1.0989           train_acc= 0.6047           valid_acc= 0.5908          \n",
      "Epoch 196, CIFAR-10 Batch 2:  cost= 1.0820           train_acc= 0.6182           valid_acc= 0.5654          \n",
      "Epoch 196, CIFAR-10 Batch 3:  cost= 0.9571           train_acc= 0.6655           valid_acc= 0.5928          \n",
      "Epoch 196, CIFAR-10 Batch 4:  cost= 0.9451           train_acc= 0.6655           valid_acc= 0.5982          \n",
      "Epoch 196, CIFAR-10 Batch 5:  cost= 0.9215           train_acc= 0.6486           valid_acc= 0.6068          \n",
      "Epoch 197, CIFAR-10 Batch 1:  cost= 1.0692           train_acc= 0.6182           valid_acc= 0.6066          \n",
      "Epoch 197, CIFAR-10 Batch 2:  cost= 0.9869           train_acc= 0.6554           valid_acc= 0.5952          \n",
      "Epoch 197, CIFAR-10 Batch 3:  cost= 0.9438           train_acc= 0.6622           valid_acc= 0.5846          \n",
      "Epoch 197, CIFAR-10 Batch 4:  cost= 1.0098           train_acc= 0.6655           valid_acc= 0.5808          \n",
      "Epoch 197, CIFAR-10 Batch 5:  cost= 0.9380           train_acc= 0.6588           valid_acc= 0.5982          \n",
      "Epoch 198, CIFAR-10 Batch 1:  cost= 1.0296           train_acc= 0.6554           valid_acc= 0.6150          \n",
      "Epoch 198, CIFAR-10 Batch 2:  cost= 0.9852           train_acc= 0.6723           valid_acc= 0.5968          \n",
      "Epoch 198, CIFAR-10 Batch 3:  cost= 0.9550           train_acc= 0.6824           valid_acc= 0.5946          \n",
      "Epoch 198, CIFAR-10 Batch 4:  cost= 0.9429           train_acc= 0.6486           valid_acc= 0.5948          \n",
      "Epoch 198, CIFAR-10 Batch 5:  cost= 0.9350           train_acc= 0.6351           valid_acc= 0.5946          \n",
      "Epoch 199, CIFAR-10 Batch 1:  cost= 1.0787           train_acc= 0.6149           valid_acc= 0.6100          \n",
      "Epoch 199, CIFAR-10 Batch 2:  cost= 1.0405           train_acc= 0.6351           valid_acc= 0.5724          \n",
      "Epoch 199, CIFAR-10 Batch 3:  cost= 0.9927           train_acc= 0.6486           valid_acc= 0.5748          \n",
      "Epoch 199, CIFAR-10 Batch 4:  cost= 0.9891           train_acc= 0.6588           valid_acc= 0.5756          \n",
      "Epoch 199, CIFAR-10 Batch 5:  cost= 1.0133           train_acc= 0.6216           valid_acc= 0.5796          \n",
      "Epoch 200, CIFAR-10 Batch 1:  cost= 1.0431           train_acc= 0.6014           valid_acc= 0.6124          \n",
      "Epoch 200, CIFAR-10 Batch 2:  cost= 1.0679           train_acc= 0.6351           valid_acc= 0.5702          \n",
      "Epoch 200, CIFAR-10 Batch 3:  cost= 0.9864           train_acc= 0.6385           valid_acc= 0.5772          \n",
      "Epoch 200, CIFAR-10 Batch 4:  cost= 0.9397           train_acc= 0.6655           valid_acc= 0.6002          \n",
      "Epoch 200, CIFAR-10 Batch 5:  cost= 1.0343           train_acc= 0.6047           valid_acc= 0.5608          \n",
      "Epoch 201, CIFAR-10 Batch 1:  cost= 1.0654           train_acc= 0.6318           valid_acc= 0.6072          \n",
      "Epoch 201, CIFAR-10 Batch 2:  cost= 1.0260           train_acc= 0.6216           valid_acc= 0.5764          \n",
      "Epoch 201, CIFAR-10 Batch 3:  cost= 0.9593           train_acc= 0.6588           valid_acc= 0.5968          \n",
      "Epoch 201, CIFAR-10 Batch 4:  cost= 0.9993           train_acc= 0.6554           valid_acc= 0.5680          \n",
      "Epoch 201, CIFAR-10 Batch 5:  cost= 0.9719           train_acc= 0.6250           valid_acc= 0.5884          \n",
      "Epoch 202, CIFAR-10 Batch 1:  cost= 1.0275           train_acc= 0.6318           valid_acc= 0.6140          \n",
      "Epoch 202, CIFAR-10 Batch 2:  cost= 1.0071           train_acc= 0.6486           valid_acc= 0.5742          \n",
      "Epoch 202, CIFAR-10 Batch 3:  cost= 1.0070           train_acc= 0.6318           valid_acc= 0.5712          \n",
      "Epoch 202, CIFAR-10 Batch 4:  cost= 0.9780           train_acc= 0.6588           valid_acc= 0.5736          \n",
      "Epoch 202, CIFAR-10 Batch 5:  cost= 0.9380           train_acc= 0.6588           valid_acc= 0.5958          \n",
      "Epoch 203, CIFAR-10 Batch 1:  cost= 1.0248           train_acc= 0.6520           valid_acc= 0.6272          \n",
      "Epoch 203, CIFAR-10 Batch 2:  cost= 1.0439           train_acc= 0.6284           valid_acc= 0.5728          \n",
      "Epoch 203, CIFAR-10 Batch 3:  cost= 0.9360           train_acc= 0.6588           valid_acc= 0.5982          \n",
      "Epoch 203, CIFAR-10 Batch 4:  cost= 0.8725           train_acc= 0.7264           valid_acc= 0.6322          \n",
      "Epoch 203, CIFAR-10 Batch 5:  cost= 0.9036           train_acc= 0.6824           valid_acc= 0.6134          \n",
      "Epoch 204, CIFAR-10 Batch 1:  cost= 1.0786           train_acc= 0.6182           valid_acc= 0.5944          \n",
      "Epoch 204, CIFAR-10 Batch 2:  cost= 0.9542           train_acc= 0.6791           valid_acc= 0.6184          \n",
      "Epoch 204, CIFAR-10 Batch 3:  cost= 0.9346           train_acc= 0.6655           valid_acc= 0.5908          \n",
      "Epoch 204, CIFAR-10 Batch 4:  cost= 0.8920           train_acc= 0.7027           valid_acc= 0.6176          \n",
      "Epoch 204, CIFAR-10 Batch 5:  cost= 0.9777           train_acc= 0.6250           valid_acc= 0.5862          \n",
      "Epoch 205, CIFAR-10 Batch 1:  cost= 1.0320           train_acc= 0.6250           valid_acc= 0.6186          \n",
      "Epoch 205, CIFAR-10 Batch 2:  cost= 1.0315           train_acc= 0.6486           valid_acc= 0.5886          \n",
      "Epoch 205, CIFAR-10 Batch 3:  cost= 0.9955           train_acc= 0.6385           valid_acc= 0.5758          \n",
      "Epoch 205, CIFAR-10 Batch 4:  cost= 0.9187           train_acc= 0.6892           valid_acc= 0.6042          \n",
      "Epoch 205, CIFAR-10 Batch 5:  cost= 0.9607           train_acc= 0.6216           valid_acc= 0.5912          \n",
      "Epoch 206, CIFAR-10 Batch 1:  cost= 1.0991           train_acc= 0.6182           valid_acc= 0.5914          \n",
      "Epoch 206, CIFAR-10 Batch 2:  cost= 1.0279           train_acc= 0.6216           valid_acc= 0.5766          \n",
      "Epoch 206, CIFAR-10 Batch 3:  cost= 1.0232           train_acc= 0.6216           valid_acc= 0.5686          \n",
      "Epoch 206, CIFAR-10 Batch 4:  cost= 0.9314           train_acc= 0.6655           valid_acc= 0.6002          \n",
      "Epoch 206, CIFAR-10 Batch 5:  cost= 1.0036           train_acc= 0.6250           valid_acc= 0.5738          \n",
      "Epoch 207, CIFAR-10 Batch 1:  cost= 1.0367           train_acc= 0.6453           valid_acc= 0.6078          \n",
      "Epoch 207, CIFAR-10 Batch 2:  cost= 0.9970           train_acc= 0.6554           valid_acc= 0.6050          \n",
      "Epoch 207, CIFAR-10 Batch 3:  cost= 0.9774           train_acc= 0.6622           valid_acc= 0.5858          \n",
      "Epoch 207, CIFAR-10 Batch 4:  cost= 0.9483           train_acc= 0.6453           valid_acc= 0.5890          \n",
      "Epoch 207, CIFAR-10 Batch 5:  cost= 0.9866           train_acc= 0.6250           valid_acc= 0.5754          \n",
      "Epoch 208, CIFAR-10 Batch 1:  cost= 1.0502           train_acc= 0.6385           valid_acc= 0.6092          \n",
      "Epoch 208, CIFAR-10 Batch 2:  cost= 0.9696           train_acc= 0.6588           valid_acc= 0.5926          \n",
      "Epoch 208, CIFAR-10 Batch 3:  cost= 0.9321           train_acc= 0.6655           valid_acc= 0.6030          \n",
      "Epoch 208, CIFAR-10 Batch 4:  cost= 0.9564           train_acc= 0.6520           valid_acc= 0.5968          \n",
      "Epoch 208, CIFAR-10 Batch 5:  cost= 0.9617           train_acc= 0.6520           valid_acc= 0.5984          \n",
      "Epoch 209, CIFAR-10 Batch 1:  cost= 1.0421           train_acc= 0.6419           valid_acc= 0.6150          \n",
      "Epoch 209, CIFAR-10 Batch 2:  cost= 0.9993           train_acc= 0.6723           valid_acc= 0.5980          \n",
      "Epoch 209, CIFAR-10 Batch 3:  cost= 0.9416           train_acc= 0.6655           valid_acc= 0.5942          \n",
      "Epoch 209, CIFAR-10 Batch 4:  cost= 0.8939           train_acc= 0.7128           valid_acc= 0.6068          \n",
      "Epoch 209, CIFAR-10 Batch 5:  cost= 0.9242           train_acc= 0.6520           valid_acc= 0.5986          \n",
      "Epoch 210, CIFAR-10 Batch 1:  cost= 1.0580           train_acc= 0.6014           valid_acc= 0.6058          \n",
      "Epoch 210, CIFAR-10 Batch 2:  cost= 0.9560           train_acc= 0.6723           valid_acc= 0.6064          \n",
      "Epoch 210, CIFAR-10 Batch 3:  cost= 0.9833           train_acc= 0.6453           valid_acc= 0.5766          \n",
      "Epoch 210, CIFAR-10 Batch 4:  cost= 0.9323           train_acc= 0.6824           valid_acc= 0.5964          \n",
      "Epoch 210, CIFAR-10 Batch 5:  cost= 0.9807           train_acc= 0.6351           valid_acc= 0.5878          \n",
      "Epoch 211, CIFAR-10 Batch 1:  cost= 1.0585           train_acc= 0.6520           valid_acc= 0.6198          \n",
      "Epoch 211, CIFAR-10 Batch 2:  cost= 0.9601           train_acc= 0.6689           valid_acc= 0.6082          \n",
      "Epoch 211, CIFAR-10 Batch 3:  cost= 0.9324           train_acc= 0.6588           valid_acc= 0.5908          \n",
      "Epoch 211, CIFAR-10 Batch 4:  cost= 0.9573           train_acc= 0.6723           valid_acc= 0.5914          \n",
      "Epoch 211, CIFAR-10 Batch 5:  cost= 0.9615           train_acc= 0.6486           valid_acc= 0.5966          \n",
      "Epoch 212, CIFAR-10 Batch 1:  cost= 1.0508           train_acc= 0.6351           valid_acc= 0.6106          \n",
      "Epoch 212, CIFAR-10 Batch 2:  cost= 0.9465           train_acc= 0.6791           valid_acc= 0.6094          \n",
      "Epoch 212, CIFAR-10 Batch 3:  cost= 1.0071           train_acc= 0.6250           valid_acc= 0.5748          \n",
      "Epoch 212, CIFAR-10 Batch 4:  cost= 0.9593           train_acc= 0.6655           valid_acc= 0.5846          \n",
      "Epoch 212, CIFAR-10 Batch 5:  cost= 1.0219           train_acc= 0.6047           valid_acc= 0.5686          \n",
      "Epoch 213, CIFAR-10 Batch 1:  cost= 1.1328           train_acc= 0.5878           valid_acc= 0.5914          \n",
      "Epoch 213, CIFAR-10 Batch 2:  cost= 1.0016           train_acc= 0.6453           valid_acc= 0.5856          \n",
      "Epoch 213, CIFAR-10 Batch 3:  cost= 0.9207           train_acc= 0.6588           valid_acc= 0.6024          \n",
      "Epoch 213, CIFAR-10 Batch 4:  cost= 0.9076           train_acc= 0.6926           valid_acc= 0.6080          \n",
      "Epoch 213, CIFAR-10 Batch 5:  cost= 0.9406           train_acc= 0.6453           valid_acc= 0.6014          \n",
      "Epoch 214, CIFAR-10 Batch 1:  cost= 1.0732           train_acc= 0.6115           valid_acc= 0.5964          \n",
      "Epoch 214, CIFAR-10 Batch 2:  cost= 0.9728           train_acc= 0.6858           valid_acc= 0.6002          \n",
      "Epoch 214, CIFAR-10 Batch 3:  cost= 0.9257           train_acc= 0.6655           valid_acc= 0.5958          \n",
      "Epoch 214, CIFAR-10 Batch 4:  cost= 0.9279           train_acc= 0.6791           valid_acc= 0.5852          \n",
      "Epoch 214, CIFAR-10 Batch 5:  cost= 0.9492           train_acc= 0.6250           valid_acc= 0.5952          \n",
      "Epoch 215, CIFAR-10 Batch 1:  cost= 1.0579           train_acc= 0.6250           valid_acc= 0.6062          \n",
      "Epoch 215, CIFAR-10 Batch 2:  cost= 1.0744           train_acc= 0.6047           valid_acc= 0.5752          \n",
      "Epoch 215, CIFAR-10 Batch 3:  cost= 0.9436           train_acc= 0.6655           valid_acc= 0.5914          \n",
      "Epoch 215, CIFAR-10 Batch 4:  cost= 0.9406           train_acc= 0.6723           valid_acc= 0.6038          \n",
      "Epoch 215, CIFAR-10 Batch 5:  cost= 0.9113           train_acc= 0.6824           valid_acc= 0.6044          \n",
      "Epoch 216, CIFAR-10 Batch 1:  cost= 1.1465           train_acc= 0.5912           valid_acc= 0.5792          \n",
      "Epoch 216, CIFAR-10 Batch 2:  cost= 0.9947           train_acc= 0.6318           valid_acc= 0.5898          \n",
      "Epoch 216, CIFAR-10 Batch 3:  cost= 0.9755           train_acc= 0.6419           valid_acc= 0.5782          \n",
      "Epoch 216, CIFAR-10 Batch 4:  cost= 0.9620           train_acc= 0.6655           valid_acc= 0.5922          \n",
      "Epoch 216, CIFAR-10 Batch 5:  cost= 0.9554           train_acc= 0.6419           valid_acc= 0.5946          \n",
      "Epoch 217, CIFAR-10 Batch 1:  cost= 1.0064           train_acc= 0.6655           valid_acc= 0.6216          \n",
      "Epoch 217, CIFAR-10 Batch 2:  cost= 1.0337           train_acc= 0.6182           valid_acc= 0.5860          \n",
      "Epoch 217, CIFAR-10 Batch 3:  cost= 0.9275           train_acc= 0.6791           valid_acc= 0.5998          \n",
      "Epoch 217, CIFAR-10 Batch 4:  cost= 0.9642           train_acc= 0.6689           valid_acc= 0.5870          \n",
      "Epoch 217, CIFAR-10 Batch 5:  cost= 0.8952           train_acc= 0.6824           valid_acc= 0.6164          \n",
      "Epoch 218, CIFAR-10 Batch 1:  cost= 1.0859           train_acc= 0.6047           valid_acc= 0.5938          \n",
      "Epoch 218, CIFAR-10 Batch 2:  cost= 0.9803           train_acc= 0.6689           valid_acc= 0.6106          \n",
      "Epoch 218, CIFAR-10 Batch 3:  cost= 0.9264           train_acc= 0.6351           valid_acc= 0.6044          \n",
      "Epoch 218, CIFAR-10 Batch 4:  cost= 0.8913           train_acc= 0.6993           valid_acc= 0.6024          \n",
      "Epoch 218, CIFAR-10 Batch 5:  cost= 0.9268           train_acc= 0.6554           valid_acc= 0.6064          \n",
      "Epoch 219, CIFAR-10 Batch 1:  cost= 1.0331           train_acc= 0.6588           valid_acc= 0.6260          \n",
      "Epoch 219, CIFAR-10 Batch 2:  cost= 1.0119           train_acc= 0.6419           valid_acc= 0.5868          \n",
      "Epoch 219, CIFAR-10 Batch 3:  cost= 0.9432           train_acc= 0.6351           valid_acc= 0.5878          \n",
      "Epoch 219, CIFAR-10 Batch 4:  cost= 0.8753           train_acc= 0.7061           valid_acc= 0.6260          \n",
      "Epoch 219, CIFAR-10 Batch 5:  cost= 0.9903           train_acc= 0.6351           valid_acc= 0.5784          \n",
      "Epoch 220, CIFAR-10 Batch 1:  cost= 1.0214           train_acc= 0.6216           valid_acc= 0.6100          \n",
      "Epoch 220, CIFAR-10 Batch 2:  cost= 0.9852           train_acc= 0.6689           valid_acc= 0.6118          \n",
      "Epoch 220, CIFAR-10 Batch 3:  cost= 0.9097           train_acc= 0.6757           valid_acc= 0.6088          \n",
      "Epoch 220, CIFAR-10 Batch 4:  cost= 0.9405           train_acc= 0.6757           valid_acc= 0.6072          \n",
      "Epoch 220, CIFAR-10 Batch 5:  cost= 0.9601           train_acc= 0.6318           valid_acc= 0.5924          \n",
      "Epoch 221, CIFAR-10 Batch 1:  cost= 1.0216           train_acc= 0.6453           valid_acc= 0.6186          \n",
      "Epoch 221, CIFAR-10 Batch 2:  cost= 1.0367           train_acc= 0.6284           valid_acc= 0.5796          \n",
      "Epoch 221, CIFAR-10 Batch 3:  cost= 0.9983           train_acc= 0.6284           valid_acc= 0.5780          \n",
      "Epoch 221, CIFAR-10 Batch 4:  cost= 0.9417           train_acc= 0.6926           valid_acc= 0.5850          \n",
      "Epoch 221, CIFAR-10 Batch 5:  cost= 0.9339           train_acc= 0.6622           valid_acc= 0.6004          \n",
      "Epoch 222, CIFAR-10 Batch 1:  cost= 1.0040           train_acc= 0.6385           valid_acc= 0.6172          \n",
      "Epoch 222, CIFAR-10 Batch 2:  cost= 0.9845           train_acc= 0.6554           valid_acc= 0.5998          \n",
      "Epoch 222, CIFAR-10 Batch 3:  cost= 0.9143           train_acc= 0.6892           valid_acc= 0.6096          \n",
      "Epoch 222, CIFAR-10 Batch 4:  cost= 0.8756           train_acc= 0.7162           valid_acc= 0.6228          \n",
      "Epoch 222, CIFAR-10 Batch 5:  cost= 0.8940           train_acc= 0.6655           valid_acc= 0.6104          \n",
      "Epoch 223, CIFAR-10 Batch 1:  cost= 1.0367           train_acc= 0.6182           valid_acc= 0.6012          \n",
      "Epoch 223, CIFAR-10 Batch 2:  cost= 0.9934           train_acc= 0.6689           valid_acc= 0.5888          \n",
      "Epoch 223, CIFAR-10 Batch 3:  cost= 0.9551           train_acc= 0.6588           valid_acc= 0.6100          \n",
      "Epoch 223, CIFAR-10 Batch 4:  cost= 0.9075           train_acc= 0.6926           valid_acc= 0.6034          \n",
      "Epoch 223, CIFAR-10 Batch 5:  cost= 0.9382           train_acc= 0.6385           valid_acc= 0.5940          \n",
      "Epoch 224, CIFAR-10 Batch 1:  cost= 0.9428           train_acc= 0.6824           valid_acc= 0.6342          \n",
      "Epoch 224, CIFAR-10 Batch 2:  cost= 0.9792           train_acc= 0.6689           valid_acc= 0.5980          \n",
      "Epoch 224, CIFAR-10 Batch 3:  cost= 0.9430           train_acc= 0.6554           valid_acc= 0.6036          \n",
      "Epoch 224, CIFAR-10 Batch 4:  cost= 0.9709           train_acc= 0.6554           valid_acc= 0.5862          \n",
      "Epoch 224, CIFAR-10 Batch 5:  cost= 0.9050           train_acc= 0.6622           valid_acc= 0.6024          \n",
      "Epoch 225, CIFAR-10 Batch 1:  cost= 1.0725           train_acc= 0.6216           valid_acc= 0.5982          \n",
      "Epoch 225, CIFAR-10 Batch 2:  cost= 0.9429           train_acc= 0.6723           valid_acc= 0.6026          \n",
      "Epoch 225, CIFAR-10 Batch 3:  cost= 0.9840           train_acc= 0.6284           valid_acc= 0.5876          \n",
      "Epoch 225, CIFAR-10 Batch 4:  cost= 0.8693           train_acc= 0.7162           valid_acc= 0.6186          \n",
      "Epoch 225, CIFAR-10 Batch 5:  cost= 0.9617           train_acc= 0.6588           valid_acc= 0.5766          \n",
      "Epoch 226, CIFAR-10 Batch 1:  cost= 1.0706           train_acc= 0.6284           valid_acc= 0.6064          \n",
      "Epoch 226, CIFAR-10 Batch 2:  cost= 1.0054           train_acc= 0.6588           valid_acc= 0.5882          \n",
      "Epoch 226, CIFAR-10 Batch 3:  cost= 1.0006           train_acc= 0.6419           valid_acc= 0.5702          \n",
      "Epoch 226, CIFAR-10 Batch 4:  cost= 0.9242           train_acc= 0.6892           valid_acc= 0.5960          \n",
      "Epoch 226, CIFAR-10 Batch 5:  cost= 0.8996           train_acc= 0.6554           valid_acc= 0.6158          \n",
      "Epoch 227, CIFAR-10 Batch 1:  cost= 1.0050           train_acc= 0.6351           valid_acc= 0.6152          \n",
      "Epoch 227, CIFAR-10 Batch 2:  cost= 0.9500           train_acc= 0.6689           valid_acc= 0.6058          \n",
      "Epoch 227, CIFAR-10 Batch 3:  cost= 0.9534           train_acc= 0.6622           valid_acc= 0.5922          \n",
      "Epoch 227, CIFAR-10 Batch 4:  cost= 0.9108           train_acc= 0.7095           valid_acc= 0.6046          \n",
      "Epoch 227, CIFAR-10 Batch 5:  cost= 0.8500           train_acc= 0.6824           valid_acc= 0.6244          \n",
      "Epoch 228, CIFAR-10 Batch 1:  cost= 1.0058           train_acc= 0.6622           valid_acc= 0.6120          \n",
      "Epoch 228, CIFAR-10 Batch 2:  cost= 1.0724           train_acc= 0.5980           valid_acc= 0.5344          \n",
      "Epoch 228, CIFAR-10 Batch 3:  cost= 0.9493           train_acc= 0.6655           valid_acc= 0.6004          \n",
      "Epoch 228, CIFAR-10 Batch 4:  cost= 0.8995           train_acc= 0.7095           valid_acc= 0.6148          \n",
      "Epoch 228, CIFAR-10 Batch 5:  cost= 0.9775           train_acc= 0.6419           valid_acc= 0.5798          \n",
      "Epoch 229, CIFAR-10 Batch 1:  cost= 0.9736           train_acc= 0.6622           valid_acc= 0.6178          \n",
      "Epoch 229, CIFAR-10 Batch 2:  cost= 1.0281           train_acc= 0.6419           valid_acc= 0.5664          \n",
      "Epoch 229, CIFAR-10 Batch 3:  cost= 0.9630           train_acc= 0.6588           valid_acc= 0.5764          \n",
      "Epoch 229, CIFAR-10 Batch 4:  cost= 0.8965           train_acc= 0.6959           valid_acc= 0.6108          \n",
      "Epoch 229, CIFAR-10 Batch 5:  cost= 0.9511           train_acc= 0.6284           valid_acc= 0.5952          \n",
      "Epoch 230, CIFAR-10 Batch 1:  cost= 1.0419           train_acc= 0.6284           valid_acc= 0.6098          \n",
      "Epoch 230, CIFAR-10 Batch 2:  cost= 0.9897           train_acc= 0.6588           valid_acc= 0.5832          \n",
      "Epoch 230, CIFAR-10 Batch 3:  cost= 0.9758           train_acc= 0.6284           valid_acc= 0.5858          \n",
      "Epoch 230, CIFAR-10 Batch 4:  cost= 0.9272           train_acc= 0.6791           valid_acc= 0.6010          \n",
      "Epoch 230, CIFAR-10 Batch 5:  cost= 0.9315           train_acc= 0.6655           valid_acc= 0.5982          \n",
      "Epoch 231, CIFAR-10 Batch 1:  cost= 1.0096           train_acc= 0.6250           valid_acc= 0.6094          \n",
      "Epoch 231, CIFAR-10 Batch 2:  cost= 0.9859           train_acc= 0.6588           valid_acc= 0.5872          \n",
      "Epoch 231, CIFAR-10 Batch 3:  cost= 0.9539           train_acc= 0.6486           valid_acc= 0.5986          \n",
      "Epoch 231, CIFAR-10 Batch 4:  cost= 0.9562           train_acc= 0.6655           valid_acc= 0.5840          \n",
      "Epoch 231, CIFAR-10 Batch 5:  cost= 0.9463           train_acc= 0.6554           valid_acc= 0.5884          \n",
      "Epoch 232, CIFAR-10 Batch 1:  cost= 1.0443           train_acc= 0.6182           valid_acc= 0.6142          \n",
      "Epoch 232, CIFAR-10 Batch 2:  cost= 0.9629           train_acc= 0.6858           valid_acc= 0.5974          \n",
      "Epoch 232, CIFAR-10 Batch 3:  cost= 0.9932           train_acc= 0.6250           valid_acc= 0.5736          \n",
      "Epoch 232, CIFAR-10 Batch 4:  cost= 0.8949           train_acc= 0.7230           valid_acc= 0.6130          \n",
      "Epoch 232, CIFAR-10 Batch 5:  cost= 0.9112           train_acc= 0.6554           valid_acc= 0.5954          \n",
      "Epoch 233, CIFAR-10 Batch 1:  cost= 0.9938           train_acc= 0.6554           valid_acc= 0.6232          \n",
      "Epoch 233, CIFAR-10 Batch 2:  cost= 0.9583           train_acc= 0.6757           valid_acc= 0.6022          \n",
      "Epoch 233, CIFAR-10 Batch 3:  cost= 0.9521           train_acc= 0.6622           valid_acc= 0.5958          \n",
      "Epoch 233, CIFAR-10 Batch 4:  cost= 0.9162           train_acc= 0.6858           valid_acc= 0.6042          \n",
      "Epoch 233, CIFAR-10 Batch 5:  cost= 1.0288           train_acc= 0.6216           valid_acc= 0.5706          \n",
      "Epoch 234, CIFAR-10 Batch 1:  cost= 0.9595           train_acc= 0.6588           valid_acc= 0.6280          \n",
      "Epoch 234, CIFAR-10 Batch 2:  cost= 1.0322           train_acc= 0.6284           valid_acc= 0.5722          \n",
      "Epoch 234, CIFAR-10 Batch 3:  cost= 0.9030           train_acc= 0.6757           valid_acc= 0.6098          \n",
      "Epoch 234, CIFAR-10 Batch 4:  cost= 0.9598           train_acc= 0.6655           valid_acc= 0.5884          \n",
      "Epoch 234, CIFAR-10 Batch 5:  cost= 0.8614           train_acc= 0.6959           valid_acc= 0.6194          \n",
      "Epoch 235, CIFAR-10 Batch 1:  cost= 1.0782           train_acc= 0.6014           valid_acc= 0.6012          \n",
      "Epoch 235, CIFAR-10 Batch 2:  cost= 1.0020           train_acc= 0.6588           valid_acc= 0.5960          \n",
      "Epoch 235, CIFAR-10 Batch 3:  cost= 0.9514           train_acc= 0.6554           valid_acc= 0.5988          \n",
      "Epoch 235, CIFAR-10 Batch 4:  cost= 1.0299           train_acc= 0.6419           valid_acc= 0.5760          \n",
      "Epoch 235, CIFAR-10 Batch 5:  cost= 0.8903           train_acc= 0.6757           valid_acc= 0.6086          \n",
      "Epoch 236, CIFAR-10 Batch 1:  cost= 1.0296           train_acc= 0.6250           valid_acc= 0.6140          \n",
      "Epoch 236, CIFAR-10 Batch 2:  cost= 0.9373           train_acc= 0.6723           valid_acc= 0.6096          \n",
      "Epoch 236, CIFAR-10 Batch 3:  cost= 0.9863           train_acc= 0.6385           valid_acc= 0.5838          \n",
      "Epoch 236, CIFAR-10 Batch 4:  cost= 1.0004           train_acc= 0.6689           valid_acc= 0.5804          \n",
      "Epoch 236, CIFAR-10 Batch 5:  cost= 0.9705           train_acc= 0.6486           valid_acc= 0.5884          \n",
      "Epoch 237, CIFAR-10 Batch 1:  cost= 1.0028           train_acc= 0.6486           valid_acc= 0.6204          \n",
      "Epoch 237, CIFAR-10 Batch 2:  cost= 0.9309           train_acc= 0.6791           valid_acc= 0.6078          \n",
      "Epoch 237, CIFAR-10 Batch 3:  cost= 0.9620           train_acc= 0.6419           valid_acc= 0.5896          \n",
      "Epoch 237, CIFAR-10 Batch 4:  cost= 0.9146           train_acc= 0.7027           valid_acc= 0.6042          \n",
      "Epoch 237, CIFAR-10 Batch 5:  cost= 0.9294           train_acc= 0.6486           valid_acc= 0.5892          \n",
      "Epoch 238, CIFAR-10 Batch 1:  cost= 1.0353           train_acc= 0.6182           valid_acc= 0.6078          \n",
      "Epoch 238, CIFAR-10 Batch 2:  cost= 1.0229           train_acc= 0.6419           valid_acc= 0.5850          \n",
      "Epoch 238, CIFAR-10 Batch 3:  cost= 0.9529           train_acc= 0.6520           valid_acc= 0.5874          \n",
      "Epoch 238, CIFAR-10 Batch 4:  cost= 0.8852           train_acc= 0.7027           valid_acc= 0.6102          \n",
      "Epoch 238, CIFAR-10 Batch 5:  cost= 0.9629           train_acc= 0.6554           valid_acc= 0.5850          \n",
      "Epoch 239, CIFAR-10 Batch 1:  cost= 1.1094           train_acc= 0.6115           valid_acc= 0.5974          \n",
      "Epoch 239, CIFAR-10 Batch 2:  cost= 0.9733           train_acc= 0.6791           valid_acc= 0.5986          \n",
      "Epoch 239, CIFAR-10 Batch 3:  cost= 1.0452           train_acc= 0.6216           valid_acc= 0.5642          \n",
      "Epoch 239, CIFAR-10 Batch 4:  cost= 0.9572           train_acc= 0.6723           valid_acc= 0.5910          \n",
      "Epoch 239, CIFAR-10 Batch 5:  cost= 0.8884           train_acc= 0.6723           valid_acc= 0.6058          \n",
      "Epoch 240, CIFAR-10 Batch 1:  cost= 1.0248           train_acc= 0.6486           valid_acc= 0.6108          \n",
      "Epoch 240, CIFAR-10 Batch 2:  cost= 1.0585           train_acc= 0.6351           valid_acc= 0.5698          \n",
      "Epoch 240, CIFAR-10 Batch 3:  cost= 0.9687           train_acc= 0.6250           valid_acc= 0.5816          \n",
      "Epoch 240, CIFAR-10 Batch 4:  cost= 0.9744           train_acc= 0.6622           valid_acc= 0.5794          \n",
      "Epoch 240, CIFAR-10 Batch 5:  cost= 0.9214           train_acc= 0.6723           valid_acc= 0.5970          \n",
      "Epoch 241, CIFAR-10 Batch 1:  cost= 1.0466           train_acc= 0.6284           valid_acc= 0.6050          \n",
      "Epoch 241, CIFAR-10 Batch 2:  cost= 1.0125           train_acc= 0.6689           valid_acc= 0.5802          \n",
      "Epoch 241, CIFAR-10 Batch 3:  cost= 0.9690           train_acc= 0.6655           valid_acc= 0.5856          \n",
      "Epoch 241, CIFAR-10 Batch 4:  cost= 0.9289           train_acc= 0.6858           valid_acc= 0.5884          \n",
      "Epoch 241, CIFAR-10 Batch 5:  cost= 0.9221           train_acc= 0.6520           valid_acc= 0.5952          \n",
      "Epoch 242, CIFAR-10 Batch 1:  cost= 0.9829           train_acc= 0.6757           valid_acc= 0.6254          \n",
      "Epoch 242, CIFAR-10 Batch 2:  cost= 1.0506           train_acc= 0.6419           valid_acc= 0.5664          \n",
      "Epoch 242, CIFAR-10 Batch 3:  cost= 0.9696           train_acc= 0.6554           valid_acc= 0.5852          \n",
      "Epoch 242, CIFAR-10 Batch 4:  cost= 0.9558           train_acc= 0.6655           valid_acc= 0.5760          \n",
      "Epoch 242, CIFAR-10 Batch 5:  cost= 0.8899           train_acc= 0.6520           valid_acc= 0.6194          \n",
      "Epoch 243, CIFAR-10 Batch 1:  cost= 0.9740           train_acc= 0.6520           valid_acc= 0.6168          \n",
      "Epoch 243, CIFAR-10 Batch 2:  cost= 0.9908           train_acc= 0.6520           valid_acc= 0.5840          \n",
      "Epoch 243, CIFAR-10 Batch 3:  cost= 0.9749           train_acc= 0.6419           valid_acc= 0.5886          \n",
      "Epoch 243, CIFAR-10 Batch 4:  cost= 0.8872           train_acc= 0.7061           valid_acc= 0.6112          \n",
      "Epoch 243, CIFAR-10 Batch 5:  cost= 0.9348           train_acc= 0.6723           valid_acc= 0.5922          \n",
      "Epoch 244, CIFAR-10 Batch 1:  cost= 0.9762           train_acc= 0.6520           valid_acc= 0.6286          \n",
      "Epoch 244, CIFAR-10 Batch 2:  cost= 0.9790           train_acc= 0.6689           valid_acc= 0.5916          \n",
      "Epoch 244, CIFAR-10 Batch 3:  cost= 1.0154           train_acc= 0.6115           valid_acc= 0.5774          \n",
      "Epoch 244, CIFAR-10 Batch 4:  cost= 0.8909           train_acc= 0.7061           valid_acc= 0.6098          \n",
      "Epoch 244, CIFAR-10 Batch 5:  cost= 0.9583           train_acc= 0.6216           valid_acc= 0.5984          \n",
      "Epoch 245, CIFAR-10 Batch 1:  cost= 1.1005           train_acc= 0.6047           valid_acc= 0.5956          \n",
      "Epoch 245, CIFAR-10 Batch 2:  cost= 0.9717           train_acc= 0.6622           valid_acc= 0.5972          \n",
      "Epoch 245, CIFAR-10 Batch 3:  cost= 0.9188           train_acc= 0.6926           valid_acc= 0.6048          \n",
      "Epoch 245, CIFAR-10 Batch 4:  cost= 0.9723           train_acc= 0.6723           valid_acc= 0.5764          \n",
      "Epoch 245, CIFAR-10 Batch 5:  cost= 1.0058           train_acc= 0.6216           valid_acc= 0.5690          \n",
      "Epoch 246, CIFAR-10 Batch 1:  cost= 1.0044           train_acc= 0.6554           valid_acc= 0.6158          \n",
      "Epoch 246, CIFAR-10 Batch 2:  cost= 0.9524           train_acc= 0.6655           valid_acc= 0.5936          \n",
      "Epoch 246, CIFAR-10 Batch 3:  cost= 0.9776           train_acc= 0.6419           valid_acc= 0.5816          \n",
      "Epoch 246, CIFAR-10 Batch 4:  cost= 0.8607           train_acc= 0.7027           valid_acc= 0.6220          \n",
      "Epoch 246, CIFAR-10 Batch 5:  cost= 0.9420           train_acc= 0.6419           valid_acc= 0.5930          \n",
      "Epoch 247, CIFAR-10 Batch 1:  cost= 1.0976           train_acc= 0.6081           valid_acc= 0.5984          \n",
      "Epoch 247, CIFAR-10 Batch 2:  cost= 0.9709           train_acc= 0.6689           valid_acc= 0.5974          \n",
      "Epoch 247, CIFAR-10 Batch 3:  cost= 0.9825           train_acc= 0.6419           valid_acc= 0.5724          \n",
      "Epoch 247, CIFAR-10 Batch 4:  cost= 0.8924           train_acc= 0.6858           valid_acc= 0.6178          \n",
      "Epoch 247, CIFAR-10 Batch 5:  cost= 0.8799           train_acc= 0.6824           valid_acc= 0.6144          \n",
      "Epoch 248, CIFAR-10 Batch 1:  cost= 1.0783           train_acc= 0.6318           valid_acc= 0.5976          \n",
      "Epoch 248, CIFAR-10 Batch 2:  cost= 0.9646           train_acc= 0.6858           valid_acc= 0.5998          \n",
      "Epoch 248, CIFAR-10 Batch 3:  cost= 0.9447           train_acc= 0.6689           valid_acc= 0.5954          \n",
      "Epoch 248, CIFAR-10 Batch 4:  cost= 0.8919           train_acc= 0.7061           valid_acc= 0.6080          \n",
      "Epoch 248, CIFAR-10 Batch 5:  cost= 0.9898           train_acc= 0.6149           valid_acc= 0.5740          \n",
      "Epoch 249, CIFAR-10 Batch 1:  cost= 1.0017           train_acc= 0.6284           valid_acc= 0.6136          \n",
      "Epoch 249, CIFAR-10 Batch 2:  cost= 1.0211           train_acc= 0.6588           valid_acc= 0.5876          \n",
      "Epoch 249, CIFAR-10 Batch 3:  cost= 1.0068           train_acc= 0.6453           valid_acc= 0.5680          \n",
      "Epoch 249, CIFAR-10 Batch 4:  cost= 0.8492           train_acc= 0.7297           valid_acc= 0.6328          \n",
      "Epoch 249, CIFAR-10 Batch 5:  cost= 0.8816           train_acc= 0.6757           valid_acc= 0.6060          \n",
      "Epoch 250, CIFAR-10 Batch 1:  cost= 0.9858           train_acc= 0.6622           valid_acc= 0.6182          \n",
      "Epoch 250, CIFAR-10 Batch 2:  cost= 0.9389           train_acc= 0.6655           valid_acc= 0.6090          \n",
      "Epoch 250, CIFAR-10 Batch 3:  cost= 0.9092           train_acc= 0.6858           valid_acc= 0.6006          \n",
      "Epoch 250, CIFAR-10 Batch 4:  cost= 0.9122           train_acc= 0.6824           valid_acc= 0.6044          \n",
      "Epoch 250, CIFAR-10 Batch 5:  cost= 0.8979           train_acc= 0.6554           valid_acc= 0.6060          \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Checkpoint\n",
    "The model has been saved to disk.\n",
    "## Test Model\n",
    "Test your model against the test dataset.  This will be your final accuracy. You should have an accuracy greater than 50%. If you don't, keep tweaking the model architecture and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.6023265182971954\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6a5f114ef0>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_training.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for train_feature_batch, train_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: train_feature_batch, loaded_y: train_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Why 50-70% Accuracy?\n",
    "You might be wondering why you can't get an accuracy any higher. First things first, 50% isn't bad for a simple CNN.  Pure guessing would get you 10% accuracy. However, you might notice people are getting scores [well above 70%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130).  That's because we haven't taught you all there is to know about neural networks. We still need to cover a few more techniques.\n",
    "## Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook.  Save the notebook file as \"dlnd_image_classification.ipynb\" and save it as a HTML file under \"File\" -> \"Download as\".  Include the \"helper.py\" and \"problem_unittests.py\" files in your submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
